{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, roc_auc_score,roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramdonForest_end_Data = pd.read_csv('./建筑业_处理.csv',encoding = 'gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramdonForest_end_Data = ramdonForest_end_Data.drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FLAG\n",
       "0.0    453\n",
       "1.0      5\n",
       "Name: FLAG, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ramdonForest_end_Data['FLAG'].groupby(ramdonForest_end_Data['FLAG']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 458 entries, 0 to 457\n",
      "Columns: 105 entries, CASH_C_EQUIV to NI_NI\n",
      "dtypes: float64(105)\n",
      "memory usage: 375.8 KB\n"
     ]
    }
   ],
   "source": [
    "ramdonForest_end_Data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 过采样数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FLAG\n",
       "0.0    317\n",
       "1.0      9\n",
       "Name: FLAG, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定义SMOTE模型，random_state相当于随机数种子的作用\n",
    "#smo = SMOTE(sampling_strategy={1:25,0:453 },random_state=42)\n",
    "ros = RandomOverSampler(random_state=30,sampling_strategy=0.03)\n",
    "X_ros,y_ros = ros.fit_resample(ramdonForest_end_Data.drop(columns = 'FLAG'),ramdonForest_end_Data['FLAG'])\n",
    "#标准化数据\n",
    "sc=StandardScaler()\n",
    "sc.fit(X_ros)#计算样本的均值和标准差\n",
    "X_ros=pd.DataFrame(sc.transform(X_ros))\n",
    "#拆分专家样本集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ros,y_ros,test_size=0.3)\n",
    "y_train.groupby(y_train).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBoost模型调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 贝叶斯优化调参\n",
    "\n",
    "def modelfit(learning_rate, n_estimators, max_depth, min_child_weight, gamma, subsample, colsample_bytree,\n",
    "             Reg_lambda, Reg_alpha):\n",
    "    xgb1 =cross_val_score(xgb.XGBClassifier(objective='binary:logistic', nthread=2,\n",
    "                             n_estimators=int(n_estimators),\n",
    "                             learning_rate=float(learning_rate),\n",
    "                             max_depth=int(max_depth), min_child_weight=int(min_child_weight),\n",
    "                             gamma=float(gamma), subsample=float(subsample),\n",
    "                             colsample_bytree=float(colsample_bytree),\n",
    "                             Reg_lambda=float(Reg_lambda), Reg_alpha=float(Reg_alpha),\n",
    "                             scale_pos_weight=100, seed=10, ),X_train, pd.DataFrame(y_train),scoring='roc_auc',cv=5).mean()\n",
    "    return xgb1\n",
    "\n",
    "\n",
    "# 参数因子池\n",
    "pool = {\n",
    "    'learning_rate': (0.0001, 0.9999),\n",
    "    'n_estimators': (400, 800),\n",
    "    'max_depth': (1, 20),  # 树模型深度\n",
    "    'min_child_weight': (1, 5),\n",
    "    'gamma': (0.1, 0.7),\n",
    "    'subsample': (0.6, 0.9),\n",
    "    'colsample_bytree': (0.6, 0.9),\n",
    "    'Reg_lambda': (0.001, 3),\n",
    "    'Reg_alpha': (0.001, 2)\n",
    "\n",
    "}\n",
    "# 定义贝叶斯调参模型\n",
    "from bayes_opt import BayesianOptimization as bayes\n",
    "\n",
    "optimizer = bayes(f=modelfit,\n",
    "                  pbounds=pool,\n",
    "                  verbose=2,\n",
    "                  random_state=1,\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | Reg_alpha | Reg_la... | colsam... |   gamma   | learni... | max_depth | min_ch... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "[22:54:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:54:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:54:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:54:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:54:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:54:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:54:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:54:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:54:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:54:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8664  \u001b[0m | \u001b[0m 0.8346  \u001b[0m | \u001b[0m 2.161   \u001b[0m | \u001b[0m 0.6     \u001b[0m | \u001b[0m 0.2814  \u001b[0m | \u001b[0m 0.1468  \u001b[0m | \u001b[0m 2.754   \u001b[0m | \u001b[0m 1.745   \u001b[0m | \u001b[0m 538.2   \u001b[0m | \u001b[0m 0.719   \u001b[0m |\n",
      "[22:54:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:54:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:54:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:54:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.8404  \u001b[0m | \u001b[0m 1.078   \u001b[0m | \u001b[0m 1.258   \u001b[0m | \u001b[0m 0.8056  \u001b[0m | \u001b[0m 0.2227  \u001b[0m | \u001b[0m 0.878   \u001b[0m | \u001b[0m 1.52    \u001b[0m | \u001b[0m 3.682   \u001b[0m | \u001b[0m 566.9   \u001b[0m | \u001b[0m 0.7676  \u001b[0m |\n",
      "[22:55:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 0.2816  \u001b[0m | \u001b[0m 0.5951  \u001b[0m | \u001b[0m 0.8402  \u001b[0m | \u001b[0m 0.681   \u001b[0m | \u001b[0m 0.3135  \u001b[0m | \u001b[0m 14.15   \u001b[0m | \u001b[0m 4.506   \u001b[0m | \u001b[0m 757.8   \u001b[0m | \u001b[0m 0.6255  \u001b[0m |\n",
      "[22:55:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8337  \u001b[0m | \u001b[0m 0.07907 \u001b[0m | \u001b[0m 0.5103  \u001b[0m | \u001b[0m 0.8634  \u001b[0m | \u001b[0m 0.159   \u001b[0m | \u001b[0m 0.4211  \u001b[0m | \u001b[0m 19.2    \u001b[0m | \u001b[0m 3.133   \u001b[0m | \u001b[0m 676.8   \u001b[0m | \u001b[0m 0.6947  \u001b[0m |\n",
      "[22:55:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7516  \u001b[0m | \u001b[0m 1.373   \u001b[0m | \u001b[0m 2.504   \u001b[0m | \u001b[0m 0.6055  \u001b[0m | \u001b[0m 0.5501  \u001b[0m | \u001b[0m 0.9888  \u001b[0m | \u001b[0m 15.22   \u001b[0m | \u001b[0m 2.122   \u001b[0m | \u001b[0m 715.7   \u001b[0m | \u001b[0m 0.631   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.9003  \u001b[0m | \u001b[95m 1.645   \u001b[0m | \u001b[95m 2.693   \u001b[0m | \u001b[95m 0.8328  \u001b[0m | \u001b[95m 0.6342  \u001b[0m | \u001b[95m 0.772   \u001b[0m | \u001b[95m 3.255   \u001b[0m | \u001b[95m 1.195   \u001b[0m | \u001b[95m 538.6   \u001b[0m | \u001b[95m 0.6166  \u001b[0m |\n",
      "[22:55:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7781  \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 0.9999  \u001b[0m | \u001b[0m 5.204   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 540.1   \u001b[0m | \u001b[0m 0.6     \u001b[0m |\n",
      "[22:55:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8666  \u001b[0m | \u001b[0m 1.086   \u001b[0m | \u001b[0m 2.248   \u001b[0m | \u001b[0m 0.7781  \u001b[0m | \u001b[0m 0.2496  \u001b[0m | \u001b[0m 0.0192  \u001b[0m | \u001b[0m 3.54    \u001b[0m | \u001b[0m 2.492   \u001b[0m | \u001b[0m 538.5   \u001b[0m | \u001b[0m 0.8721  \u001b[0m |\n",
      "[22:55:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8241  \u001b[0m | \u001b[0m 1.619   \u001b[0m | \u001b[0m 2.497   \u001b[0m | \u001b[0m 0.6751  \u001b[0m | \u001b[0m 0.2609  \u001b[0m | \u001b[0m 0.6608  \u001b[0m | \u001b[0m 1.767   \u001b[0m | \u001b[0m 1.709   \u001b[0m | \u001b[0m 538.9   \u001b[0m | \u001b[0m 0.6778  \u001b[0m |\n",
      "[22:55:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8182  \u001b[0m | \u001b[0m 0.7288  \u001b[0m | \u001b[0m 2.861   \u001b[0m | \u001b[0m 0.6086  \u001b[0m | \u001b[0m 0.4795  \u001b[0m | \u001b[0m 0.8766  \u001b[0m | \u001b[0m 3.203   \u001b[0m | \u001b[0m 1.803   \u001b[0m | \u001b[0m 538.8   \u001b[0m | \u001b[0m 0.8551  \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m 0.9118  \u001b[0m | \u001b[95m 1.854   \u001b[0m | \u001b[95m 2.884   \u001b[0m | \u001b[95m 0.716   \u001b[0m | \u001b[95m 0.5552  \u001b[0m | \u001b[95m 0.3185  \u001b[0m | \u001b[95m 16.54   \u001b[0m | \u001b[95m 3.713   \u001b[0m | \u001b[95m 525.1   \u001b[0m | \u001b[95m 0.6576  \u001b[0m |\n",
      "[22:55:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8614  \u001b[0m | \u001b[0m 1.903   \u001b[0m | \u001b[0m 1.672   \u001b[0m | \u001b[0m 0.8529  \u001b[0m | \u001b[0m 0.2036  \u001b[0m | \u001b[0m 0.8093  \u001b[0m | \u001b[0m 7.505   \u001b[0m | \u001b[0m 3.996   \u001b[0m | \u001b[0m 734.0   \u001b[0m | \u001b[0m 0.6947  \u001b[0m |\n",
      "[22:55:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8995  \u001b[0m | \u001b[0m 1.221   \u001b[0m | \u001b[0m 0.1363  \u001b[0m | \u001b[0m 0.7309  \u001b[0m | \u001b[0m 0.3825  \u001b[0m | \u001b[0m 0.1259  \u001b[0m | \u001b[0m 6.991   \u001b[0m | \u001b[0m 1.967   \u001b[0m | \u001b[0m 736.1   \u001b[0m | \u001b[0m 0.8555  \u001b[0m |\n",
      "[22:55:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.8344  \u001b[0m | \u001b[0m 0.05856 \u001b[0m | \u001b[0m 0.6327  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 0.491   \u001b[0m | \u001b[0m 0.9667  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 1.407   \u001b[0m | \u001b[0m 772.9   \u001b[0m | \u001b[0m 0.7546  \u001b[0m |\n",
      "[22:55:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8679  \u001b[0m | \u001b[0m 0.381   \u001b[0m | \u001b[0m 1.043   \u001b[0m | \u001b[0m 0.8948  \u001b[0m | \u001b[0m 0.2735  \u001b[0m | \u001b[0m 0.4448  \u001b[0m | \u001b[0m 9.13    \u001b[0m | \u001b[0m 4.639   \u001b[0m | \u001b[0m 731.7   \u001b[0m | \u001b[0m 0.896   \u001b[0m |\n",
      "[22:55:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.8713  \u001b[0m | \u001b[0m 0.8254  \u001b[0m | \u001b[0m 0.1935  \u001b[0m | \u001b[0m 0.6067  \u001b[0m | \u001b[0m 0.6357  \u001b[0m | \u001b[0m 0.1708  \u001b[0m | \u001b[0m 2.286   \u001b[0m | \u001b[0m 1.149   \u001b[0m | \u001b[0m 783.0   \u001b[0m | \u001b[0m 0.6963  \u001b[0m |\n",
      "[22:55:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8773  \u001b[0m | \u001b[0m 1.582   \u001b[0m | \u001b[0m 1.296   \u001b[0m | \u001b[0m 0.7173  \u001b[0m | \u001b[0m 0.4489  \u001b[0m | \u001b[0m 0.2781  \u001b[0m | \u001b[0m 13.61   \u001b[0m | \u001b[0m 3.766   \u001b[0m | \u001b[0m 452.7   \u001b[0m | \u001b[0m 0.7288  \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8492  \u001b[0m | \u001b[0m 1.676   \u001b[0m | \u001b[0m 2.733   \u001b[0m | \u001b[0m 0.8641  \u001b[0m | \u001b[0m 0.5259  \u001b[0m | \u001b[0m 0.7199  \u001b[0m | \u001b[0m 16.06   \u001b[0m | \u001b[0m 3.799   \u001b[0m | \u001b[0m 525.0   \u001b[0m | \u001b[0m 0.8817  \u001b[0m |\n",
      "[22:55:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.9009  \u001b[0m | \u001b[0m 0.4046  \u001b[0m | \u001b[0m 1.74    \u001b[0m | \u001b[0m 0.6298  \u001b[0m | \u001b[0m 0.2621  \u001b[0m | \u001b[0m 0.3802  \u001b[0m | \u001b[0m 5.447   \u001b[0m | \u001b[0m 2.016   \u001b[0m | \u001b[0m 703.1   \u001b[0m | \u001b[0m 0.7325  \u001b[0m |\n",
      "[22:55:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.858   \u001b[0m | \u001b[0m 1.345   \u001b[0m | \u001b[0m 1.044   \u001b[0m | \u001b[0m 0.612   \u001b[0m | \u001b[0m 0.504   \u001b[0m | \u001b[0m 0.6781  \u001b[0m | \u001b[0m 3.211   \u001b[0m | \u001b[0m 4.05    \u001b[0m | \u001b[0m 784.8   \u001b[0m | \u001b[0m 0.6747  \u001b[0m |\n",
      "[22:55:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7583  \u001b[0m | \u001b[0m 1.748   \u001b[0m | \u001b[0m 2.418   \u001b[0m | \u001b[0m 0.6846  \u001b[0m | \u001b[0m 0.5308  \u001b[0m | \u001b[0m 0.2052  \u001b[0m | \u001b[0m 11.61   \u001b[0m | \u001b[0m 4.345   \u001b[0m | \u001b[0m 582.1   \u001b[0m | \u001b[0m 0.8342  \u001b[0m |\n",
      "[22:55:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.837   \u001b[0m | \u001b[0m 1.887   \u001b[0m | \u001b[0m 1.369   \u001b[0m | \u001b[0m 0.6327  \u001b[0m | \u001b[0m 0.4764  \u001b[0m | \u001b[0m 0.3101  \u001b[0m | \u001b[0m 15.35   \u001b[0m | \u001b[0m 3.103   \u001b[0m | \u001b[0m 615.2   \u001b[0m | \u001b[0m 0.8532  \u001b[0m |\n",
      "[22:55:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7443  \u001b[0m | \u001b[0m 1.155   \u001b[0m | \u001b[0m 2.147   \u001b[0m | \u001b[0m 0.6995  \u001b[0m | \u001b[0m 0.3126  \u001b[0m | \u001b[0m 0.6286  \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 3.678   \u001b[0m | \u001b[0m 616.1   \u001b[0m | \u001b[0m 0.8855  \u001b[0m |\n",
      "[22:55:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:55:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.8587  \u001b[0m | \u001b[0m 1.626   \u001b[0m | \u001b[0m 2.942   \u001b[0m | \u001b[0m 0.6908  \u001b[0m | \u001b[0m 0.5936  \u001b[0m | \u001b[0m 0.5993  \u001b[0m | \u001b[0m 15.89   \u001b[0m | \u001b[0m 4.71    \u001b[0m | \u001b[0m 524.7   \u001b[0m | \u001b[0m 0.7284  \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.8585  \u001b[0m | \u001b[0m 1.779   \u001b[0m | \u001b[0m 1.832   \u001b[0m | \u001b[0m 0.8627  \u001b[0m | \u001b[0m 0.6446  \u001b[0m | \u001b[0m 0.006696\u001b[0m | \u001b[0m 13.72   \u001b[0m | \u001b[0m 3.01    \u001b[0m | \u001b[0m 452.3   \u001b[0m | \u001b[0m 0.7904  \u001b[0m |\n",
      "[22:56:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.8651  \u001b[0m | \u001b[0m 1.088   \u001b[0m | \u001b[0m 1.467   \u001b[0m | \u001b[0m 0.7417  \u001b[0m | \u001b[0m 0.4354  \u001b[0m | \u001b[0m 0.03093 \u001b[0m | \u001b[0m 5.835   \u001b[0m | \u001b[0m 1.362   \u001b[0m | \u001b[0m 702.9   \u001b[0m | \u001b[0m 0.8378  \u001b[0m |\n",
      "[22:56:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.8691  \u001b[0m | \u001b[0m 1.096   \u001b[0m | \u001b[0m 1.975   \u001b[0m | \u001b[0m 0.6118  \u001b[0m | \u001b[0m 0.6449  \u001b[0m | \u001b[0m 0.003121\u001b[0m | \u001b[0m 5.637   \u001b[0m | \u001b[0m 1.145   \u001b[0m | \u001b[0m 703.0   \u001b[0m | \u001b[0m 0.7734  \u001b[0m |\n",
      "[22:56:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.8933  \u001b[0m | \u001b[0m 1.897   \u001b[0m | \u001b[0m 0.2971  \u001b[0m | \u001b[0m 0.7485  \u001b[0m | \u001b[0m 0.358   \u001b[0m | \u001b[0m 0.03924 \u001b[0m | \u001b[0m 7.843   \u001b[0m | \u001b[0m 1.019   \u001b[0m | \u001b[0m 736.0   \u001b[0m | \u001b[0m 0.805   \u001b[0m |\n",
      "[22:56:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.8913  \u001b[0m | \u001b[0m 0.9943  \u001b[0m | \u001b[0m 0.5694  \u001b[0m | \u001b[0m 0.6277  \u001b[0m | \u001b[0m 0.3442  \u001b[0m | \u001b[0m 0.581   \u001b[0m | \u001b[0m 6.967   \u001b[0m | \u001b[0m 1.489   \u001b[0m | \u001b[0m 737.0   \u001b[0m | \u001b[0m 0.6786  \u001b[0m |\n",
      "[22:56:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.8973  \u001b[0m | \u001b[0m 0.1789  \u001b[0m | \u001b[0m 1.183   \u001b[0m | \u001b[0m 0.8692  \u001b[0m | \u001b[0m 0.493   \u001b[0m | \u001b[0m 0.5797  \u001b[0m | \u001b[0m 4.65    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 703.4   \u001b[0m | \u001b[0m 0.7212  \u001b[0m |\n",
      "=====================================================================================================================================\n",
      "{'target': 0.9117559523809524, 'params': {'Reg_alpha': 1.8537533637055619, 'Reg_lambda': 2.884122321282139, 'colsample_bytree': 0.7160372737388345, 'gamma': 0.5552427943453344, 'learning_rate': 0.3185022273431129, 'max_depth': 16.537333237272072, 'min_child_weight': 3.712607529262894, 'n_estimators': 525.1360182390339, 'subsample': 0.6576407419449536}}\n"
     ]
    }
   ],
   "source": [
    "# 调参并输出最优因子\n",
    "optimizer.maximize(\n",
    "    init_points=5,\n",
    "    n_iter=25,\n",
    ")\n",
    "print(optimizer.max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { Reg_alpha, Reg_lambda } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:12:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "the xgboost model auc: 0.875\n"
     ]
    }
   ],
   "source": [
    "# xgboost模型训练\n",
    "{'target': 0.9117559523809524, 'params': {'Reg_alpha': 1.8537533637055619, 'Reg_lambda': 2.884122321282139, \n",
    "                                          'colsample_bytree': 0.7160372737388345, 'gamma': 0.5552427943453344, \n",
    "                                          'learning_rate': 0.3185022273431129, 'max_depth': 16.537333237272072, \n",
    "                                          'min_child_weight': 3.712607529262894, 'n_estimators': 525.1360182390339, \n",
    "                                          'subsample': 0.6576407419449536}}\n",
    "xgb1 = xgb.XGBClassifier(n_estimators=525,learning_rate=0.31,\n",
    "                        max_depth=16,min_child_weight=3,gamma=0.55,\n",
    "                        subsample=0.65,colsample_bytree=0.71,\n",
    "                        objective='binary:logistic',nthread=2,\n",
    "                        scale_pos_weight=100,seed=10,Reg_lambda = 2.88,\n",
    "                         Reg_alpha = 1.85)#scale_pos_weight很重要\n",
    "xgb1.fit(X_train, y_train)\n",
    "\n",
    "y_test_pre = xgb1.predict(X_test)\n",
    "y_test_true = np.array(y_test)\n",
    "print(\"the xgboost model auc: %.4g\" % metrics.roc_auc_score(y_test_true,y_test_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOING_CONCERN_NI      0.218689\n",
      "IN_TC                 0.122523\n",
      "NOPERATE_INCOME       0.120010\n",
      "C_FR_OTH_OPERATE_A    0.102898\n",
      "PREPAYMENT            0.064720\n",
      "DEFER_TAX_ASSETS      0.059281\n",
      "GOODWILL              0.058267\n",
      "C_INF_FR_INVEST_A     0.054402\n",
      "OR_TC                 0.031268\n",
      "RETAINED_EARNINGS     0.024222\n",
      "ASSETS_IMPAIR_LOSS    0.020345\n",
      "C_FR_OTH_FINAN_A      0.018772\n",
      "LT_BORR               0.013387\n",
      "CASH_C_EQUIV          0.012535\n",
      "NCL_WITHIN_1Y         0.009422\n",
      "NOTES_RECEIV          0.007876\n",
      "N_CF_FR_FINAN_A       0.007484\n",
      "N_INCOME_ATTR_P       0.006905\n",
      "NOPERATE_EXP          0.006870\n",
      "N_CHANGE_IN_CASH      0.005542\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# 特征重要性排名\n",
    "xgb_predictors = [i for i in ramdonForest_end_Data.drop(columns = 'FLAG').columns]\n",
    "xgb_feat_imp = pd.Series(xgb1.feature_importances_, xgb_predictors).sort_values(ascending=False)\n",
    "xgb_feat_imp[0:20].plot(kind='bar', title='Feature Importance')\n",
    "plt.ylabel('Feature Importance Score')\n",
    "plt.show()\n",
    "print(xgb_feat_imp[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GOING_CONCERN_NI      0.218689\n",
       "IN_TC                 0.122523\n",
       "NOPERATE_INCOME       0.120010\n",
       "C_FR_OTH_OPERATE_A    0.102898\n",
       "PREPAYMENT            0.064720\n",
       "DEFER_TAX_ASSETS      0.059281\n",
       "GOODWILL              0.058267\n",
       "C_INF_FR_INVEST_A     0.054402\n",
       "OR_TC                 0.031268\n",
       "RETAINED_EARNINGS     0.024222\n",
       "ASSETS_IMPAIR_LOSS    0.020345\n",
       "C_FR_OTH_FINAN_A      0.018772\n",
       "LT_BORR               0.013387\n",
       "CASH_C_EQUIV          0.012535\n",
       "NCL_WITHIN_1Y         0.009422\n",
       "NOTES_RECEIV          0.007876\n",
       "N_CF_FR_FINAN_A       0.007484\n",
       "N_INCOME_ATTR_P       0.006905\n",
       "NOPERATE_EXP          0.006870\n",
       "N_CHANGE_IN_CASH      0.005542\n",
       "dtype: float32"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_feat_imp[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       136\n",
      "         1.0       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.99       140\n",
      "   macro avg       1.00      0.88      0.93       140\n",
      "weighted avg       0.99      0.99      0.99       140\n",
      "\n",
      "auc值为: 0.875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'XGBClassifier ROC Curve')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 具体的模型得分报告\n",
    "print(classification_report(y_test_true,y_test_pre))\n",
    "print(\"auc值为:\", roc_auc_score(y_test_true,y_test_pre))\n",
    "\n",
    "# ROC曲线绘制\n",
    "fpr1, tpr1, threshold1 = roc_curve(y_test_true, y_test_pre)\n",
    "plt.plot(fpr1, tpr1, color='r')\n",
    "plt.plot([0, 1], [0, 1], color='blue', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('XGBClassifier ROC Curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LightGBM模型调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#贝叶斯优化调参\n",
    "def modelfit(learning_rate,n_estimators,max_depth,num_leaves,min_data_in_leaf,max_bin,feature_fraction,\n",
    "            bagging_fraction,bagging_freq,lambda_l1,lambda_l2,min_split_gain):\n",
    "    lgb1 = cross_val_score(lgb.LGBMClassifier(boosting_type='gbdt',objective= 'binary',metric =  'binary_logloss,auc',\n",
    "                              n_estimators = int(n_estimators),\n",
    "                              max_depth = int(max_depth),\n",
    "                              num_leaves = int(num_leaves),\n",
    "                              learning_rate = float(learning_rate),\n",
    "                              min_data_in_leaf = int(min_data_in_leaf),\n",
    "                              max_bin = int(max_bin),\n",
    "                              feature_fraction = float(feature_fraction),\n",
    "                              bagging_fraction = float(bagging_fraction),\n",
    "                              bagging_freq = int(bagging_freq),\n",
    "                              lambda_l1 = float(lambda_l1),lambda_l2 = float(lambda_l2),\n",
    "                              min_split_gain = float(min_split_gain),\n",
    "                              cat_smooth = 100,nthread = 4, ),X_train,pd.DataFrame(y_train),scoring='roc_auc',cv=5).mean()\n",
    "    return lgb1\n",
    "\n",
    "pool = {\n",
    "    'learning_rate':(0.0001,0.9999),\n",
    "    'n_estimators':(400,800),\n",
    "    'max_depth':(1,20),              #树模型深度\n",
    "    'num_leaves':(10,30),            #叶子树，树模型复杂度\n",
    "    'min_data_in_leaf':(1,70),       #处理过拟合，一个叶子上数据的最小数量\n",
    "    'max_bin':(5,255),               #工具箱数（叶子结点数+非叶子节点数？）\n",
    "    'feature_fraction':(0.5,0.999),  #每次迭代中随机选择特征的比例。加速训练，处理过拟合\n",
    "    'bagging_fraction':(0.5,0.999),  #不进行重采样的情况下随机选择部分数据\n",
    "    'bagging_freq':(3,5),            #bagging的次数。0表示禁用bagging，非零值表示执行k次bagging\n",
    "    'lambda_l1':(0.0001,0.9999),\n",
    "    'lambda_l2':(0.0001,0.9999),\n",
    "    'min_split_gain':(0.01,0.999)    #执行切分的最小增益\n",
    "    \n",
    "}\n",
    "\n",
    "from bayes_opt import BayesianOptimization as bayes\n",
    "optimizer = bayes(f=modelfit,\n",
    "                 pbounds = pool,\n",
    "                 verbose = 2,\n",
    "                 random_state = 1,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | baggin... | featur... | lambda_l1 | lambda_l2 | learni... |  max_bin  | max_depth | min_da... | min_sp... | n_esti... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8465056787061448, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8465056787061448\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41419643367299724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41419643367299724\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5510648799850851, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5510648799850851\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.050043468254297944, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.050043468254297944\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8465056787061448, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8465056787061448\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41419643367299724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41419643367299724\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5510648799850851, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5510648799850851\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.050043468254297944, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.050043468254297944\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8465056787061448, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8465056787061448\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41419643367299724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41419643367299724\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5510648799850851, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5510648799850851\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.050043468254297944, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.050043468254297944\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8465056787061448, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8465056787061448\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41419643367299724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41419643367299724\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5510648799850851, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5510648799850851\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.050043468254297944, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.050043468254297944\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8465056787061448, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8465056787061448\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=66, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=66\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41419643367299724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41419643367299724\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5510648799850851, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5510648799850851\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.050043468254297944, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.050043468254297944\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.8542  \u001b[0m | \u001b[0m 0.5511  \u001b[0m | \u001b[0m 3.828   \u001b[0m | \u001b[0m 0.8465  \u001b[0m | \u001b[0m 0.4142  \u001b[0m | \u001b[0m 0.05004 \u001b[0m | \u001b[0m 0.5359  \u001b[0m | \u001b[0m 170.9   \u001b[0m | \u001b[0m 10.78   \u001b[0m | \u001b[0m 66.18   \u001b[0m | \u001b[0m 0.5901  \u001b[0m | \u001b[0m 761.4   \u001b[0m | \u001b[0m 12.75   \u001b[0m |\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6984407416557813, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6984407416557813\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16542112627750938, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16542112627750938\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5694988972781285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5694988972781285\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9274230786799547, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9274230786799547\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6984407416557813, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6984407416557813\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16542112627750938, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16542112627750938\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5694988972781285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5694988972781285\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9274230786799547, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9274230786799547\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6984407416557813, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6984407416557813\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16542112627750938, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16542112627750938\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5694988972781285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5694988972781285\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9274230786799547, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9274230786799547\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6984407416557813, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6984407416557813\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16542112627750938, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16542112627750938\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5694988972781285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5694988972781285\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9274230786799547, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9274230786799547\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6984407416557813, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6984407416557813\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16542112627750938, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16542112627750938\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5694988972781285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5694988972781285\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9274230786799547, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9274230786799547\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.9463  \u001b[0m | \u001b[0m 0.5695  \u001b[0m | \u001b[0m 4.615   \u001b[0m | \u001b[0m 0.6984  \u001b[0m | \u001b[0m 0.1654  \u001b[0m | \u001b[0m 0.9274  \u001b[0m | \u001b[0m 0.3478  \u001b[0m | \u001b[0m 192.7   \u001b[0m | \u001b[0m 14.79   \u001b[0m | \u001b[0m 61.95   \u001b[0m | \u001b[0m 0.6268  \u001b[0m | \u001b[0m 700.4   \u001b[0m | \u001b[0m 16.98   \u001b[0m |\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7136175037457761, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7136175037457761\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9647470791389559, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9647470791389559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.634694017990748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.634694017990748\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6634088095188844, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6634088095188844\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7136175037457761, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7136175037457761\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9647470791389559, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9647470791389559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.634694017990748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.634694017990748\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6634088095188844, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6634088095188844\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7136175037457761, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7136175037457761\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9647470791389559, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9647470791389559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.634694017990748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.634694017990748\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6634088095188844, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6634088095188844\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7136175037457761, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7136175037457761\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9647470791389559, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9647470791389559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.634694017990748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.634694017990748\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6634088095188844, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6634088095188844\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7136175037457761, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7136175037457761\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9647470791389559, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9647470791389559\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.634694017990748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.634694017990748\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6634088095188844, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6634088095188844\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.8474  \u001b[0m | \u001b[0m 0.6347  \u001b[0m | \u001b[0m 4.792   \u001b[0m | \u001b[0m 0.7136  \u001b[0m | \u001b[0m 0.9647  \u001b[0m | \u001b[0m 0.6634  \u001b[0m | \u001b[0m 0.6217  \u001b[0m | \u001b[0m 33.69   \u001b[0m | \u001b[0m 19.04   \u001b[0m | \u001b[0m 32.04   \u001b[0m | \u001b[0m 0.582   \u001b[0m | \u001b[0m 563.3   \u001b[0m | \u001b[0m 14.74   \u001b[0m |\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5014322931885483, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5014322931885483\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6171214846379998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6171214846379998\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9507863807605647, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9507863807605647\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.32667957279174176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.32667957279174176\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5014322931885483, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5014322931885483\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6171214846379998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6171214846379998\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9507863807605647, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9507863807605647\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.32667957279174176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.32667957279174176\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5014322931885483, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5014322931885483\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6171214846379998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6171214846379998\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9507863807605647, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9507863807605647\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.32667957279174176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.32667957279174176\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5014322931885483, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5014322931885483\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6171214846379998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6171214846379998\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9507863807605647, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9507863807605647\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.32667957279174176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.32667957279174176\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5014322931885483, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5014322931885483\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6171214846379998, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6171214846379998\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9507863807605647, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9507863807605647\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.32667957279174176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.32667957279174176\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.9183  \u001b[0m | \u001b[0m 0.9508  \u001b[0m | \u001b[0m 4.147   \u001b[0m | \u001b[0m 0.5014  \u001b[0m | \u001b[0m 0.6171  \u001b[0m | \u001b[0m 0.3267  \u001b[0m | \u001b[0m 0.5271  \u001b[0m | \u001b[0m 226.5   \u001b[0m | \u001b[0m 7.788   \u001b[0m | \u001b[0m 63.69   \u001b[0m | \u001b[0m 0.6265  \u001b[0m | \u001b[0m 406.3   \u001b[0m | \u001b[0m 28.59   \u001b[0m |\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.585997913664319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.585997913664319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13720832247895198, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13720832247895198\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8447575618409451, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8447575618409451\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9325089439445562, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9325089439445562\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.585997913664319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.585997913664319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13720832247895198, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13720832247895198\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8447575618409451, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8447575618409451\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9325089439445562, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9325089439445562\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.585997913664319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.585997913664319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13720832247895198, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13720832247895198\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8447575618409451, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8447575618409451\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9325089439445562, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9325089439445562\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.585997913664319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.585997913664319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13720832247895198, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13720832247895198\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8447575618409451, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8447575618409451\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9325089439445562, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9325089439445562\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.585997913664319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.585997913664319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13720832247895198, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13720832247895198\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8447575618409451, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8447575618409451\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9325089439445562, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9325089439445562\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.9476  \u001b[0m | \u001b[0m 0.8448  \u001b[0m | \u001b[0m 4.995   \u001b[0m | \u001b[0m 0.586   \u001b[0m | \u001b[0m 0.1372  \u001b[0m | \u001b[0m 0.9325  \u001b[0m | \u001b[0m 0.6968  \u001b[0m | \u001b[0m 21.5    \u001b[0m | \u001b[0m 15.35   \u001b[0m | \u001b[0m 53.02   \u001b[0m | \u001b[0m 0.9229  \u001b[0m | \u001b[0m 684.6   \u001b[0m | \u001b[0m 12.49   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5188661356501592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5188661356501592\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6060398655440489, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6060398655440489\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9872360721867921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9872360721867921\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.150721185749143, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.150721185749143\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5188661356501592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5188661356501592\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6060398655440489, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6060398655440489\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9872360721867921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9872360721867921\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.150721185749143, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.150721185749143\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5188661356501592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5188661356501592\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6060398655440489, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6060398655440489\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9872360721867921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9872360721867921\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.150721185749143, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.150721185749143\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5188661356501592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5188661356501592\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6060398655440489, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6060398655440489\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9872360721867921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9872360721867921\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.150721185749143, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.150721185749143\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5188661356501592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5188661356501592\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=51, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=51\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.6060398655440489, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6060398655440489\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9872360721867921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9872360721867921\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.150721185749143, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.150721185749143\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.9222  \u001b[0m | \u001b[0m 0.9872  \u001b[0m | \u001b[0m 4.56    \u001b[0m | \u001b[0m 0.5189  \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 0.1507  \u001b[0m | \u001b[0m 0.4046  \u001b[0m | \u001b[0m 166.4   \u001b[0m | \u001b[0m 11.81   \u001b[0m | \u001b[0m 51.09   \u001b[0m | \u001b[0m 0.1858  \u001b[0m | \u001b[0m 599.5   \u001b[0m | \u001b[0m 11.69   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9626781992450375, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9626781992450375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08291886660074, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08291886660074\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7072115826885701, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7072115826885701\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8832789376509664, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8832789376509664\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9626781992450375, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9626781992450375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08291886660074, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08291886660074\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7072115826885701, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7072115826885701\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8832789376509664, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8832789376509664\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9626781992450375, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9626781992450375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08291886660074, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08291886660074\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7072115826885701, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7072115826885701\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8832789376509664, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8832789376509664\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9626781992450375, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9626781992450375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08291886660074, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08291886660074\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7072115826885701, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7072115826885701\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8832789376509664, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8832789376509664\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9626781992450375, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9626781992450375\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08291886660074, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08291886660074\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7072115826885701, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7072115826885701\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8832789376509664, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8832789376509664\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.9365  \u001b[0m | \u001b[0m 0.7072  \u001b[0m | \u001b[0m 4.512   \u001b[0m | \u001b[0m 0.9627  \u001b[0m | \u001b[0m 0.08292 \u001b[0m | \u001b[0m 0.8833  \u001b[0m | \u001b[0m 0.256   \u001b[0m | \u001b[0m 248.2   \u001b[0m | \u001b[0m 19.04   \u001b[0m | \u001b[0m 32.39   \u001b[0m | \u001b[0m 0.03234 \u001b[0m | \u001b[0m 431.4   \u001b[0m | \u001b[0m 26.21   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8796975862780128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8796975862780128\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0027240744476565056, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0027240744476565056\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8675754748054831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8675754748054831\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9770757602087684, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9770757602087684\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8796975862780128, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8796975862780128\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0027240744476565056, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0027240744476565056\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8675754748054831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8675754748054831\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9770757602087684, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9770757602087684\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0.8675754748054831, 4.582610495406188, 0.8796975862780128, 0.0027240744476565056, 0.9770757602087684, 0.5163353822493522, 207.88350844167658, 9.60168770865501, 24.498245653779765, 0.3980785091924386, 426.8602156590946, 13.855622699006041)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-7d46391b1c97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer.maximize(\n\u001b[0;32m      2\u001b[0m     \u001b[0minit_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-ada2736dc4c1>\u001b[0m in \u001b[0;36mmodelfit\u001b[1;34m(learning_rate, n_estimators, max_depth, num_leaves, min_data_in_leaf, max_bin, feature_fraction, bagging_fraction, bagging_freq, lambda_l1, lambda_l2, min_split_gain)\u001b[0m\n\u001b[0;32m     14\u001b[0m                               \u001b[0mlambda_l1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambda_l1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlambda_l2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambda_l2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                               \u001b[0mmin_split_gain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_split_gain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                               cat_smooth = 100,nthread = 4, ),X_train,pd.DataFrame(y_train),scoring='roc_auc',cv=5).mean()\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlgb1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    443\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    446\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 252\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;31m# For callabe scoring, the return type is only know after calling. If the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    855\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m                                         callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[0;32m    858\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    615\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_metrics_callable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m                               callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[0;32m    618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    250\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   2458\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   2459\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2460\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   2461\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2462\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer.maximize(\n",
    "    init_points = 5,\n",
    "    n_iter = 25,\n",
    ")\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.73, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.73\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "the lightgbm model auc : 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lgb1 = lgb.LGBMClassifier(boosting_type='gbdt',objective= 'binary',metric =  'binary_logloss,auc',\n",
    "                          bagging_fraction = 0.7, bagging_freq = 3,\n",
    "                          feature_fraction = 0.3,lambda_l1 =  0.5,lambda_l2 = 0.73,\n",
    "                          learning_rate = 0.01,max_bin = 113,max_depth = 10,\n",
    "                          min_data_in_leaf = 8,min_split_gain = 0.38,\n",
    "                          n_estimators = 670,num_leaves = 15,\n",
    "                          cat_smooth = 100,nthread = 4)\n",
    "#cat_smooth：可以减少噪声对分类特征的影响，尤其是对于数据较少的分类\n",
    "lgb_model = lgb1.fit(X_train,pd.DataFrame(y_train))\n",
    "y_test_pre = lgb1.predict(X_test)\n",
    "y_test_true = np.array(y_test)\n",
    "print (\"the lightgbm model auc : %.4g\" % metrics.roc_auc_score(y_test_true,y_test_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOING_CONCERN_NI      135\n",
      "C_FR_OTH_OPERATE_A     78\n",
      "NOPERATE_EXP           70\n",
      "IN_TC                  69\n",
      "PREPAYMENT             54\n",
      "                     ... \n",
      "T_LIAB_EQUITY           0\n",
      "ADVANCE_RECEIPTS        0\n",
      "C_FR_BORR               0\n",
      "TAXES_PAYABLE           0\n",
      "INTAN_ASSETS            0\n",
      "Length: 104, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "#特征重要性排名\n",
    "lgb_predictors = [i  for i in ramdonForest_end_Data.drop(columns = 'FLAG').columns]\n",
    "lgb_feat_imp = pd.Series(lgb_model.feature_importances_,lgb_predictors).sort_values(ascending=False)\n",
    "lgb_feat_imp[0:20].plot(kind = 'bar',title='Feature Importance')\n",
    "plt.ylabel('Feature Importance Score')\n",
    "plt.show()\n",
    "print(lgb_feat_imp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOING_CONCERN_NI       135\n",
      "C_FR_OTH_OPERATE_A      78\n",
      "NOPERATE_EXP            70\n",
      "IN_TC                   69\n",
      "PREPAYMENT              54\n",
      "NOPERATE_INCOME         47\n",
      "OR_TC                   42\n",
      "C_INF_FR_INVEST_A       34\n",
      "NCL_WITHIN_1Y           32\n",
      "LT_BORR                 32\n",
      "MINORITY_INT            28\n",
      "BIZ_TAX_SURCHG          20\n",
      "RETAINED_EARNINGS       19\n",
      "GOODWILL                17\n",
      "N_CF_FR_FINAN_A         16\n",
      "LT_EQUITY_INVEST        15\n",
      "AP_TC                   15\n",
      "DISP_FIX_ASSETS_OTH     15\n",
      "N_CE_END_BAL            14\n",
      "OTH_PAYABLE             13\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(lgb_feat_imp[0:20] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       136\n",
      "         1.0       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.99       140\n",
      "   macro avg       1.00      0.88      0.93       140\n",
      "weighted avg       0.99      0.99      0.99       140\n",
      "\n",
      "auc值为: 0.875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LGBClassifier ROC Curve')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#具体的模型得分报告\n",
    "print(classification_report(y_test_true,y_test_pre))\n",
    "print(\"auc值为:\",roc_auc_score(y_test_true,y_test_pre))\n",
    "\n",
    "#ROC曲线绘制\n",
    "fpr1,tpr1,threshold1 = roc_curve(y_test_true,y_test_pre)\n",
    "plt.plot(fpr1, tpr1, color='r') \n",
    "plt.plot([0, 1], [0, 1], color='blue',linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('LGBClassifier ROC Curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Catboost模型调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(learning_rate,depth,bagging_temperature):\n",
    "    cat1 = cross_val_score(CatBoostClassifier(loss_function = 'Logloss',\n",
    "                             eval_metric = 'AUC',\n",
    "                             iterations = 2500,\n",
    "                             learning_rate = float(learning_rate),\n",
    "                             depth = int(depth),\n",
    "                             verbose = 100,\n",
    "                             bagging_temperature = float(bagging_temperature),\n",
    "                             early_stopping_rounds = 500),X_train,pd.DataFrame(y_train),scoring='roc_auc',cv=5).mean()\n",
    "    return cat1\n",
    "\n",
    "pool = {\n",
    "    'learning_rate':(0.01,0.999),\n",
    "    'depth':(4,9),\n",
    "    'bagging_temperature':(0.01,0.999)\n",
    "}\n",
    "from bayes_opt import BayesianOptimization as bayes\n",
    "optimizer = bayes(f=modelfit,\n",
    "                 pbounds = pool,\n",
    "                 verbose = 2,\n",
    "                 random_state = 1,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... |   depth   | learni... |\n",
      "-------------------------------------------------------------\n",
      "0:\ttotal: 207ms\tremaining: 8m 37s\n",
      "100:\ttotal: 6.09s\tremaining: 2m 24s\n",
      "200:\ttotal: 12.3s\tremaining: 2m 20s\n",
      "300:\ttotal: 17.9s\tremaining: 2m 10s\n",
      "400:\ttotal: 22.8s\tremaining: 1m 59s\n",
      "500:\ttotal: 27.8s\tremaining: 1m 50s\n",
      "600:\ttotal: 32.7s\tremaining: 1m 43s\n",
      "700:\ttotal: 37.6s\tremaining: 1m 36s\n",
      "800:\ttotal: 42.4s\tremaining: 1m 30s\n",
      "900:\ttotal: 47.4s\tremaining: 1m 24s\n",
      "1000:\ttotal: 52.3s\tremaining: 1m 18s\n",
      "1100:\ttotal: 57.2s\tremaining: 1m 12s\n",
      "1200:\ttotal: 1m 2s\tremaining: 1m 7s\n",
      "1300:\ttotal: 1m 7s\tremaining: 1m 1s\n",
      "1400:\ttotal: 1m 12s\tremaining: 56.5s\n",
      "1500:\ttotal: 1m 17s\tremaining: 51.3s\n",
      "1600:\ttotal: 1m 22s\tremaining: 46.1s\n",
      "1700:\ttotal: 1m 27s\tremaining: 41s\n",
      "1800:\ttotal: 1m 32s\tremaining: 35.8s\n",
      "1900:\ttotal: 1m 37s\tremaining: 30.7s\n",
      "2000:\ttotal: 1m 42s\tremaining: 25.5s\n",
      "2100:\ttotal: 1m 47s\tremaining: 20.4s\n",
      "2200:\ttotal: 1m 52s\tremaining: 15.3s\n",
      "2300:\ttotal: 1m 58s\tremaining: 10.2s\n",
      "2400:\ttotal: 2m 3s\tremaining: 5.09s\n",
      "2499:\ttotal: 2m 8s\tremaining: 0us\n",
      "0:\ttotal: 65.1ms\tremaining: 2m 42s\n",
      "100:\ttotal: 5.23s\tremaining: 2m 4s\n",
      "200:\ttotal: 10.4s\tremaining: 1m 58s\n",
      "300:\ttotal: 15.4s\tremaining: 1m 52s\n",
      "400:\ttotal: 20.6s\tremaining: 1m 47s\n",
      "500:\ttotal: 25.8s\tremaining: 1m 42s\n",
      "600:\ttotal: 30.9s\tremaining: 1m 37s\n",
      "700:\ttotal: 36.1s\tremaining: 1m 32s\n",
      "800:\ttotal: 41.2s\tremaining: 1m 27s\n",
      "900:\ttotal: 46.3s\tremaining: 1m 22s\n",
      "1000:\ttotal: 51.6s\tremaining: 1m 17s\n",
      "1100:\ttotal: 56.9s\tremaining: 1m 12s\n",
      "1200:\ttotal: 1m 2s\tremaining: 1m 7s\n",
      "1300:\ttotal: 1m 7s\tremaining: 1m 2s\n",
      "1400:\ttotal: 1m 12s\tremaining: 57s\n",
      "1500:\ttotal: 1m 18s\tremaining: 51.9s\n",
      "1600:\ttotal: 1m 23s\tremaining: 46.9s\n",
      "1700:\ttotal: 1m 29s\tremaining: 42s\n",
      "1800:\ttotal: 1m 35s\tremaining: 36.9s\n",
      "1900:\ttotal: 1m 40s\tremaining: 31.8s\n",
      "2000:\ttotal: 1m 46s\tremaining: 26.5s\n",
      "2100:\ttotal: 1m 51s\tremaining: 21.2s\n",
      "2200:\ttotal: 1m 57s\tremaining: 15.9s\n",
      "2300:\ttotal: 2m 4s\tremaining: 10.7s\n",
      "2400:\ttotal: 2m 9s\tremaining: 5.34s\n",
      "2499:\ttotal: 2m 14s\tremaining: 0us\n",
      "0:\ttotal: 68.5ms\tremaining: 2m 51s\n",
      "100:\ttotal: 5.42s\tremaining: 2m 8s\n",
      "200:\ttotal: 11.1s\tremaining: 2m 6s\n",
      "300:\ttotal: 17s\tremaining: 2m 3s\n",
      "400:\ttotal: 23.7s\tremaining: 2m 3s\n",
      "500:\ttotal: 30.9s\tremaining: 2m 3s\n",
      "600:\ttotal: 37.6s\tremaining: 1m 58s\n",
      "700:\ttotal: 43.8s\tremaining: 1m 52s\n",
      "800:\ttotal: 49.6s\tremaining: 1m 45s\n",
      "900:\ttotal: 55.4s\tremaining: 1m 38s\n",
      "1000:\ttotal: 1m 1s\tremaining: 1m 31s\n",
      "1100:\ttotal: 1m 6s\tremaining: 1m 25s\n",
      "1200:\ttotal: 1m 12s\tremaining: 1m 18s\n",
      "1300:\ttotal: 1m 18s\tremaining: 1m 12s\n",
      "1400:\ttotal: 1m 24s\tremaining: 1m 5s\n",
      "1500:\ttotal: 1m 31s\tremaining: 1m 1s\n",
      "1600:\ttotal: 1m 38s\tremaining: 55.4s\n",
      "1700:\ttotal: 1m 45s\tremaining: 49.4s\n",
      "1800:\ttotal: 1m 52s\tremaining: 43.7s\n",
      "1900:\ttotal: 2m 1s\tremaining: 38.3s\n",
      "2000:\ttotal: 2m 8s\tremaining: 32s\n",
      "2100:\ttotal: 2m 15s\tremaining: 25.7s\n",
      "2200:\ttotal: 2m 21s\tremaining: 19.2s\n",
      "2300:\ttotal: 2m 27s\tremaining: 12.8s\n",
      "2400:\ttotal: 2m 34s\tremaining: 6.37s\n",
      "2499:\ttotal: 2m 41s\tremaining: 0us\n",
      "0:\ttotal: 94.3ms\tremaining: 3m 55s\n",
      "100:\ttotal: 6.02s\tremaining: 2m 22s\n",
      "200:\ttotal: 11.8s\tremaining: 2m 15s\n",
      "300:\ttotal: 17.8s\tremaining: 2m 10s\n",
      "400:\ttotal: 24.2s\tremaining: 2m 6s\n",
      "500:\ttotal: 30.4s\tremaining: 2m 1s\n",
      "600:\ttotal: 37.4s\tremaining: 1m 58s\n",
      "700:\ttotal: 43.7s\tremaining: 1m 52s\n",
      "800:\ttotal: 49.7s\tremaining: 1m 45s\n",
      "900:\ttotal: 55.4s\tremaining: 1m 38s\n",
      "1000:\ttotal: 1m 1s\tremaining: 1m 32s\n",
      "1100:\ttotal: 1m 8s\tremaining: 1m 27s\n",
      "1200:\ttotal: 1m 14s\tremaining: 1m 20s\n",
      "1300:\ttotal: 1m 20s\tremaining: 1m 14s\n",
      "1400:\ttotal: 1m 25s\tremaining: 1m 7s\n",
      "1500:\ttotal: 1m 31s\tremaining: 1m\n",
      "1600:\ttotal: 1m 37s\tremaining: 54.9s\n",
      "1700:\ttotal: 1m 43s\tremaining: 48.7s\n",
      "1800:\ttotal: 1m 49s\tremaining: 42.4s\n",
      "1900:\ttotal: 1m 54s\tremaining: 36.1s\n",
      "2000:\ttotal: 2m\tremaining: 30s\n",
      "2100:\ttotal: 2m 5s\tremaining: 23.9s\n",
      "2200:\ttotal: 2m 11s\tremaining: 17.8s\n",
      "2300:\ttotal: 2m 16s\tremaining: 11.8s\n",
      "2400:\ttotal: 2m 22s\tremaining: 5.86s\n",
      "2499:\ttotal: 2m 27s\tremaining: 0us\n",
      "0:\ttotal: 72.2ms\tremaining: 3m\n",
      "100:\ttotal: 5.3s\tremaining: 2m 5s\n",
      "200:\ttotal: 10.5s\tremaining: 2m\n",
      "300:\ttotal: 15.9s\tremaining: 1m 56s\n",
      "400:\ttotal: 21.3s\tremaining: 1m 51s\n",
      "500:\ttotal: 26.8s\tremaining: 1m 47s\n",
      "600:\ttotal: 32.7s\tremaining: 1m 43s\n",
      "700:\ttotal: 38.9s\tremaining: 1m 39s\n",
      "800:\ttotal: 45.6s\tremaining: 1m 36s\n",
      "900:\ttotal: 51.3s\tremaining: 1m 31s\n",
      "1000:\ttotal: 56.8s\tremaining: 1m 24s\n",
      "1100:\ttotal: 1m 2s\tremaining: 1m 19s\n",
      "1200:\ttotal: 1m 7s\tremaining: 1m 13s\n",
      "1300:\ttotal: 1m 13s\tremaining: 1m 7s\n",
      "1400:\ttotal: 1m 18s\tremaining: 1m 1s\n",
      "1500:\ttotal: 1m 23s\tremaining: 55.7s\n",
      "1600:\ttotal: 1m 29s\tremaining: 50s\n",
      "1700:\ttotal: 1m 34s\tremaining: 44.3s\n",
      "1800:\ttotal: 1m 41s\tremaining: 39.3s\n",
      "1900:\ttotal: 1m 48s\tremaining: 34.2s\n",
      "2000:\ttotal: 1m 54s\tremaining: 28.6s\n",
      "2100:\ttotal: 2m 1s\tremaining: 23.1s\n",
      "2200:\ttotal: 2m 9s\tremaining: 17.5s\n",
      "2300:\ttotal: 2m 14s\tremaining: 11.7s\n",
      "2400:\ttotal: 2m 20s\tremaining: 5.78s\n",
      "2499:\ttotal: 2m 25s\tremaining: 0us\n",
      "0:\ttotal: 98.6ms\tremaining: 4m 6s\n",
      "100:\ttotal: 5.5s\tremaining: 2m 10s\n",
      "200:\ttotal: 11s\tremaining: 2m 5s\n",
      "300:\ttotal: 16.2s\tremaining: 1m 58s\n",
      "400:\ttotal: 21.6s\tremaining: 1m 53s\n",
      "500:\ttotal: 27.3s\tremaining: 1m 48s\n",
      "600:\ttotal: 33.3s\tremaining: 1m 45s\n",
      "700:\ttotal: 39.1s\tremaining: 1m 40s\n",
      "800:\ttotal: 45s\tremaining: 1m 35s\n",
      "900:\ttotal: 50.8s\tremaining: 1m 30s\n",
      "1000:\ttotal: 56.7s\tremaining: 1m 24s\n",
      "1100:\ttotal: 1m 3s\tremaining: 1m 20s\n",
      "1200:\ttotal: 1m 8s\tremaining: 1m 14s\n",
      "1300:\ttotal: 1m 14s\tremaining: 1m 8s\n",
      "1400:\ttotal: 1m 20s\tremaining: 1m 3s\n",
      "1500:\ttotal: 1m 25s\tremaining: 57.2s\n",
      "1600:\ttotal: 1m 31s\tremaining: 51.5s\n",
      "1700:\ttotal: 1m 37s\tremaining: 45.8s\n",
      "1800:\ttotal: 1m 43s\tremaining: 40.1s\n",
      "1900:\ttotal: 1m 49s\tremaining: 34.7s\n",
      "2000:\ttotal: 1m 56s\tremaining: 29s\n",
      "2100:\ttotal: 2m 2s\tremaining: 23.2s\n",
      "2200:\ttotal: 2m 8s\tremaining: 17.5s\n",
      "2300:\ttotal: 2m 14s\tremaining: 11.6s\n",
      "2400:\ttotal: 2m 20s\tremaining: 5.77s\n",
      "2499:\ttotal: 2m 25s\tremaining: 0us\n",
      "0:\ttotal: 77.1ms\tremaining: 3m 12s\n",
      "100:\ttotal: 6.51s\tremaining: 2m 34s\n",
      "200:\ttotal: 13.1s\tremaining: 2m 29s\n",
      "300:\ttotal: 19.4s\tremaining: 2m 21s\n",
      "400:\ttotal: 25.4s\tremaining: 2m 12s\n",
      "500:\ttotal: 31.4s\tremaining: 2m 5s\n",
      "600:\ttotal: 37.6s\tremaining: 1m 58s\n",
      "700:\ttotal: 44.2s\tremaining: 1m 53s\n",
      "800:\ttotal: 50.2s\tremaining: 1m 46s\n",
      "900:\ttotal: 56.4s\tremaining: 1m 40s\n",
      "1000:\ttotal: 1m 2s\tremaining: 1m 33s\n",
      "1100:\ttotal: 1m 8s\tremaining: 1m 27s\n",
      "1200:\ttotal: 1m 15s\tremaining: 1m 21s\n",
      "1300:\ttotal: 1m 21s\tremaining: 1m 15s\n",
      "1400:\ttotal: 1m 27s\tremaining: 1m 8s\n",
      "1500:\ttotal: 1m 34s\tremaining: 1m 2s\n",
      "1600:\ttotal: 1m 40s\tremaining: 56.5s\n",
      "1700:\ttotal: 1m 47s\tremaining: 50.4s\n",
      "1800:\ttotal: 1m 54s\tremaining: 44.4s\n",
      "1900:\ttotal: 2m\tremaining: 38.1s\n",
      "2000:\ttotal: 2m 7s\tremaining: 31.7s\n",
      "2100:\ttotal: 2m 13s\tremaining: 25.3s\n",
      "2200:\ttotal: 2m 19s\tremaining: 18.9s\n",
      "2300:\ttotal: 2m 25s\tremaining: 12.6s\n",
      "2400:\ttotal: 2m 31s\tremaining: 6.26s\n",
      "2499:\ttotal: 2m 37s\tremaining: 0us\n",
      "0:\ttotal: 118ms\tremaining: 4m 55s\n",
      "100:\ttotal: 6.04s\tremaining: 2m 23s\n",
      "200:\ttotal: 12.2s\tremaining: 2m 19s\n",
      "300:\ttotal: 18.1s\tremaining: 2m 12s\n",
      "400:\ttotal: 23.9s\tremaining: 2m 5s\n",
      "500:\ttotal: 29.9s\tremaining: 1m 59s\n",
      "600:\ttotal: 36.3s\tremaining: 1m 54s\n",
      "700:\ttotal: 42.9s\tremaining: 1m 50s\n",
      "800:\ttotal: 48.7s\tremaining: 1m 43s\n",
      "900:\ttotal: 54.7s\tremaining: 1m 36s\n",
      "1000:\ttotal: 1m\tremaining: 1m 31s\n",
      "1100:\ttotal: 1m 6s\tremaining: 1m 24s\n",
      "1200:\ttotal: 1m 12s\tremaining: 1m 18s\n",
      "1300:\ttotal: 1m 17s\tremaining: 1m 11s\n",
      "1400:\ttotal: 1m 23s\tremaining: 1m 5s\n",
      "1500:\ttotal: 1m 29s\tremaining: 59.5s\n",
      "1600:\ttotal: 1m 34s\tremaining: 53.3s\n",
      "1700:\ttotal: 1m 40s\tremaining: 47.2s\n",
      "1800:\ttotal: 1m 45s\tremaining: 41.1s\n",
      "1900:\ttotal: 1m 51s\tremaining: 35.2s\n",
      "2000:\ttotal: 1m 58s\tremaining: 29.5s\n",
      "2100:\ttotal: 2m 3s\tremaining: 23.5s\n",
      "2200:\ttotal: 2m 9s\tremaining: 17.6s\n",
      "2300:\ttotal: 2m 14s\tremaining: 11.6s\n",
      "2400:\ttotal: 2m 20s\tremaining: 5.79s\n",
      "2499:\ttotal: 2m 26s\tremaining: 0us\n",
      "0:\ttotal: 73ms\tremaining: 3m 2s\n",
      "100:\ttotal: 6.57s\tremaining: 2m 36s\n",
      "200:\ttotal: 12.6s\tremaining: 2m 23s\n",
      "300:\ttotal: 18.8s\tremaining: 2m 17s\n",
      "400:\ttotal: 25.3s\tremaining: 2m 12s\n",
      "500:\ttotal: 31.6s\tremaining: 2m 6s\n",
      "600:\ttotal: 37.8s\tremaining: 1m 59s\n",
      "700:\ttotal: 43.6s\tremaining: 1m 51s\n",
      "800:\ttotal: 49.4s\tremaining: 1m 44s\n",
      "900:\ttotal: 55.2s\tremaining: 1m 37s\n",
      "1000:\ttotal: 1m\tremaining: 1m 31s\n",
      "1100:\ttotal: 1m 6s\tremaining: 1m 24s\n",
      "1200:\ttotal: 1m 12s\tremaining: 1m 18s\n",
      "1300:\ttotal: 1m 19s\tremaining: 1m 12s\n",
      "1400:\ttotal: 1m 25s\tremaining: 1m 6s\n",
      "1500:\ttotal: 1m 31s\tremaining: 1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600:\ttotal: 1m 37s\tremaining: 54.7s\n",
      "1700:\ttotal: 1m 44s\tremaining: 49.1s\n",
      "1800:\ttotal: 1m 50s\tremaining: 43s\n",
      "1900:\ttotal: 1m 56s\tremaining: 36.8s\n",
      "2000:\ttotal: 2m 2s\tremaining: 30.6s\n",
      "2100:\ttotal: 2m 9s\tremaining: 24.5s\n",
      "2200:\ttotal: 2m 15s\tremaining: 18.4s\n",
      "2300:\ttotal: 2m 21s\tremaining: 12.2s\n",
      "2400:\ttotal: 2m 27s\tremaining: 6.06s\n",
      "2499:\ttotal: 2m 32s\tremaining: 0us\n",
      "0:\ttotal: 70.1ms\tremaining: 2m 55s\n",
      "100:\ttotal: 6.23s\tremaining: 2m 27s\n",
      "200:\ttotal: 12.6s\tremaining: 2m 23s\n",
      "300:\ttotal: 18.8s\tremaining: 2m 17s\n",
      "400:\ttotal: 24.8s\tremaining: 2m 9s\n",
      "500:\ttotal: 31s\tremaining: 2m 3s\n",
      "600:\ttotal: 36.9s\tremaining: 1m 56s\n",
      "700:\ttotal: 42.8s\tremaining: 1m 49s\n",
      "800:\ttotal: 48.8s\tremaining: 1m 43s\n",
      "900:\ttotal: 54.7s\tremaining: 1m 36s\n",
      "1000:\ttotal: 1m\tremaining: 1m 30s\n",
      "1100:\ttotal: 1m 6s\tremaining: 1m 24s\n",
      "1200:\ttotal: 1m 12s\tremaining: 1m 18s\n",
      "1300:\ttotal: 1m 18s\tremaining: 1m 11s\n",
      "1400:\ttotal: 1m 23s\tremaining: 1m 5s\n",
      "1500:\ttotal: 1m 29s\tremaining: 59.8s\n",
      "1600:\ttotal: 1m 35s\tremaining: 53.8s\n",
      "1700:\ttotal: 1m 41s\tremaining: 47.8s\n",
      "1800:\ttotal: 1m 47s\tremaining: 41.7s\n",
      "1900:\ttotal: 1m 53s\tremaining: 35.6s\n",
      "2000:\ttotal: 1m 59s\tremaining: 29.7s\n",
      "2100:\ttotal: 2m 5s\tremaining: 23.8s\n",
      "2200:\ttotal: 2m 11s\tremaining: 17.8s\n",
      "2300:\ttotal: 2m 17s\tremaining: 11.9s\n",
      "2400:\ttotal: 2m 23s\tremaining: 5.91s\n",
      "2499:\ttotal: 2m 29s\tremaining: 0us\n",
      "0:\ttotal: 55.7ms\tremaining: 2m 19s\n",
      "100:\ttotal: 5.92s\tremaining: 2m 20s\n",
      "200:\ttotal: 11.7s\tremaining: 2m 14s\n",
      "300:\ttotal: 17.6s\tremaining: 2m 8s\n",
      "400:\ttotal: 23.7s\tremaining: 2m 3s\n",
      "500:\ttotal: 29.7s\tremaining: 1m 58s\n",
      "600:\ttotal: 35.8s\tremaining: 1m 53s\n",
      "700:\ttotal: 41.8s\tremaining: 1m 47s\n",
      "800:\ttotal: 47.9s\tremaining: 1m 41s\n",
      "900:\ttotal: 53.8s\tremaining: 1m 35s\n",
      "1000:\ttotal: 59.5s\tremaining: 1m 29s\n",
      "1100:\ttotal: 1m 5s\tremaining: 1m 23s\n",
      "1200:\ttotal: 1m 11s\tremaining: 1m 17s\n",
      "1300:\ttotal: 1m 17s\tremaining: 1m 11s\n",
      "1400:\ttotal: 1m 23s\tremaining: 1m 5s\n",
      "1500:\ttotal: 1m 30s\tremaining: 60s\n",
      "1600:\ttotal: 1m 36s\tremaining: 54s\n",
      "1700:\ttotal: 1m 42s\tremaining: 48.2s\n",
      "1800:\ttotal: 1m 48s\tremaining: 42.1s\n",
      "1900:\ttotal: 1m 54s\tremaining: 36s\n",
      "2000:\ttotal: 2m\tremaining: 30s\n",
      "2100:\ttotal: 2m 6s\tremaining: 23.9s\n",
      "2200:\ttotal: 2m 11s\tremaining: 17.9s\n",
      "2300:\ttotal: 2m 17s\tremaining: 11.9s\n",
      "2400:\ttotal: 2m 23s\tremaining: 5.93s\n",
      "2499:\ttotal: 2m 29s\tremaining: 0us\n",
      "0:\ttotal: 74.9ms\tremaining: 3m 7s\n",
      "100:\ttotal: 6.1s\tremaining: 2m 24s\n",
      "200:\ttotal: 12.3s\tremaining: 2m 20s\n",
      "300:\ttotal: 18.1s\tremaining: 2m 12s\n",
      "400:\ttotal: 24.1s\tremaining: 2m 6s\n",
      "500:\ttotal: 30s\tremaining: 1m 59s\n",
      "600:\ttotal: 35.8s\tremaining: 1m 53s\n",
      "700:\ttotal: 41.9s\tremaining: 1m 47s\n",
      "800:\ttotal: 47.9s\tremaining: 1m 41s\n",
      "900:\ttotal: 53.8s\tremaining: 1m 35s\n",
      "1000:\ttotal: 60s\tremaining: 1m 29s\n",
      "1100:\ttotal: 1m 5s\tremaining: 1m 23s\n",
      "1200:\ttotal: 1m 11s\tremaining: 1m 17s\n",
      "1300:\ttotal: 1m 17s\tremaining: 1m 11s\n",
      "1400:\ttotal: 1m 23s\tremaining: 1m 5s\n",
      "1500:\ttotal: 1m 29s\tremaining: 59.5s\n",
      "1600:\ttotal: 1m 35s\tremaining: 53.4s\n",
      "1700:\ttotal: 1m 40s\tremaining: 47.4s\n",
      "1800:\ttotal: 1m 46s\tremaining: 41.5s\n",
      "1900:\ttotal: 1m 52s\tremaining: 35.5s\n",
      "2000:\ttotal: 1m 58s\tremaining: 29.6s\n",
      "2100:\ttotal: 2m 4s\tremaining: 23.7s\n",
      "2200:\ttotal: 2m 10s\tremaining: 17.7s\n",
      "2300:\ttotal: 2m 16s\tremaining: 11.8s\n",
      "2400:\ttotal: 2m 22s\tremaining: 5.86s\n",
      "2499:\ttotal: 2m 28s\tremaining: 0us\n",
      "0:\ttotal: 55.8ms\tremaining: 2m 19s\n",
      "100:\ttotal: 5.68s\tremaining: 2m 15s\n",
      "200:\ttotal: 11.7s\tremaining: 2m 13s\n",
      "300:\ttotal: 18s\tremaining: 2m 11s\n",
      "400:\ttotal: 24s\tremaining: 2m 5s\n",
      "500:\ttotal: 30.5s\tremaining: 2m 1s\n",
      "600:\ttotal: 36.6s\tremaining: 1m 55s\n",
      "700:\ttotal: 42.3s\tremaining: 1m 48s\n",
      "800:\ttotal: 48.5s\tremaining: 1m 42s\n",
      "900:\ttotal: 54.5s\tremaining: 1m 36s\n",
      "1000:\ttotal: 1m\tremaining: 1m 30s\n",
      "1100:\ttotal: 1m 5s\tremaining: 1m 23s\n",
      "1200:\ttotal: 1m 10s\tremaining: 1m 16s\n",
      "1300:\ttotal: 1m 16s\tremaining: 1m 10s\n",
      "1400:\ttotal: 1m 22s\tremaining: 1m 4s\n",
      "1500:\ttotal: 1m 27s\tremaining: 58.5s\n",
      "1600:\ttotal: 1m 34s\tremaining: 52.9s\n",
      "1700:\ttotal: 1m 40s\tremaining: 47.2s\n",
      "1800:\ttotal: 1m 46s\tremaining: 41.4s\n",
      "1900:\ttotal: 1m 52s\tremaining: 35.4s\n",
      "2000:\ttotal: 1m 58s\tremaining: 29.5s\n",
      "2100:\ttotal: 2m 4s\tremaining: 23.6s\n",
      "2200:\ttotal: 2m 9s\tremaining: 17.6s\n",
      "2300:\ttotal: 2m 15s\tremaining: 11.7s\n",
      "2400:\ttotal: 2m 21s\tremaining: 5.83s\n",
      "2499:\ttotal: 2m 27s\tremaining: 0us\n",
      "0:\ttotal: 68.7ms\tremaining: 2m 51s\n",
      "100:\ttotal: 6.22s\tremaining: 2m 27s\n",
      "200:\ttotal: 12.5s\tremaining: 2m 22s\n",
      "300:\ttotal: 18.6s\tremaining: 2m 16s\n",
      "400:\ttotal: 24.8s\tremaining: 2m 9s\n",
      "500:\ttotal: 30.9s\tremaining: 2m 3s\n",
      "600:\ttotal: 36.8s\tremaining: 1m 56s\n",
      "700:\ttotal: 42.7s\tremaining: 1m 49s\n",
      "800:\ttotal: 48.7s\tremaining: 1m 43s\n",
      "900:\ttotal: 54.4s\tremaining: 1m 36s\n",
      "1000:\ttotal: 1m\tremaining: 1m 30s\n",
      "1100:\ttotal: 1m 6s\tremaining: 1m 23s\n",
      "1200:\ttotal: 1m 11s\tremaining: 1m 17s\n",
      "1300:\ttotal: 1m 18s\tremaining: 1m 11s\n",
      "1400:\ttotal: 1m 24s\tremaining: 1m 5s\n",
      "1500:\ttotal: 1m 30s\tremaining: 59.9s\n",
      "1600:\ttotal: 1m 36s\tremaining: 53.9s\n",
      "1700:\ttotal: 1m 42s\tremaining: 48s\n",
      "1800:\ttotal: 1m 48s\tremaining: 42.1s\n",
      "1900:\ttotal: 1m 54s\tremaining: 36s\n",
      "2000:\ttotal: 2m\tremaining: 30s\n",
      "2100:\ttotal: 2m 6s\tremaining: 24s\n",
      "2200:\ttotal: 2m 12s\tremaining: 18s\n",
      "2300:\ttotal: 2m 18s\tremaining: 12s\n",
      "2400:\ttotal: 2m 25s\tremaining: 5.99s\n",
      "2499:\ttotal: 2m 31s\tremaining: 0us\n",
      "0:\ttotal: 89.8ms\tremaining: 3m 44s\n",
      "100:\ttotal: 6.19s\tremaining: 2m 26s\n",
      "200:\ttotal: 11.9s\tremaining: 2m 16s\n",
      "300:\ttotal: 17.9s\tremaining: 2m 10s\n",
      "400:\ttotal: 25.5s\tremaining: 2m 13s\n",
      "500:\ttotal: 31.5s\tremaining: 2m 5s\n",
      "600:\ttotal: 37.5s\tremaining: 1m 58s\n",
      "700:\ttotal: 43.7s\tremaining: 1m 52s\n",
      "800:\ttotal: 50s\tremaining: 1m 46s\n",
      "900:\ttotal: 56.4s\tremaining: 1m 40s\n",
      "1000:\ttotal: 1m 2s\tremaining: 1m 33s\n",
      "1100:\ttotal: 1m 8s\tremaining: 1m 27s\n",
      "1200:\ttotal: 1m 14s\tremaining: 1m 20s\n",
      "1300:\ttotal: 1m 21s\tremaining: 1m 14s\n",
      "1400:\ttotal: 1m 27s\tremaining: 1m 8s\n",
      "1500:\ttotal: 1m 33s\tremaining: 1m 2s\n",
      "1600:\ttotal: 1m 39s\tremaining: 55.7s\n",
      "1700:\ttotal: 1m 45s\tremaining: 49.5s\n",
      "1800:\ttotal: 1m 51s\tremaining: 43.3s\n",
      "1900:\ttotal: 1m 57s\tremaining: 37s\n",
      "2000:\ttotal: 2m 3s\tremaining: 30.9s\n",
      "2100:\ttotal: 2m 9s\tremaining: 24.7s\n",
      "2200:\ttotal: 2m 15s\tremaining: 18.5s\n",
      "2300:\ttotal: 2m 21s\tremaining: 12.3s\n",
      "2400:\ttotal: 2m 28s\tremaining: 6.12s\n",
      "2499:\ttotal: 2m 34s\tremaining: 0us\n",
      "0:\ttotal: 75.3ms\tremaining: 3m 8s\n",
      "100:\ttotal: 6.54s\tremaining: 2m 35s\n",
      "200:\ttotal: 12.7s\tremaining: 2m 25s\n",
      "300:\ttotal: 18.9s\tremaining: 2m 18s\n",
      "400:\ttotal: 25.1s\tremaining: 2m 11s\n",
      "500:\ttotal: 31.3s\tremaining: 2m 4s\n",
      "600:\ttotal: 37.3s\tremaining: 1m 57s\n",
      "700:\ttotal: 43.5s\tremaining: 1m 51s\n",
      "800:\ttotal: 49.6s\tremaining: 1m 45s\n",
      "900:\ttotal: 56.2s\tremaining: 1m 39s\n",
      "1000:\ttotal: 1m 2s\tremaining: 1m 33s\n",
      "1100:\ttotal: 1m 8s\tremaining: 1m 27s\n",
      "1200:\ttotal: 1m 14s\tremaining: 1m 20s\n",
      "1300:\ttotal: 1m 20s\tremaining: 1m 14s\n",
      "1400:\ttotal: 1m 26s\tremaining: 1m 8s\n",
      "1500:\ttotal: 1m 32s\tremaining: 1m 1s\n",
      "1600:\ttotal: 1m 38s\tremaining: 55.5s\n",
      "1700:\ttotal: 1m 45s\tremaining: 49.3s\n",
      "1800:\ttotal: 1m 51s\tremaining: 43.2s\n",
      "1900:\ttotal: 1m 57s\tremaining: 37s\n",
      "2000:\ttotal: 2m 3s\tremaining: 30.9s\n",
      "2100:\ttotal: 2m 9s\tremaining: 24.7s\n",
      "2200:\ttotal: 2m 16s\tremaining: 18.5s\n",
      "2300:\ttotal: 2m 22s\tremaining: 12.4s\n",
      "2400:\ttotal: 2m 29s\tremaining: 6.15s\n",
      "2499:\ttotal: 2m 35s\tremaining: 0us\n",
      "0:\ttotal: 68.2ms\tremaining: 2m 50s\n",
      "100:\ttotal: 6.08s\tremaining: 2m 24s\n",
      "200:\ttotal: 12.1s\tremaining: 2m 17s\n",
      "300:\ttotal: 18.5s\tremaining: 2m 15s\n",
      "400:\ttotal: 24.7s\tremaining: 2m 9s\n",
      "500:\ttotal: 30.9s\tremaining: 2m 3s\n",
      "600:\ttotal: 37.3s\tremaining: 1m 57s\n",
      "700:\ttotal: 43.3s\tremaining: 1m 51s\n",
      "800:\ttotal: 49.2s\tremaining: 1m 44s\n",
      "900:\ttotal: 55.5s\tremaining: 1m 38s\n",
      "1000:\ttotal: 1m 1s\tremaining: 1m 32s\n",
      "1100:\ttotal: 1m 7s\tremaining: 1m 26s\n",
      "1200:\ttotal: 1m 14s\tremaining: 1m 20s\n",
      "1300:\ttotal: 1m 20s\tremaining: 1m 13s\n",
      "1400:\ttotal: 1m 26s\tremaining: 1m 7s\n",
      "1500:\ttotal: 1m 32s\tremaining: 1m 1s\n",
      "1600:\ttotal: 1m 39s\tremaining: 55.7s\n",
      "1700:\ttotal: 1m 45s\tremaining: 49.4s\n",
      "1800:\ttotal: 1m 51s\tremaining: 43.2s\n",
      "1900:\ttotal: 1m 57s\tremaining: 37.1s\n",
      "2000:\ttotal: 2m 4s\tremaining: 30.9s\n",
      "2100:\ttotal: 2m 10s\tremaining: 24.7s\n",
      "2200:\ttotal: 2m 16s\tremaining: 18.5s\n",
      "2300:\ttotal: 2m 23s\tremaining: 12.4s\n",
      "2400:\ttotal: 2m 29s\tremaining: 6.16s\n",
      "2499:\ttotal: 2m 35s\tremaining: 0us\n",
      "0:\ttotal: 102ms\tremaining: 4m 15s\n",
      "100:\ttotal: 5.63s\tremaining: 2m 13s\n",
      "200:\ttotal: 11.2s\tremaining: 2m 7s\n",
      "300:\ttotal: 16.6s\tremaining: 2m 1s\n",
      "400:\ttotal: 21.9s\tremaining: 1m 54s\n",
      "500:\ttotal: 27.2s\tremaining: 1m 48s\n",
      "600:\ttotal: 32.6s\tremaining: 1m 43s\n",
      "700:\ttotal: 38s\tremaining: 1m 37s\n",
      "800:\ttotal: 43.4s\tremaining: 1m 32s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900:\ttotal: 48.8s\tremaining: 1m 26s\n",
      "1000:\ttotal: 54.1s\tremaining: 1m 21s\n",
      "1100:\ttotal: 59.6s\tremaining: 1m 15s\n",
      "1200:\ttotal: 1m 5s\tremaining: 1m 10s\n",
      "1300:\ttotal: 1m 10s\tremaining: 1m 4s\n",
      "1400:\ttotal: 1m 15s\tremaining: 59.4s\n",
      "1500:\ttotal: 1m 21s\tremaining: 54.2s\n",
      "1600:\ttotal: 1m 27s\tremaining: 49s\n",
      "1700:\ttotal: 1m 33s\tremaining: 43.7s\n",
      "1800:\ttotal: 1m 39s\tremaining: 38.5s\n",
      "1900:\ttotal: 1m 45s\tremaining: 33.2s\n",
      "2000:\ttotal: 1m 51s\tremaining: 27.7s\n",
      "2100:\ttotal: 1m 56s\tremaining: 22.2s\n",
      "2200:\ttotal: 2m 2s\tremaining: 16.7s\n",
      "2300:\ttotal: 2m 8s\tremaining: 11.1s\n",
      "2400:\ttotal: 2m 15s\tremaining: 5.59s\n",
      "2499:\ttotal: 2m 21s\tremaining: 0us\n",
      "0:\ttotal: 61.5ms\tremaining: 2m 33s\n",
      "100:\ttotal: 5.77s\tremaining: 2m 17s\n",
      "200:\ttotal: 11.7s\tremaining: 2m 13s\n",
      "300:\ttotal: 18.6s\tremaining: 2m 15s\n",
      "400:\ttotal: 25s\tremaining: 2m 10s\n",
      "500:\ttotal: 31.3s\tremaining: 2m 5s\n",
      "600:\ttotal: 38s\tremaining: 2m\n",
      "700:\ttotal: 44.1s\tremaining: 1m 53s\n",
      "800:\ttotal: 50.2s\tremaining: 1m 46s\n",
      "900:\ttotal: 55.9s\tremaining: 1m 39s\n",
      "1000:\ttotal: 1m 1s\tremaining: 1m 32s\n",
      "1100:\ttotal: 1m 8s\tremaining: 1m 26s\n",
      "1200:\ttotal: 1m 14s\tremaining: 1m 20s\n",
      "1300:\ttotal: 1m 20s\tremaining: 1m 13s\n",
      "1400:\ttotal: 1m 26s\tremaining: 1m 7s\n",
      "1500:\ttotal: 1m 31s\tremaining: 1m 1s\n",
      "1600:\ttotal: 1m 37s\tremaining: 55s\n",
      "1700:\ttotal: 1m 43s\tremaining: 48.8s\n",
      "1800:\ttotal: 1m 49s\tremaining: 42.6s\n",
      "1900:\ttotal: 1m 55s\tremaining: 36.5s\n",
      "2000:\ttotal: 2m 2s\tremaining: 30.4s\n",
      "2100:\ttotal: 2m 7s\tremaining: 24.2s\n",
      "2200:\ttotal: 2m 13s\tremaining: 18.1s\n",
      "2300:\ttotal: 2m 19s\tremaining: 12s\n",
      "2400:\ttotal: 2m 25s\tremaining: 5.98s\n",
      "2499:\ttotal: 2m 31s\tremaining: 0us\n",
      "0:\ttotal: 113ms\tremaining: 4m 42s\n",
      "100:\ttotal: 6.43s\tremaining: 2m 32s\n",
      "200:\ttotal: 13.7s\tremaining: 2m 36s\n",
      "300:\ttotal: 20.4s\tremaining: 2m 29s\n",
      "400:\ttotal: 26.9s\tremaining: 2m 20s\n",
      "500:\ttotal: 34.3s\tremaining: 2m 16s\n",
      "600:\ttotal: 41.1s\tremaining: 2m 9s\n",
      "700:\ttotal: 48s\tremaining: 2m 3s\n",
      "800:\ttotal: 54.2s\tremaining: 1m 54s\n",
      "900:\ttotal: 1m\tremaining: 1m 47s\n",
      "1000:\ttotal: 1m 6s\tremaining: 1m 39s\n",
      "1100:\ttotal: 1m 13s\tremaining: 1m 32s\n",
      "1200:\ttotal: 1m 18s\tremaining: 1m 25s\n",
      "1300:\ttotal: 1m 24s\tremaining: 1m 17s\n",
      "1400:\ttotal: 1m 30s\tremaining: 1m 10s\n",
      "1500:\ttotal: 1m 35s\tremaining: 1m 3s\n",
      "1600:\ttotal: 1m 41s\tremaining: 57.2s\n",
      "1700:\ttotal: 1m 47s\tremaining: 50.6s\n",
      "1800:\ttotal: 1m 54s\tremaining: 44.3s\n",
      "1900:\ttotal: 2m\tremaining: 38s\n",
      "2000:\ttotal: 2m 6s\tremaining: 31.6s\n",
      "2100:\ttotal: 2m 12s\tremaining: 25.2s\n",
      "2200:\ttotal: 2m 18s\tremaining: 18.8s\n",
      "2300:\ttotal: 2m 24s\tremaining: 12.5s\n",
      "2400:\ttotal: 2m 30s\tremaining: 6.2s\n",
      "2499:\ttotal: 2m 36s\tremaining: 0us\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9806  \u001b[0m | \u001b[0m 0.4224  \u001b[0m | \u001b[0m 7.602   \u001b[0m | \u001b[0m 0.01011 \u001b[0m |\n",
      "0:\ttotal: 13.6ms\tremaining: 34s\n",
      "100:\ttotal: 1.15s\tremaining: 27.4s\n",
      "200:\ttotal: 2.43s\tremaining: 27.8s\n",
      "300:\ttotal: 3.68s\tremaining: 26.9s\n",
      "400:\ttotal: 4.78s\tremaining: 25s\n",
      "500:\ttotal: 5.86s\tremaining: 23.4s\n",
      "600:\ttotal: 6.95s\tremaining: 22s\n",
      "700:\ttotal: 8.02s\tremaining: 20.6s\n",
      "800:\ttotal: 9.07s\tremaining: 19.3s\n",
      "900:\ttotal: 10.1s\tremaining: 18s\n",
      "1000:\ttotal: 11.2s\tremaining: 16.7s\n",
      "1100:\ttotal: 12.4s\tremaining: 15.7s\n",
      "1200:\ttotal: 13.5s\tremaining: 14.6s\n",
      "1300:\ttotal: 14.5s\tremaining: 13.4s\n",
      "1400:\ttotal: 15.6s\tremaining: 12.2s\n",
      "1500:\ttotal: 16.6s\tremaining: 11.1s\n",
      "1600:\ttotal: 17.7s\tremaining: 9.96s\n",
      "1700:\ttotal: 18.8s\tremaining: 8.84s\n",
      "1800:\ttotal: 19.9s\tremaining: 7.72s\n",
      "1900:\ttotal: 21s\tremaining: 6.61s\n",
      "2000:\ttotal: 22.1s\tremaining: 5.5s\n",
      "2100:\ttotal: 23.2s\tremaining: 4.41s\n",
      "2200:\ttotal: 24.4s\tremaining: 3.32s\n",
      "2300:\ttotal: 25.6s\tremaining: 2.22s\n",
      "2400:\ttotal: 26.8s\tremaining: 1.1s\n",
      "2499:\ttotal: 27.9s\tremaining: 0us\n",
      "0:\ttotal: 12.4ms\tremaining: 31s\n",
      "100:\ttotal: 1.24s\tremaining: 29.5s\n",
      "200:\ttotal: 2.37s\tremaining: 27.1s\n",
      "300:\ttotal: 3.51s\tremaining: 25.7s\n",
      "400:\ttotal: 4.66s\tremaining: 24.4s\n",
      "500:\ttotal: 5.89s\tremaining: 23.5s\n",
      "600:\ttotal: 7s\tremaining: 22.1s\n",
      "700:\ttotal: 8.09s\tremaining: 20.8s\n",
      "800:\ttotal: 9.23s\tremaining: 19.6s\n",
      "900:\ttotal: 10.3s\tremaining: 18.3s\n",
      "1000:\ttotal: 11.4s\tremaining: 17.1s\n",
      "1100:\ttotal: 12.5s\tremaining: 15.9s\n",
      "1200:\ttotal: 13.7s\tremaining: 14.8s\n",
      "1300:\ttotal: 14.9s\tremaining: 13.7s\n",
      "1400:\ttotal: 16s\tremaining: 12.5s\n",
      "1500:\ttotal: 17.2s\tremaining: 11.4s\n",
      "1600:\ttotal: 18.4s\tremaining: 10.3s\n",
      "1700:\ttotal: 19.4s\tremaining: 9.11s\n",
      "1800:\ttotal: 20.5s\tremaining: 7.95s\n",
      "1900:\ttotal: 21.6s\tremaining: 6.81s\n",
      "2000:\ttotal: 22.6s\tremaining: 5.65s\n",
      "2100:\ttotal: 23.7s\tremaining: 4.5s\n",
      "2200:\ttotal: 24.7s\tremaining: 3.36s\n",
      "2300:\ttotal: 25.7s\tremaining: 2.23s\n",
      "2400:\ttotal: 26.8s\tremaining: 1.1s\n",
      "2499:\ttotal: 27.8s\tremaining: 0us\n",
      "0:\ttotal: 11.4ms\tremaining: 28.5s\n",
      "100:\ttotal: 1.06s\tremaining: 25.3s\n",
      "200:\ttotal: 2.13s\tremaining: 24.4s\n",
      "300:\ttotal: 3.19s\tremaining: 23.3s\n",
      "400:\ttotal: 4.27s\tremaining: 22.4s\n",
      "500:\ttotal: 5.36s\tremaining: 21.4s\n",
      "600:\ttotal: 6.41s\tremaining: 20.3s\n",
      "700:\ttotal: 7.47s\tremaining: 19.2s\n",
      "800:\ttotal: 8.49s\tremaining: 18s\n",
      "900:\ttotal: 9.52s\tremaining: 16.9s\n",
      "1000:\ttotal: 10.6s\tremaining: 15.9s\n",
      "1100:\ttotal: 11.6s\tremaining: 14.8s\n",
      "1200:\ttotal: 12.7s\tremaining: 13.7s\n",
      "1300:\ttotal: 13.7s\tremaining: 12.7s\n",
      "1400:\ttotal: 14.8s\tremaining: 11.6s\n",
      "1500:\ttotal: 15.9s\tremaining: 10.6s\n",
      "1600:\ttotal: 17s\tremaining: 9.55s\n",
      "1700:\ttotal: 18.1s\tremaining: 8.48s\n",
      "1800:\ttotal: 19.1s\tremaining: 7.42s\n",
      "1900:\ttotal: 20.3s\tremaining: 6.38s\n",
      "2000:\ttotal: 21.4s\tremaining: 5.34s\n",
      "2100:\ttotal: 22.6s\tremaining: 4.3s\n",
      "2200:\ttotal: 23.8s\tremaining: 3.23s\n",
      "2300:\ttotal: 24.9s\tremaining: 2.15s\n",
      "2400:\ttotal: 26s\tremaining: 1.07s\n",
      "2499:\ttotal: 27.2s\tremaining: 0us\n",
      "0:\ttotal: 18.4ms\tremaining: 46.1s\n",
      "100:\ttotal: 1.06s\tremaining: 25.1s\n",
      "200:\ttotal: 2.18s\tremaining: 24.9s\n",
      "300:\ttotal: 3.4s\tremaining: 24.8s\n",
      "400:\ttotal: 4.77s\tremaining: 25s\n",
      "500:\ttotal: 6.05s\tremaining: 24.1s\n",
      "600:\ttotal: 7.28s\tremaining: 23s\n",
      "700:\ttotal: 8.81s\tremaining: 22.6s\n",
      "800:\ttotal: 10s\tremaining: 21.3s\n",
      "900:\ttotal: 11.1s\tremaining: 19.8s\n",
      "1000:\ttotal: 12.3s\tremaining: 18.4s\n",
      "1100:\ttotal: 13.5s\tremaining: 17.2s\n",
      "1200:\ttotal: 14.9s\tremaining: 16.2s\n",
      "1300:\ttotal: 16.9s\tremaining: 15.5s\n",
      "1400:\ttotal: 18.5s\tremaining: 14.5s\n",
      "1500:\ttotal: 20.1s\tremaining: 13.4s\n",
      "1600:\ttotal: 21.8s\tremaining: 12.3s\n",
      "1700:\ttotal: 23.2s\tremaining: 10.9s\n",
      "1800:\ttotal: 24.3s\tremaining: 9.43s\n",
      "1900:\ttotal: 25.5s\tremaining: 8.03s\n",
      "2000:\ttotal: 26.6s\tremaining: 6.63s\n",
      "2100:\ttotal: 27.8s\tremaining: 5.28s\n",
      "2200:\ttotal: 28.9s\tremaining: 3.93s\n",
      "2300:\ttotal: 30.1s\tremaining: 2.61s\n",
      "2400:\ttotal: 31.2s\tremaining: 1.29s\n",
      "2499:\ttotal: 32.3s\tremaining: 0us\n",
      "0:\ttotal: 19.9ms\tremaining: 49.6s\n",
      "100:\ttotal: 1.1s\tremaining: 26.2s\n",
      "200:\ttotal: 2.22s\tremaining: 25.4s\n",
      "300:\ttotal: 3.33s\tremaining: 24.4s\n",
      "400:\ttotal: 4.58s\tremaining: 24s\n",
      "500:\ttotal: 5.71s\tremaining: 22.8s\n",
      "600:\ttotal: 6.8s\tremaining: 21.5s\n",
      "700:\ttotal: 7.91s\tremaining: 20.3s\n",
      "800:\ttotal: 8.99s\tremaining: 19.1s\n",
      "900:\ttotal: 10s\tremaining: 17.8s\n",
      "1000:\ttotal: 11.2s\tremaining: 16.8s\n",
      "1100:\ttotal: 12.4s\tremaining: 15.8s\n",
      "1200:\ttotal: 13.5s\tremaining: 14.6s\n",
      "1300:\ttotal: 14.5s\tremaining: 13.3s\n",
      "1400:\ttotal: 15.8s\tremaining: 12.4s\n",
      "1500:\ttotal: 16.9s\tremaining: 11.2s\n",
      "1600:\ttotal: 18s\tremaining: 10.1s\n",
      "1700:\ttotal: 19.2s\tremaining: 9s\n",
      "1800:\ttotal: 20.2s\tremaining: 7.85s\n",
      "1900:\ttotal: 21.3s\tremaining: 6.7s\n",
      "2000:\ttotal: 22.3s\tremaining: 5.56s\n",
      "2100:\ttotal: 23.3s\tremaining: 4.43s\n",
      "2200:\ttotal: 24.4s\tremaining: 3.31s\n",
      "2300:\ttotal: 25.4s\tremaining: 2.2s\n",
      "2400:\ttotal: 26.5s\tremaining: 1.09s\n",
      "2499:\ttotal: 27.5s\tremaining: 0us\n",
      "0:\ttotal: 12.1ms\tremaining: 30.3s\n",
      "100:\ttotal: 1.07s\tremaining: 25.3s\n",
      "200:\ttotal: 2.15s\tremaining: 24.6s\n",
      "300:\ttotal: 3.2s\tremaining: 23.4s\n",
      "400:\ttotal: 4.27s\tremaining: 22.4s\n",
      "500:\ttotal: 5.34s\tremaining: 21.3s\n",
      "600:\ttotal: 6.42s\tremaining: 20.3s\n",
      "700:\ttotal: 7.61s\tremaining: 19.5s\n",
      "800:\ttotal: 8.69s\tremaining: 18.4s\n",
      "900:\ttotal: 9.75s\tremaining: 17.3s\n",
      "1000:\ttotal: 10.8s\tremaining: 16.2s\n",
      "1100:\ttotal: 11.9s\tremaining: 15.1s\n",
      "1200:\ttotal: 12.9s\tremaining: 14s\n",
      "1300:\ttotal: 14s\tremaining: 12.9s\n",
      "1400:\ttotal: 15s\tremaining: 11.8s\n",
      "1500:\ttotal: 16.1s\tremaining: 10.7s\n",
      "1600:\ttotal: 17.2s\tremaining: 9.65s\n",
      "1700:\ttotal: 18.2s\tremaining: 8.56s\n",
      "1800:\ttotal: 19.3s\tremaining: 7.47s\n",
      "1900:\ttotal: 20.3s\tremaining: 6.4s\n",
      "2000:\ttotal: 21.4s\tremaining: 5.33s\n",
      "2100:\ttotal: 22.4s\tremaining: 4.26s\n",
      "2200:\ttotal: 23.4s\tremaining: 3.18s\n",
      "2300:\ttotal: 24.5s\tremaining: 2.12s\n",
      "2400:\ttotal: 25.5s\tremaining: 1.05s\n",
      "2499:\ttotal: 26.5s\tremaining: 0us\n",
      "0:\ttotal: 15.3ms\tremaining: 38.3s\n",
      "100:\ttotal: 1.02s\tremaining: 24.4s\n",
      "200:\ttotal: 2.07s\tremaining: 23.7s\n",
      "300:\ttotal: 3.09s\tremaining: 22.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400:\ttotal: 4.1s\tremaining: 21.5s\n",
      "500:\ttotal: 5.13s\tremaining: 20.5s\n",
      "600:\ttotal: 6.14s\tremaining: 19.4s\n",
      "700:\ttotal: 7.2s\tremaining: 18.5s\n",
      "800:\ttotal: 8.24s\tremaining: 17.5s\n",
      "900:\ttotal: 9.29s\tremaining: 16.5s\n",
      "1000:\ttotal: 10.3s\tremaining: 15.4s\n",
      "1100:\ttotal: 11.4s\tremaining: 14.4s\n",
      "1200:\ttotal: 12.4s\tremaining: 13.4s\n",
      "1300:\ttotal: 13.5s\tremaining: 12.5s\n",
      "1400:\ttotal: 14.6s\tremaining: 11.4s\n",
      "1500:\ttotal: 15.6s\tremaining: 10.4s\n",
      "1600:\ttotal: 16.8s\tremaining: 9.42s\n",
      "1700:\ttotal: 17.8s\tremaining: 8.36s\n",
      "1800:\ttotal: 18.8s\tremaining: 7.3s\n",
      "1900:\ttotal: 20s\tremaining: 6.31s\n",
      "2000:\ttotal: 21.2s\tremaining: 5.28s\n",
      "2100:\ttotal: 22.4s\tremaining: 4.25s\n",
      "2200:\ttotal: 23.6s\tremaining: 3.2s\n",
      "2300:\ttotal: 24.7s\tremaining: 2.14s\n",
      "2400:\ttotal: 25.9s\tremaining: 1.07s\n",
      "2499:\ttotal: 27.1s\tremaining: 0us\n",
      "0:\ttotal: 18.6ms\tremaining: 46.4s\n",
      "100:\ttotal: 1.46s\tremaining: 34.8s\n",
      "200:\ttotal: 2.56s\tremaining: 29.3s\n",
      "300:\ttotal: 3.62s\tremaining: 26.4s\n",
      "400:\ttotal: 4.7s\tremaining: 24.6s\n",
      "500:\ttotal: 5.75s\tremaining: 22.9s\n",
      "600:\ttotal: 6.8s\tremaining: 21.5s\n",
      "700:\ttotal: 7.83s\tremaining: 20.1s\n",
      "800:\ttotal: 8.89s\tremaining: 18.9s\n",
      "900:\ttotal: 9.95s\tremaining: 17.7s\n",
      "1000:\ttotal: 11.1s\tremaining: 16.7s\n",
      "1100:\ttotal: 12.4s\tremaining: 15.8s\n",
      "1200:\ttotal: 13.8s\tremaining: 15s\n",
      "1300:\ttotal: 15.1s\tremaining: 13.9s\n",
      "1400:\ttotal: 16.7s\tremaining: 13.1s\n",
      "1500:\ttotal: 18.3s\tremaining: 12.2s\n",
      "1600:\ttotal: 19.4s\tremaining: 10.9s\n",
      "1700:\ttotal: 20.5s\tremaining: 9.63s\n",
      "1800:\ttotal: 21.6s\tremaining: 8.39s\n",
      "1900:\ttotal: 22.8s\tremaining: 7.19s\n",
      "2000:\ttotal: 23.9s\tremaining: 5.96s\n",
      "2100:\ttotal: 24.9s\tremaining: 4.74s\n",
      "2200:\ttotal: 26.1s\tremaining: 3.54s\n",
      "2300:\ttotal: 27.1s\tremaining: 2.34s\n",
      "2400:\ttotal: 28.2s\tremaining: 1.16s\n",
      "2499:\ttotal: 29.2s\tremaining: 0us\n",
      "0:\ttotal: 14.9ms\tremaining: 37.2s\n",
      "100:\ttotal: 1.09s\tremaining: 25.9s\n",
      "200:\ttotal: 2.25s\tremaining: 25.7s\n",
      "300:\ttotal: 3.48s\tremaining: 25.4s\n",
      "400:\ttotal: 4.82s\tremaining: 25.2s\n",
      "500:\ttotal: 6.1s\tremaining: 24.3s\n",
      "600:\ttotal: 7.24s\tremaining: 22.9s\n",
      "700:\ttotal: 8.39s\tremaining: 21.5s\n",
      "800:\ttotal: 9.67s\tremaining: 20.5s\n",
      "900:\ttotal: 10.8s\tremaining: 19.2s\n",
      "1000:\ttotal: 11.9s\tremaining: 17.9s\n",
      "1100:\ttotal: 13s\tremaining: 16.6s\n",
      "1200:\ttotal: 14.2s\tremaining: 15.4s\n",
      "1300:\ttotal: 15.5s\tremaining: 14.3s\n",
      "1400:\ttotal: 16.6s\tremaining: 13s\n",
      "1500:\ttotal: 17.7s\tremaining: 11.8s\n",
      "1600:\ttotal: 19s\tremaining: 10.7s\n",
      "1700:\ttotal: 20.2s\tremaining: 9.51s\n",
      "1800:\ttotal: 21.3s\tremaining: 8.28s\n",
      "1900:\ttotal: 22.4s\tremaining: 7.07s\n",
      "2000:\ttotal: 23.5s\tremaining: 5.87s\n",
      "2100:\ttotal: 24.6s\tremaining: 4.68s\n",
      "2200:\ttotal: 25.9s\tremaining: 3.52s\n",
      "2300:\ttotal: 27.1s\tremaining: 2.34s\n",
      "2400:\ttotal: 28.2s\tremaining: 1.16s\n",
      "2499:\ttotal: 29.3s\tremaining: 0us\n",
      "0:\ttotal: 12.5ms\tremaining: 31.2s\n",
      "100:\ttotal: 1.33s\tremaining: 31.5s\n",
      "200:\ttotal: 2.54s\tremaining: 29.1s\n",
      "300:\ttotal: 3.69s\tremaining: 26.9s\n",
      "400:\ttotal: 4.85s\tremaining: 25.4s\n",
      "500:\ttotal: 6.04s\tremaining: 24.1s\n",
      "600:\ttotal: 7.38s\tremaining: 23.3s\n",
      "700:\ttotal: 8.53s\tremaining: 21.9s\n",
      "800:\ttotal: 9.69s\tremaining: 20.6s\n",
      "900:\ttotal: 11s\tremaining: 19.5s\n",
      "1000:\ttotal: 12.3s\tremaining: 18.4s\n",
      "1100:\ttotal: 13.8s\tremaining: 17.5s\n",
      "1200:\ttotal: 15.1s\tremaining: 16.3s\n",
      "1300:\ttotal: 16.2s\tremaining: 14.9s\n",
      "1400:\ttotal: 17.5s\tremaining: 13.7s\n",
      "1500:\ttotal: 18.7s\tremaining: 12.5s\n",
      "1600:\ttotal: 20s\tremaining: 11.2s\n",
      "1700:\ttotal: 21.2s\tremaining: 9.96s\n",
      "1800:\ttotal: 22.5s\tremaining: 8.73s\n",
      "1900:\ttotal: 23.6s\tremaining: 7.44s\n",
      "2000:\ttotal: 24.7s\tremaining: 6.15s\n",
      "2100:\ttotal: 25.9s\tremaining: 4.92s\n",
      "2200:\ttotal: 27.1s\tremaining: 3.69s\n",
      "2300:\ttotal: 28.5s\tremaining: 2.46s\n",
      "2400:\ttotal: 29.6s\tremaining: 1.22s\n",
      "2499:\ttotal: 30.7s\tremaining: 0us\n",
      "0:\ttotal: 13.7ms\tremaining: 34.3s\n",
      "100:\ttotal: 1.11s\tremaining: 26.4s\n",
      "200:\ttotal: 2.33s\tremaining: 26.7s\n",
      "300:\ttotal: 3.48s\tremaining: 25.4s\n",
      "400:\ttotal: 4.59s\tremaining: 24s\n",
      "500:\ttotal: 5.66s\tremaining: 22.6s\n",
      "600:\ttotal: 6.76s\tremaining: 21.4s\n",
      "700:\ttotal: 7.92s\tremaining: 20.3s\n",
      "800:\ttotal: 8.99s\tremaining: 19.1s\n",
      "900:\ttotal: 10.1s\tremaining: 17.8s\n",
      "1000:\ttotal: 11.1s\tremaining: 16.6s\n",
      "1100:\ttotal: 12.3s\tremaining: 15.6s\n",
      "1200:\ttotal: 13.5s\tremaining: 14.6s\n",
      "1300:\ttotal: 14.6s\tremaining: 13.4s\n",
      "1400:\ttotal: 15.6s\tremaining: 12.2s\n",
      "1500:\ttotal: 16.7s\tremaining: 11.1s\n",
      "1600:\ttotal: 17.9s\tremaining: 10.1s\n",
      "1700:\ttotal: 19.1s\tremaining: 8.97s\n",
      "1800:\ttotal: 20.1s\tremaining: 7.82s\n",
      "1900:\ttotal: 21.2s\tremaining: 6.68s\n",
      "2000:\ttotal: 22.3s\tremaining: 5.56s\n",
      "2100:\ttotal: 23.5s\tremaining: 4.46s\n",
      "2200:\ttotal: 24.6s\tremaining: 3.35s\n",
      "2300:\ttotal: 25.7s\tremaining: 2.22s\n",
      "2400:\ttotal: 26.7s\tremaining: 1.1s\n",
      "2499:\ttotal: 27.8s\tremaining: 0us\n",
      "0:\ttotal: 36.5ms\tremaining: 1m 31s\n",
      "100:\ttotal: 1.17s\tremaining: 27.7s\n",
      "200:\ttotal: 2.27s\tremaining: 26s\n",
      "300:\ttotal: 3.37s\tremaining: 24.6s\n",
      "400:\ttotal: 4.52s\tremaining: 23.6s\n",
      "500:\ttotal: 5.53s\tremaining: 22.1s\n",
      "600:\ttotal: 6.73s\tremaining: 21.3s\n",
      "700:\ttotal: 7.82s\tremaining: 20.1s\n",
      "800:\ttotal: 8.97s\tremaining: 19s\n",
      "900:\ttotal: 10s\tremaining: 17.8s\n",
      "1000:\ttotal: 11.1s\tremaining: 16.6s\n",
      "1100:\ttotal: 12.2s\tremaining: 15.5s\n",
      "1200:\ttotal: 13.3s\tremaining: 14.4s\n",
      "1300:\ttotal: 14.5s\tremaining: 13.3s\n",
      "1400:\ttotal: 15.6s\tremaining: 12.2s\n",
      "1500:\ttotal: 16.8s\tremaining: 11.2s\n",
      "1600:\ttotal: 17.9s\tremaining: 10s\n",
      "1700:\ttotal: 19s\tremaining: 8.94s\n",
      "1800:\ttotal: 20.2s\tremaining: 7.83s\n",
      "1900:\ttotal: 21.3s\tremaining: 6.7s\n",
      "2000:\ttotal: 22.5s\tremaining: 5.61s\n",
      "2100:\ttotal: 23.6s\tremaining: 4.47s\n",
      "2200:\ttotal: 24.7s\tremaining: 3.35s\n",
      "2300:\ttotal: 25.8s\tremaining: 2.23s\n",
      "2400:\ttotal: 26.9s\tremaining: 1.11s\n",
      "2499:\ttotal: 28.2s\tremaining: 0us\n",
      "0:\ttotal: 18.8ms\tremaining: 47.1s\n",
      "100:\ttotal: 1.22s\tremaining: 29s\n",
      "200:\ttotal: 2.41s\tremaining: 27.6s\n",
      "300:\ttotal: 3.65s\tremaining: 26.7s\n",
      "400:\ttotal: 4.89s\tremaining: 25.6s\n",
      "500:\ttotal: 6.37s\tremaining: 25.4s\n",
      "600:\ttotal: 7.6s\tremaining: 24s\n",
      "700:\ttotal: 8.82s\tremaining: 22.6s\n",
      "800:\ttotal: 10.4s\tremaining: 22.1s\n",
      "900:\ttotal: 12.1s\tremaining: 21.5s\n",
      "1000:\ttotal: 13.9s\tremaining: 20.8s\n",
      "1100:\ttotal: 15.2s\tremaining: 19.3s\n",
      "1200:\ttotal: 16.4s\tremaining: 17.7s\n",
      "1300:\ttotal: 17.6s\tremaining: 16.3s\n",
      "1400:\ttotal: 18.9s\tremaining: 14.8s\n",
      "1500:\ttotal: 20.2s\tremaining: 13.5s\n",
      "1600:\ttotal: 21.6s\tremaining: 12.1s\n",
      "1700:\ttotal: 22.7s\tremaining: 10.7s\n",
      "1800:\ttotal: 23.9s\tremaining: 9.27s\n",
      "1900:\ttotal: 25s\tremaining: 7.89s\n",
      "2000:\ttotal: 26.2s\tremaining: 6.53s\n",
      "2100:\ttotal: 27.4s\tremaining: 5.19s\n",
      "2200:\ttotal: 28.6s\tremaining: 3.88s\n",
      "2300:\ttotal: 29.8s\tremaining: 2.58s\n",
      "2400:\ttotal: 31.3s\tremaining: 1.29s\n",
      "2499:\ttotal: 32.9s\tremaining: 0us\n",
      "0:\ttotal: 18.8ms\tremaining: 47s\n",
      "100:\ttotal: 1.56s\tremaining: 37.1s\n",
      "200:\ttotal: 2.82s\tremaining: 32.3s\n",
      "300:\ttotal: 4.09s\tremaining: 29.9s\n",
      "400:\ttotal: 5.39s\tremaining: 28.2s\n",
      "500:\ttotal: 6.75s\tremaining: 26.9s\n",
      "600:\ttotal: 8.24s\tremaining: 26s\n",
      "700:\ttotal: 9.62s\tremaining: 24.7s\n",
      "800:\ttotal: 10.9s\tremaining: 23.1s\n",
      "900:\ttotal: 12.2s\tremaining: 21.7s\n",
      "1000:\ttotal: 13.5s\tremaining: 20.3s\n",
      "1100:\ttotal: 14.8s\tremaining: 18.9s\n",
      "1200:\ttotal: 16.1s\tremaining: 17.4s\n",
      "1300:\ttotal: 17.5s\tremaining: 16.1s\n",
      "1400:\ttotal: 18.9s\tremaining: 14.8s\n",
      "1500:\ttotal: 20.3s\tremaining: 13.5s\n",
      "1600:\ttotal: 21.7s\tremaining: 12.2s\n",
      "1700:\ttotal: 23.1s\tremaining: 10.9s\n",
      "1800:\ttotal: 24.3s\tremaining: 9.44s\n",
      "1900:\ttotal: 25.5s\tremaining: 8.04s\n",
      "2000:\ttotal: 26.7s\tremaining: 6.65s\n",
      "2100:\ttotal: 27.8s\tremaining: 5.27s\n",
      "2200:\ttotal: 28.8s\tremaining: 3.92s\n",
      "2300:\ttotal: 30s\tremaining: 2.6s\n",
      "2400:\ttotal: 31.1s\tremaining: 1.28s\n",
      "2499:\ttotal: 32.3s\tremaining: 0us\n",
      "0:\ttotal: 17.1ms\tremaining: 42.8s\n",
      "100:\ttotal: 1.1s\tremaining: 26.1s\n",
      "200:\ttotal: 2.27s\tremaining: 26s\n",
      "300:\ttotal: 3.45s\tremaining: 25.2s\n",
      "400:\ttotal: 4.65s\tremaining: 24.3s\n",
      "500:\ttotal: 5.8s\tremaining: 23.1s\n",
      "600:\ttotal: 6.94s\tremaining: 21.9s\n",
      "700:\ttotal: 8.06s\tremaining: 20.7s\n",
      "800:\ttotal: 9.4s\tremaining: 19.9s\n",
      "900:\ttotal: 10.6s\tremaining: 18.9s\n",
      "1000:\ttotal: 11.9s\tremaining: 17.8s\n",
      "1100:\ttotal: 13.2s\tremaining: 16.7s\n",
      "1200:\ttotal: 14.4s\tremaining: 15.5s\n",
      "1300:\ttotal: 15.5s\tremaining: 14.2s\n",
      "1400:\ttotal: 16.5s\tremaining: 13s\n",
      "1500:\ttotal: 17.6s\tremaining: 11.7s\n",
      "1600:\ttotal: 18.7s\tremaining: 10.5s\n",
      "1700:\ttotal: 19.8s\tremaining: 9.31s\n",
      "1800:\ttotal: 20.9s\tremaining: 8.11s\n",
      "1900:\ttotal: 22.1s\tremaining: 6.96s\n",
      "2000:\ttotal: 23.2s\tremaining: 5.79s\n",
      "2100:\ttotal: 24.4s\tremaining: 4.63s\n",
      "2200:\ttotal: 25.6s\tremaining: 3.47s\n",
      "2300:\ttotal: 26.7s\tremaining: 2.31s\n",
      "2400:\ttotal: 27.7s\tremaining: 1.14s\n",
      "2499:\ttotal: 28.7s\tremaining: 0us\n",
      "0:\ttotal: 11.8ms\tremaining: 29.6s\n",
      "100:\ttotal: 1.09s\tremaining: 26s\n",
      "200:\ttotal: 2.17s\tremaining: 24.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300:\ttotal: 3.27s\tremaining: 23.9s\n",
      "400:\ttotal: 4.34s\tremaining: 22.7s\n",
      "500:\ttotal: 5.4s\tremaining: 21.5s\n",
      "600:\ttotal: 6.5s\tremaining: 20.5s\n",
      "700:\ttotal: 7.63s\tremaining: 19.6s\n",
      "800:\ttotal: 8.74s\tremaining: 18.5s\n",
      "900:\ttotal: 9.85s\tremaining: 17.5s\n",
      "1000:\ttotal: 11s\tremaining: 16.4s\n",
      "1100:\ttotal: 12s\tremaining: 15.3s\n",
      "1200:\ttotal: 13.1s\tremaining: 14.2s\n",
      "1300:\ttotal: 14.2s\tremaining: 13.1s\n",
      "1400:\ttotal: 15.3s\tremaining: 12s\n",
      "1500:\ttotal: 16.4s\tremaining: 10.9s\n",
      "1600:\ttotal: 17.5s\tremaining: 9.82s\n",
      "1700:\ttotal: 18.6s\tremaining: 8.73s\n",
      "1800:\ttotal: 19.6s\tremaining: 7.62s\n",
      "1900:\ttotal: 20.7s\tremaining: 6.54s\n",
      "2000:\ttotal: 21.8s\tremaining: 5.44s\n",
      "2100:\ttotal: 22.9s\tremaining: 4.35s\n",
      "2200:\ttotal: 24s\tremaining: 3.26s\n",
      "2300:\ttotal: 25.1s\tremaining: 2.17s\n",
      "2400:\ttotal: 26.2s\tremaining: 1.08s\n",
      "2499:\ttotal: 27.3s\tremaining: 0us\n",
      "0:\ttotal: 12.1ms\tremaining: 30.1s\n",
      "100:\ttotal: 1.1s\tremaining: 26.2s\n",
      "200:\ttotal: 2.21s\tremaining: 25.3s\n",
      "300:\ttotal: 3.29s\tremaining: 24.1s\n",
      "400:\ttotal: 4.37s\tremaining: 22.9s\n",
      "500:\ttotal: 5.49s\tremaining: 21.9s\n",
      "600:\ttotal: 6.54s\tremaining: 20.7s\n",
      "700:\ttotal: 7.62s\tremaining: 19.6s\n",
      "800:\ttotal: 8.76s\tremaining: 18.6s\n",
      "900:\ttotal: 9.8s\tremaining: 17.4s\n",
      "1000:\ttotal: 10.9s\tremaining: 16.3s\n",
      "1100:\ttotal: 11.9s\tremaining: 15.1s\n",
      "1200:\ttotal: 12.9s\tremaining: 14s\n",
      "1300:\ttotal: 14s\tremaining: 12.9s\n",
      "1400:\ttotal: 15.1s\tremaining: 11.9s\n",
      "1500:\ttotal: 16.3s\tremaining: 10.9s\n",
      "1600:\ttotal: 17.5s\tremaining: 9.85s\n",
      "1700:\ttotal: 18.6s\tremaining: 8.75s\n",
      "1800:\ttotal: 19.7s\tremaining: 7.65s\n",
      "1900:\ttotal: 20.8s\tremaining: 6.54s\n",
      "2000:\ttotal: 21.8s\tremaining: 5.45s\n",
      "2100:\ttotal: 22.9s\tremaining: 4.35s\n",
      "2200:\ttotal: 23.9s\tremaining: 3.25s\n",
      "2300:\ttotal: 25s\tremaining: 2.16s\n",
      "2400:\ttotal: 26.1s\tremaining: 1.08s\n",
      "2499:\ttotal: 27.3s\tremaining: 0us\n",
      "0:\ttotal: 16.9ms\tremaining: 42.3s\n",
      "100:\ttotal: 1.31s\tremaining: 31.2s\n",
      "200:\ttotal: 2.56s\tremaining: 29.3s\n",
      "300:\ttotal: 3.72s\tremaining: 27.2s\n",
      "400:\ttotal: 5.06s\tremaining: 26.5s\n",
      "500:\ttotal: 6.27s\tremaining: 25s\n",
      "600:\ttotal: 7.37s\tremaining: 23.3s\n",
      "700:\ttotal: 8.51s\tremaining: 21.8s\n",
      "800:\ttotal: 9.78s\tremaining: 20.7s\n",
      "900:\ttotal: 10.9s\tremaining: 19.4s\n",
      "1000:\ttotal: 12.2s\tremaining: 18.3s\n",
      "1100:\ttotal: 13.3s\tremaining: 16.9s\n",
      "1200:\ttotal: 14.5s\tremaining: 15.6s\n",
      "1300:\ttotal: 15.7s\tremaining: 14.5s\n",
      "1400:\ttotal: 16.8s\tremaining: 13.2s\n",
      "1500:\ttotal: 17.9s\tremaining: 11.9s\n",
      "1600:\ttotal: 19s\tremaining: 10.7s\n",
      "1700:\ttotal: 20.3s\tremaining: 9.52s\n",
      "1800:\ttotal: 21.9s\tremaining: 8.49s\n",
      "1900:\ttotal: 23.5s\tremaining: 7.4s\n",
      "2000:\ttotal: 25s\tremaining: 6.23s\n",
      "2100:\ttotal: 26.3s\tremaining: 4.99s\n",
      "2200:\ttotal: 27.7s\tremaining: 3.76s\n",
      "2300:\ttotal: 29s\tremaining: 2.51s\n",
      "2400:\ttotal: 30.4s\tremaining: 1.25s\n",
      "2499:\ttotal: 31.5s\tremaining: 0us\n",
      "0:\ttotal: 12.2ms\tremaining: 30.6s\n",
      "100:\ttotal: 1.09s\tremaining: 25.9s\n",
      "200:\ttotal: 2.15s\tremaining: 24.6s\n",
      "300:\ttotal: 3.3s\tremaining: 24.1s\n",
      "400:\ttotal: 4.54s\tremaining: 23.8s\n",
      "500:\ttotal: 5.81s\tremaining: 23.2s\n",
      "600:\ttotal: 7.43s\tremaining: 23.5s\n",
      "700:\ttotal: 9.01s\tremaining: 23.1s\n",
      "800:\ttotal: 10.6s\tremaining: 22.5s\n",
      "900:\ttotal: 12.3s\tremaining: 21.8s\n",
      "1000:\ttotal: 14s\tremaining: 20.9s\n",
      "1100:\ttotal: 15.2s\tremaining: 19.4s\n",
      "1200:\ttotal: 16.4s\tremaining: 17.8s\n",
      "1300:\ttotal: 17.6s\tremaining: 16.2s\n",
      "1400:\ttotal: 18.8s\tremaining: 14.7s\n",
      "1500:\ttotal: 20s\tremaining: 13.3s\n",
      "1600:\ttotal: 21.2s\tremaining: 11.9s\n",
      "1700:\ttotal: 22.4s\tremaining: 10.5s\n",
      "1800:\ttotal: 23.5s\tremaining: 9.12s\n",
      "1900:\ttotal: 24.6s\tremaining: 7.76s\n",
      "2000:\ttotal: 25.8s\tremaining: 6.44s\n",
      "2100:\ttotal: 27s\tremaining: 5.13s\n",
      "2200:\ttotal: 28.1s\tremaining: 3.82s\n",
      "2300:\ttotal: 29.3s\tremaining: 2.53s\n",
      "2400:\ttotal: 30.3s\tremaining: 1.25s\n",
      "2499:\ttotal: 31.4s\tremaining: 0us\n",
      "0:\ttotal: 11.9ms\tremaining: 29.7s\n",
      "100:\ttotal: 1.07s\tremaining: 25.3s\n",
      "200:\ttotal: 2.1s\tremaining: 24s\n",
      "300:\ttotal: 3.15s\tremaining: 23s\n",
      "400:\ttotal: 4.2s\tremaining: 22s\n",
      "500:\ttotal: 5.23s\tremaining: 20.9s\n",
      "600:\ttotal: 6.28s\tremaining: 19.8s\n",
      "700:\ttotal: 7.33s\tremaining: 18.8s\n",
      "800:\ttotal: 8.43s\tremaining: 17.9s\n",
      "900:\ttotal: 9.55s\tremaining: 16.9s\n",
      "1000:\ttotal: 10.6s\tremaining: 15.9s\n",
      "1100:\ttotal: 11.7s\tremaining: 14.9s\n",
      "1200:\ttotal: 12.7s\tremaining: 13.8s\n",
      "1300:\ttotal: 13.7s\tremaining: 12.7s\n",
      "1400:\ttotal: 14.8s\tremaining: 11.6s\n",
      "1500:\ttotal: 15.8s\tremaining: 10.5s\n",
      "1600:\ttotal: 16.9s\tremaining: 9.52s\n",
      "1700:\ttotal: 18s\tremaining: 8.46s\n",
      "1800:\ttotal: 19.1s\tremaining: 7.43s\n",
      "1900:\ttotal: 20.2s\tremaining: 6.38s\n",
      "2000:\ttotal: 21.4s\tremaining: 5.34s\n",
      "2100:\ttotal: 22.5s\tremaining: 4.28s\n",
      "2200:\ttotal: 23.6s\tremaining: 3.21s\n",
      "2300:\ttotal: 24.7s\tremaining: 2.14s\n",
      "2400:\ttotal: 25.8s\tremaining: 1.06s\n",
      "2499:\ttotal: 27s\tremaining: 0us\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.9787  \u001b[0m | \u001b[0m 0.309   \u001b[0m | \u001b[0m 4.734   \u001b[0m | \u001b[0m 0.1013  \u001b[0m |\n",
      "0:\ttotal: 19.8ms\tremaining: 49.6s\n",
      "100:\ttotal: 1.68s\tremaining: 40s\n",
      "200:\ttotal: 3.42s\tremaining: 39.2s\n",
      "300:\ttotal: 5.23s\tremaining: 38.2s\n",
      "400:\ttotal: 7.14s\tremaining: 37.4s\n",
      "500:\ttotal: 8.91s\tremaining: 35.6s\n",
      "600:\ttotal: 10.6s\tremaining: 33.6s\n",
      "700:\ttotal: 12.3s\tremaining: 31.7s\n",
      "800:\ttotal: 14.1s\tremaining: 29.8s\n",
      "900:\ttotal: 16s\tremaining: 28.3s\n",
      "1000:\ttotal: 17.8s\tremaining: 26.7s\n",
      "1100:\ttotal: 19.5s\tremaining: 24.8s\n",
      "1200:\ttotal: 21.2s\tremaining: 23s\n",
      "1300:\ttotal: 22.9s\tremaining: 21.1s\n",
      "1400:\ttotal: 24.6s\tremaining: 19.3s\n",
      "1500:\ttotal: 26.3s\tremaining: 17.5s\n",
      "1600:\ttotal: 27.9s\tremaining: 15.7s\n",
      "1700:\ttotal: 29.5s\tremaining: 13.9s\n",
      "1800:\ttotal: 31.4s\tremaining: 12.2s\n",
      "1900:\ttotal: 33.3s\tremaining: 10.5s\n",
      "2000:\ttotal: 35.1s\tremaining: 8.74s\n",
      "2100:\ttotal: 36.8s\tremaining: 6.98s\n",
      "2200:\ttotal: 38.5s\tremaining: 5.22s\n",
      "2300:\ttotal: 40.2s\tremaining: 3.47s\n",
      "2400:\ttotal: 41.9s\tremaining: 1.73s\n",
      "2499:\ttotal: 43.8s\tremaining: 0us\n",
      "0:\ttotal: 44.2ms\tremaining: 1m 50s\n",
      "100:\ttotal: 1.73s\tremaining: 41s\n",
      "200:\ttotal: 3.43s\tremaining: 39.3s\n",
      "300:\ttotal: 5.12s\tremaining: 37.4s\n",
      "400:\ttotal: 6.92s\tremaining: 36.2s\n",
      "500:\ttotal: 8.86s\tremaining: 35.3s\n",
      "600:\ttotal: 10.6s\tremaining: 33.4s\n",
      "700:\ttotal: 12.2s\tremaining: 31.4s\n",
      "800:\ttotal: 13.9s\tremaining: 29.5s\n",
      "900:\ttotal: 15.6s\tremaining: 27.7s\n",
      "1000:\ttotal: 17.3s\tremaining: 26s\n",
      "1100:\ttotal: 19s\tremaining: 24.2s\n",
      "1200:\ttotal: 20.8s\tremaining: 22.4s\n",
      "1300:\ttotal: 22.4s\tremaining: 20.7s\n",
      "1400:\ttotal: 24.2s\tremaining: 19s\n",
      "1500:\ttotal: 26.1s\tremaining: 17.4s\n",
      "1600:\ttotal: 27.9s\tremaining: 15.7s\n",
      "1700:\ttotal: 29.8s\tremaining: 14s\n",
      "1800:\ttotal: 31.7s\tremaining: 12.3s\n",
      "1900:\ttotal: 33.7s\tremaining: 10.6s\n",
      "2000:\ttotal: 35.7s\tremaining: 8.9s\n",
      "2100:\ttotal: 37.4s\tremaining: 7.1s\n",
      "2200:\ttotal: 39.3s\tremaining: 5.33s\n",
      "2300:\ttotal: 41.4s\tremaining: 3.58s\n",
      "2400:\ttotal: 43.3s\tremaining: 1.78s\n",
      "2499:\ttotal: 45s\tremaining: 0us\n",
      "0:\ttotal: 24.1ms\tremaining: 1m\n",
      "100:\ttotal: 1.83s\tremaining: 43.5s\n",
      "200:\ttotal: 3.73s\tremaining: 42.6s\n",
      "300:\ttotal: 5.58s\tremaining: 40.8s\n",
      "400:\ttotal: 7.31s\tremaining: 38.3s\n",
      "500:\ttotal: 9.04s\tremaining: 36.1s\n",
      "600:\ttotal: 11s\tremaining: 34.9s\n",
      "700:\ttotal: 12.9s\tremaining: 33.2s\n",
      "800:\ttotal: 15.2s\tremaining: 32.2s\n",
      "900:\ttotal: 17.1s\tremaining: 30.4s\n",
      "1000:\ttotal: 19.1s\tremaining: 28.6s\n",
      "1100:\ttotal: 21s\tremaining: 26.7s\n",
      "1200:\ttotal: 22.9s\tremaining: 24.8s\n",
      "1300:\ttotal: 24.9s\tremaining: 23s\n",
      "1400:\ttotal: 26.9s\tremaining: 21.1s\n",
      "1500:\ttotal: 29s\tremaining: 19.3s\n",
      "1600:\ttotal: 31.1s\tremaining: 17.4s\n",
      "1700:\ttotal: 32.9s\tremaining: 15.5s\n",
      "1800:\ttotal: 35s\tremaining: 13.6s\n",
      "1900:\ttotal: 37s\tremaining: 11.7s\n",
      "2000:\ttotal: 38.9s\tremaining: 9.71s\n",
      "2100:\ttotal: 40.8s\tremaining: 7.75s\n",
      "2200:\ttotal: 42.7s\tremaining: 5.8s\n",
      "2300:\ttotal: 44.8s\tremaining: 3.88s\n",
      "2400:\ttotal: 47.1s\tremaining: 1.94s\n",
      "2499:\ttotal: 48.9s\tremaining: 0us\n",
      "0:\ttotal: 23.7ms\tremaining: 59.2s\n",
      "100:\ttotal: 1.79s\tremaining: 42.5s\n",
      "200:\ttotal: 3.62s\tremaining: 41.4s\n",
      "300:\ttotal: 5.43s\tremaining: 39.7s\n",
      "400:\ttotal: 7.34s\tremaining: 38.4s\n",
      "500:\ttotal: 9.13s\tremaining: 36.4s\n",
      "600:\ttotal: 10.9s\tremaining: 34.4s\n",
      "700:\ttotal: 12.7s\tremaining: 32.6s\n",
      "800:\ttotal: 14.5s\tremaining: 30.8s\n",
      "900:\ttotal: 16.2s\tremaining: 28.8s\n",
      "1000:\ttotal: 18s\tremaining: 26.9s\n",
      "1100:\ttotal: 19.8s\tremaining: 25.2s\n",
      "1200:\ttotal: 21.5s\tremaining: 23.2s\n",
      "1300:\ttotal: 23.2s\tremaining: 21.4s\n",
      "1400:\ttotal: 25.4s\tremaining: 19.9s\n",
      "1500:\ttotal: 27.6s\tremaining: 18.4s\n",
      "1600:\ttotal: 29.5s\tremaining: 16.6s\n",
      "1700:\ttotal: 31.3s\tremaining: 14.7s\n",
      "1800:\ttotal: 33.5s\tremaining: 13s\n",
      "1900:\ttotal: 35.5s\tremaining: 11.2s\n",
      "2000:\ttotal: 37.4s\tremaining: 9.32s\n",
      "2100:\ttotal: 39.3s\tremaining: 7.46s\n",
      "2200:\ttotal: 41.1s\tremaining: 5.58s\n",
      "2300:\ttotal: 42.8s\tremaining: 3.7s\n",
      "2400:\ttotal: 44.6s\tremaining: 1.84s\n",
      "2499:\ttotal: 46.5s\tremaining: 0us\n",
      "0:\ttotal: 26.6ms\tremaining: 1m 6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\ttotal: 1.86s\tremaining: 44.2s\n",
      "200:\ttotal: 3.77s\tremaining: 43.1s\n",
      "300:\ttotal: 5.56s\tremaining: 40.6s\n",
      "400:\ttotal: 7.4s\tremaining: 38.8s\n",
      "500:\ttotal: 9.21s\tremaining: 36.8s\n",
      "600:\ttotal: 11s\tremaining: 34.9s\n",
      "700:\ttotal: 12.8s\tremaining: 33s\n",
      "800:\ttotal: 14.6s\tremaining: 30.9s\n",
      "900:\ttotal: 16.4s\tremaining: 29.1s\n",
      "1000:\ttotal: 18.2s\tremaining: 27.2s\n",
      "1100:\ttotal: 19.9s\tremaining: 25.3s\n",
      "1200:\ttotal: 21.7s\tremaining: 23.4s\n",
      "1300:\ttotal: 23.5s\tremaining: 21.6s\n",
      "1400:\ttotal: 25.7s\tremaining: 20.1s\n",
      "1500:\ttotal: 27.5s\tremaining: 18.3s\n",
      "1600:\ttotal: 29.3s\tremaining: 16.5s\n",
      "1700:\ttotal: 31.2s\tremaining: 14.6s\n",
      "1800:\ttotal: 33.3s\tremaining: 12.9s\n",
      "1900:\ttotal: 35.5s\tremaining: 11.2s\n",
      "2000:\ttotal: 37.3s\tremaining: 9.31s\n",
      "2100:\ttotal: 39.3s\tremaining: 7.46s\n",
      "2200:\ttotal: 41s\tremaining: 5.57s\n",
      "2300:\ttotal: 42.8s\tremaining: 3.7s\n",
      "2400:\ttotal: 44.6s\tremaining: 1.84s\n",
      "2499:\ttotal: 46.3s\tremaining: 0us\n",
      "0:\ttotal: 22.6ms\tremaining: 56.5s\n",
      "100:\ttotal: 1.78s\tremaining: 42.2s\n",
      "200:\ttotal: 3.51s\tremaining: 40.2s\n",
      "300:\ttotal: 5.2s\tremaining: 38s\n",
      "400:\ttotal: 6.97s\tremaining: 36.5s\n",
      "500:\ttotal: 8.9s\tremaining: 35.5s\n",
      "600:\ttotal: 10.7s\tremaining: 33.7s\n",
      "700:\ttotal: 12.5s\tremaining: 32s\n",
      "800:\ttotal: 14.3s\tremaining: 30.3s\n",
      "900:\ttotal: 16.1s\tremaining: 28.6s\n",
      "1000:\ttotal: 18s\tremaining: 27s\n",
      "1100:\ttotal: 19.9s\tremaining: 25.3s\n",
      "1200:\ttotal: 21.9s\tremaining: 23.7s\n",
      "1300:\ttotal: 24s\tremaining: 22.1s\n",
      "1400:\ttotal: 25.9s\tremaining: 20.3s\n",
      "1500:\ttotal: 27.7s\tremaining: 18.4s\n",
      "1600:\ttotal: 29.5s\tremaining: 16.6s\n",
      "1700:\ttotal: 31.3s\tremaining: 14.7s\n",
      "1800:\ttotal: 33.2s\tremaining: 12.9s\n",
      "1900:\ttotal: 35.1s\tremaining: 11.1s\n",
      "2000:\ttotal: 36.9s\tremaining: 9.21s\n",
      "2100:\ttotal: 38.7s\tremaining: 7.36s\n",
      "2200:\ttotal: 40.5s\tremaining: 5.51s\n",
      "2300:\ttotal: 42.3s\tremaining: 3.66s\n",
      "2400:\ttotal: 44.3s\tremaining: 1.83s\n",
      "2499:\ttotal: 46.4s\tremaining: 0us\n",
      "0:\ttotal: 26.2ms\tremaining: 1m 5s\n",
      "100:\ttotal: 1.96s\tremaining: 46.6s\n",
      "200:\ttotal: 4.11s\tremaining: 47s\n",
      "300:\ttotal: 6.25s\tremaining: 45.7s\n",
      "400:\ttotal: 8.21s\tremaining: 43s\n",
      "500:\ttotal: 10.4s\tremaining: 41.7s\n",
      "600:\ttotal: 12.7s\tremaining: 40s\n",
      "700:\ttotal: 14.6s\tremaining: 37.3s\n",
      "800:\ttotal: 16.4s\tremaining: 34.7s\n",
      "900:\ttotal: 18.5s\tremaining: 32.8s\n",
      "1000:\ttotal: 20.8s\tremaining: 31.2s\n",
      "1100:\ttotal: 23s\tremaining: 29.3s\n",
      "1200:\ttotal: 25s\tremaining: 27s\n",
      "1300:\ttotal: 27.1s\tremaining: 25s\n",
      "1400:\ttotal: 28.9s\tremaining: 22.7s\n",
      "1500:\ttotal: 30.7s\tremaining: 20.5s\n",
      "1600:\ttotal: 32.7s\tremaining: 18.3s\n",
      "1700:\ttotal: 34.6s\tremaining: 16.2s\n",
      "1800:\ttotal: 36.7s\tremaining: 14.3s\n",
      "1900:\ttotal: 38.7s\tremaining: 12.2s\n",
      "2000:\ttotal: 40.6s\tremaining: 10.1s\n",
      "2100:\ttotal: 42.8s\tremaining: 8.12s\n",
      "2200:\ttotal: 44.9s\tremaining: 6.1s\n",
      "2300:\ttotal: 46.7s\tremaining: 4.04s\n",
      "2400:\ttotal: 48.4s\tremaining: 2s\n",
      "2499:\ttotal: 50.1s\tremaining: 0us\n",
      "0:\ttotal: 18.9ms\tremaining: 47.3s\n",
      "100:\ttotal: 1.66s\tremaining: 39.3s\n",
      "200:\ttotal: 3.33s\tremaining: 38.1s\n",
      "300:\ttotal: 4.97s\tremaining: 36.3s\n",
      "400:\ttotal: 6.64s\tremaining: 34.8s\n",
      "500:\ttotal: 8.27s\tremaining: 33s\n",
      "600:\ttotal: 9.93s\tremaining: 31.4s\n",
      "700:\ttotal: 11.6s\tremaining: 29.8s\n",
      "800:\ttotal: 13.3s\tremaining: 28.1s\n",
      "900:\ttotal: 15s\tremaining: 26.7s\n",
      "1000:\ttotal: 16.8s\tremaining: 25.1s\n",
      "1100:\ttotal: 18.5s\tremaining: 23.4s\n",
      "1200:\ttotal: 20.1s\tremaining: 21.8s\n",
      "1300:\ttotal: 21.9s\tremaining: 20.2s\n",
      "1400:\ttotal: 23.6s\tremaining: 18.5s\n",
      "1500:\ttotal: 25.4s\tremaining: 16.9s\n",
      "1600:\ttotal: 27.3s\tremaining: 15.3s\n",
      "1700:\ttotal: 29.1s\tremaining: 13.7s\n",
      "1800:\ttotal: 31s\tremaining: 12s\n",
      "1900:\ttotal: 33.2s\tremaining: 10.5s\n",
      "2000:\ttotal: 35.3s\tremaining: 8.8s\n",
      "2100:\ttotal: 37.5s\tremaining: 7.12s\n",
      "2200:\ttotal: 39.5s\tremaining: 5.36s\n",
      "2300:\ttotal: 41.4s\tremaining: 3.58s\n",
      "2400:\ttotal: 43.7s\tremaining: 1.8s\n",
      "2499:\ttotal: 45.9s\tremaining: 0us\n",
      "0:\ttotal: 26.4ms\tremaining: 1m 6s\n",
      "100:\ttotal: 2.28s\tremaining: 54.1s\n",
      "200:\ttotal: 4.27s\tremaining: 48.9s\n",
      "300:\ttotal: 6.12s\tremaining: 44.7s\n",
      "400:\ttotal: 8.27s\tremaining: 43.3s\n",
      "500:\ttotal: 10.4s\tremaining: 41.6s\n",
      "600:\ttotal: 12.3s\tremaining: 38.8s\n",
      "700:\ttotal: 14.2s\tremaining: 36.5s\n",
      "800:\ttotal: 16s\tremaining: 33.9s\n",
      "900:\ttotal: 17.8s\tremaining: 31.5s\n",
      "1000:\ttotal: 19.5s\tremaining: 29.3s\n",
      "1100:\ttotal: 21.3s\tremaining: 27s\n",
      "1200:\ttotal: 23.1s\tremaining: 24.9s\n",
      "1300:\ttotal: 24.9s\tremaining: 23s\n",
      "1400:\ttotal: 26.7s\tremaining: 21s\n",
      "1500:\ttotal: 28.7s\tremaining: 19.1s\n",
      "1600:\ttotal: 30.5s\tremaining: 17.2s\n",
      "1700:\ttotal: 32.4s\tremaining: 15.2s\n",
      "1800:\ttotal: 34.3s\tremaining: 13.3s\n",
      "1900:\ttotal: 36.2s\tremaining: 11.4s\n",
      "2000:\ttotal: 38.2s\tremaining: 9.53s\n",
      "2100:\ttotal: 40.1s\tremaining: 7.61s\n",
      "2200:\ttotal: 42s\tremaining: 5.71s\n",
      "2300:\ttotal: 43.7s\tremaining: 3.78s\n",
      "2400:\ttotal: 45.5s\tremaining: 1.88s\n",
      "2499:\ttotal: 47.2s\tremaining: 0us\n",
      "0:\ttotal: 50.4ms\tremaining: 2m 5s\n",
      "100:\ttotal: 1.7s\tremaining: 40.5s\n",
      "200:\ttotal: 3.4s\tremaining: 38.9s\n",
      "300:\ttotal: 5.12s\tremaining: 37.4s\n",
      "400:\ttotal: 6.84s\tremaining: 35.8s\n",
      "500:\ttotal: 8.67s\tremaining: 34.6s\n",
      "600:\ttotal: 10.5s\tremaining: 33.1s\n",
      "700:\ttotal: 12.2s\tremaining: 31.4s\n",
      "800:\ttotal: 14s\tremaining: 29.7s\n",
      "900:\ttotal: 15.8s\tremaining: 28.1s\n",
      "1000:\ttotal: 17.6s\tremaining: 26.3s\n",
      "1100:\ttotal: 19.4s\tremaining: 24.7s\n",
      "1200:\ttotal: 21.4s\tremaining: 23.1s\n",
      "1300:\ttotal: 23.4s\tremaining: 21.6s\n",
      "1400:\ttotal: 25.3s\tremaining: 19.9s\n",
      "1500:\ttotal: 27.3s\tremaining: 18.2s\n",
      "1600:\ttotal: 29.1s\tremaining: 16.4s\n",
      "1700:\ttotal: 31s\tremaining: 14.6s\n",
      "1800:\ttotal: 33.2s\tremaining: 12.9s\n",
      "1900:\ttotal: 35.4s\tremaining: 11.2s\n",
      "2000:\ttotal: 37.3s\tremaining: 9.3s\n",
      "2100:\ttotal: 39.2s\tremaining: 7.45s\n",
      "2200:\ttotal: 41.5s\tremaining: 5.64s\n",
      "2300:\ttotal: 43.8s\tremaining: 3.79s\n",
      "2400:\ttotal: 46.3s\tremaining: 1.91s\n",
      "2499:\ttotal: 48.8s\tremaining: 0us\n",
      "0:\ttotal: 26.2ms\tremaining: 1m 5s\n",
      "100:\ttotal: 2.13s\tremaining: 50.7s\n",
      "200:\ttotal: 4.23s\tremaining: 48.4s\n",
      "300:\ttotal: 6.25s\tremaining: 45.6s\n",
      "400:\ttotal: 8.31s\tremaining: 43.5s\n",
      "500:\ttotal: 10.4s\tremaining: 41.5s\n",
      "600:\ttotal: 12.5s\tremaining: 39.4s\n",
      "700:\ttotal: 14.6s\tremaining: 37.5s\n",
      "800:\ttotal: 16.7s\tremaining: 35.4s\n",
      "900:\ttotal: 18.9s\tremaining: 33.6s\n",
      "1000:\ttotal: 21.4s\tremaining: 32s\n",
      "1100:\ttotal: 23.7s\tremaining: 30.1s\n",
      "1200:\ttotal: 25.8s\tremaining: 27.9s\n",
      "1300:\ttotal: 28.1s\tremaining: 25.9s\n",
      "1400:\ttotal: 30.3s\tremaining: 23.7s\n",
      "1500:\ttotal: 32.5s\tremaining: 21.6s\n",
      "1600:\ttotal: 34.8s\tremaining: 19.5s\n",
      "1700:\ttotal: 37s\tremaining: 17.4s\n",
      "1800:\ttotal: 39.4s\tremaining: 15.3s\n",
      "1900:\ttotal: 41.7s\tremaining: 13.1s\n",
      "2000:\ttotal: 43.9s\tremaining: 10.9s\n",
      "2100:\ttotal: 46.1s\tremaining: 8.76s\n",
      "2200:\ttotal: 48.3s\tremaining: 6.56s\n",
      "2300:\ttotal: 50.4s\tremaining: 4.36s\n",
      "2400:\ttotal: 52.6s\tremaining: 2.17s\n",
      "2499:\ttotal: 54.7s\tremaining: 0us\n",
      "0:\ttotal: 25.3ms\tremaining: 1m 3s\n",
      "100:\ttotal: 2.12s\tremaining: 50.5s\n",
      "200:\ttotal: 4.21s\tremaining: 48.1s\n",
      "300:\ttotal: 6.26s\tremaining: 45.7s\n",
      "400:\ttotal: 8.35s\tremaining: 43.7s\n",
      "500:\ttotal: 10.5s\tremaining: 41.7s\n",
      "600:\ttotal: 12.5s\tremaining: 39.6s\n",
      "700:\ttotal: 14.7s\tremaining: 37.7s\n",
      "800:\ttotal: 16.8s\tremaining: 35.7s\n",
      "900:\ttotal: 18.9s\tremaining: 33.6s\n",
      "1000:\ttotal: 21s\tremaining: 31.4s\n",
      "1100:\ttotal: 23.1s\tremaining: 29.3s\n",
      "1200:\ttotal: 25.1s\tremaining: 27.2s\n",
      "1300:\ttotal: 27.2s\tremaining: 25.1s\n",
      "1400:\ttotal: 29.3s\tremaining: 23s\n",
      "1500:\ttotal: 31.3s\tremaining: 20.9s\n",
      "1600:\ttotal: 33.4s\tremaining: 18.8s\n",
      "1700:\ttotal: 35.6s\tremaining: 16.7s\n",
      "1800:\ttotal: 37.9s\tremaining: 14.7s\n",
      "1900:\ttotal: 40.2s\tremaining: 12.7s\n",
      "2000:\ttotal: 42.4s\tremaining: 10.6s\n",
      "2100:\ttotal: 44.6s\tremaining: 8.47s\n",
      "2200:\ttotal: 46.8s\tremaining: 6.36s\n",
      "2300:\ttotal: 49.1s\tremaining: 4.24s\n",
      "2400:\ttotal: 51.3s\tremaining: 2.11s\n",
      "2499:\ttotal: 53.5s\tremaining: 0us\n",
      "0:\ttotal: 27.1ms\tremaining: 1m 7s\n",
      "100:\ttotal: 2.31s\tremaining: 54.9s\n",
      "200:\ttotal: 4.73s\tremaining: 54.1s\n",
      "300:\ttotal: 6.92s\tremaining: 50.6s\n",
      "400:\ttotal: 9.14s\tremaining: 47.8s\n",
      "500:\ttotal: 11.7s\tremaining: 46.5s\n",
      "600:\ttotal: 14.2s\tremaining: 44.9s\n",
      "700:\ttotal: 16.5s\tremaining: 42.4s\n",
      "800:\ttotal: 18.7s\tremaining: 39.8s\n",
      "900:\ttotal: 21.4s\tremaining: 38.1s\n",
      "1000:\ttotal: 23.7s\tremaining: 35.5s\n",
      "1100:\ttotal: 26.1s\tremaining: 33.1s\n",
      "1200:\ttotal: 28.3s\tremaining: 30.7s\n",
      "1300:\ttotal: 30.9s\tremaining: 28.5s\n",
      "1400:\ttotal: 33.3s\tremaining: 26.2s\n",
      "1500:\ttotal: 35.6s\tremaining: 23.7s\n",
      "1600:\ttotal: 37.9s\tremaining: 21.3s\n",
      "1700:\ttotal: 40.3s\tremaining: 18.9s\n",
      "1800:\ttotal: 42.7s\tremaining: 16.6s\n",
      "1900:\ttotal: 45.1s\tremaining: 14.2s\n",
      "2000:\ttotal: 47.4s\tremaining: 11.8s\n",
      "2100:\ttotal: 49.7s\tremaining: 9.44s\n",
      "2200:\ttotal: 52s\tremaining: 7.06s\n",
      "2300:\ttotal: 54.2s\tremaining: 4.68s\n",
      "2400:\ttotal: 56.4s\tremaining: 2.32s\n",
      "2499:\ttotal: 58.5s\tremaining: 0us\n",
      "0:\ttotal: 29.3ms\tremaining: 1m 13s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\ttotal: 2.2s\tremaining: 52.2s\n",
      "200:\ttotal: 4.47s\tremaining: 51.1s\n",
      "300:\ttotal: 6.68s\tremaining: 48.8s\n",
      "400:\ttotal: 8.9s\tremaining: 46.6s\n",
      "500:\ttotal: 11.1s\tremaining: 44.1s\n",
      "600:\ttotal: 13.2s\tremaining: 41.6s\n",
      "700:\ttotal: 15.4s\tremaining: 39.6s\n",
      "800:\ttotal: 17.8s\tremaining: 37.7s\n",
      "900:\ttotal: 20s\tremaining: 35.4s\n",
      "1000:\ttotal: 22.1s\tremaining: 33.1s\n",
      "1100:\ttotal: 24.4s\tremaining: 31s\n",
      "1200:\ttotal: 26.6s\tremaining: 28.8s\n",
      "1300:\ttotal: 28.7s\tremaining: 26.4s\n",
      "1400:\ttotal: 30.5s\tremaining: 23.9s\n",
      "1500:\ttotal: 32.3s\tremaining: 21.5s\n",
      "1600:\ttotal: 34.5s\tremaining: 19.4s\n",
      "1700:\ttotal: 36.3s\tremaining: 17.1s\n",
      "1800:\ttotal: 38.2s\tremaining: 14.8s\n",
      "1900:\ttotal: 40.4s\tremaining: 12.7s\n",
      "2000:\ttotal: 42.2s\tremaining: 10.5s\n",
      "2100:\ttotal: 44.1s\tremaining: 8.38s\n",
      "2200:\ttotal: 46.1s\tremaining: 6.26s\n",
      "2300:\ttotal: 47.9s\tremaining: 4.14s\n",
      "2400:\ttotal: 49.8s\tremaining: 2.05s\n",
      "2499:\ttotal: 51.8s\tremaining: 0us\n",
      "0:\ttotal: 20ms\tremaining: 50s\n",
      "100:\ttotal: 1.97s\tremaining: 46.8s\n",
      "200:\ttotal: 4.05s\tremaining: 46.4s\n",
      "300:\ttotal: 6.06s\tremaining: 44.3s\n",
      "400:\ttotal: 8.11s\tremaining: 42.5s\n",
      "500:\ttotal: 10.2s\tremaining: 40.6s\n",
      "600:\ttotal: 12.3s\tremaining: 38.8s\n",
      "700:\ttotal: 14.3s\tremaining: 36.7s\n",
      "800:\ttotal: 16.4s\tremaining: 34.7s\n",
      "900:\ttotal: 18.3s\tremaining: 32.6s\n",
      "1000:\ttotal: 20.2s\tremaining: 30.2s\n",
      "1100:\ttotal: 22.2s\tremaining: 28.2s\n",
      "1200:\ttotal: 24.2s\tremaining: 26.2s\n",
      "1300:\ttotal: 26.2s\tremaining: 24.1s\n",
      "1400:\ttotal: 28s\tremaining: 22s\n",
      "1500:\ttotal: 30s\tremaining: 20s\n",
      "1600:\ttotal: 31.9s\tremaining: 17.9s\n",
      "1700:\ttotal: 33.8s\tremaining: 15.9s\n",
      "1800:\ttotal: 36s\tremaining: 14s\n",
      "1900:\ttotal: 38.5s\tremaining: 12.1s\n",
      "2000:\ttotal: 40.8s\tremaining: 10.2s\n",
      "2100:\ttotal: 42.7s\tremaining: 8.11s\n",
      "2200:\ttotal: 44.6s\tremaining: 6.07s\n",
      "2300:\ttotal: 46.4s\tremaining: 4.01s\n",
      "2400:\ttotal: 48.1s\tremaining: 1.98s\n",
      "2499:\ttotal: 49.8s\tremaining: 0us\n",
      "0:\ttotal: 20.3ms\tremaining: 50.7s\n",
      "100:\ttotal: 1.73s\tremaining: 41s\n",
      "200:\ttotal: 3.5s\tremaining: 40.1s\n",
      "300:\ttotal: 5.39s\tremaining: 39.4s\n",
      "400:\ttotal: 7.29s\tremaining: 38.2s\n",
      "500:\ttotal: 9.46s\tremaining: 37.8s\n",
      "600:\ttotal: 11.3s\tremaining: 35.7s\n",
      "700:\ttotal: 13.2s\tremaining: 33.9s\n",
      "800:\ttotal: 14.9s\tremaining: 31.6s\n",
      "900:\ttotal: 16.5s\tremaining: 29.3s\n",
      "1000:\ttotal: 18.3s\tremaining: 27.4s\n",
      "1100:\ttotal: 20.1s\tremaining: 25.5s\n",
      "1200:\ttotal: 21.8s\tremaining: 23.5s\n",
      "1300:\ttotal: 23.5s\tremaining: 21.7s\n",
      "1400:\ttotal: 25.3s\tremaining: 19.8s\n",
      "1500:\ttotal: 27s\tremaining: 17.9s\n",
      "1600:\ttotal: 28.8s\tremaining: 16.2s\n",
      "1700:\ttotal: 30.7s\tremaining: 14.4s\n",
      "1800:\ttotal: 32.5s\tremaining: 12.6s\n",
      "1900:\ttotal: 34.4s\tremaining: 10.8s\n",
      "2000:\ttotal: 36.8s\tremaining: 9.17s\n",
      "2100:\ttotal: 39s\tremaining: 7.4s\n",
      "2200:\ttotal: 40.8s\tremaining: 5.54s\n",
      "2300:\ttotal: 42.6s\tremaining: 3.69s\n",
      "2400:\ttotal: 44.4s\tremaining: 1.83s\n",
      "2499:\ttotal: 46.2s\tremaining: 0us\n",
      "0:\ttotal: 23.8ms\tremaining: 59.4s\n",
      "100:\ttotal: 1.8s\tremaining: 42.7s\n",
      "200:\ttotal: 3.67s\tremaining: 42s\n",
      "300:\ttotal: 5.54s\tremaining: 40.5s\n",
      "400:\ttotal: 7.55s\tremaining: 39.5s\n",
      "500:\ttotal: 9.68s\tremaining: 38.6s\n",
      "600:\ttotal: 11.9s\tremaining: 37.5s\n",
      "700:\ttotal: 13.8s\tremaining: 35.5s\n",
      "800:\ttotal: 15.7s\tremaining: 33.3s\n",
      "900:\ttotal: 17.8s\tremaining: 31.6s\n",
      "1000:\ttotal: 19.8s\tremaining: 29.6s\n",
      "1100:\ttotal: 21.6s\tremaining: 27.5s\n",
      "1200:\ttotal: 23.8s\tremaining: 25.7s\n",
      "1300:\ttotal: 26s\tremaining: 24s\n",
      "1400:\ttotal: 28.1s\tremaining: 22.1s\n",
      "1500:\ttotal: 30s\tremaining: 20s\n",
      "1600:\ttotal: 31.8s\tremaining: 17.8s\n",
      "1700:\ttotal: 33.8s\tremaining: 15.9s\n",
      "1800:\ttotal: 36.5s\tremaining: 14.2s\n",
      "1900:\ttotal: 39.2s\tremaining: 12.4s\n",
      "2000:\ttotal: 41.8s\tremaining: 10.4s\n",
      "2100:\ttotal: 44.1s\tremaining: 8.38s\n",
      "2200:\ttotal: 46.7s\tremaining: 6.34s\n",
      "2300:\ttotal: 49s\tremaining: 4.24s\n",
      "2400:\ttotal: 51.4s\tremaining: 2.12s\n",
      "2499:\ttotal: 53.6s\tremaining: 0us\n",
      "0:\ttotal: 52.7ms\tremaining: 2m 11s\n",
      "100:\ttotal: 1.75s\tremaining: 41.5s\n",
      "200:\ttotal: 3.54s\tremaining: 40.4s\n",
      "300:\ttotal: 5.36s\tremaining: 39.1s\n",
      "400:\ttotal: 7.43s\tremaining: 38.9s\n",
      "500:\ttotal: 9.42s\tremaining: 37.6s\n",
      "600:\ttotal: 11.3s\tremaining: 35.7s\n",
      "700:\ttotal: 13.1s\tremaining: 33.7s\n",
      "800:\ttotal: 15s\tremaining: 31.8s\n",
      "900:\ttotal: 17s\tremaining: 30.1s\n",
      "1000:\ttotal: 18.8s\tremaining: 28.1s\n",
      "1100:\ttotal: 20.9s\tremaining: 26.5s\n",
      "1200:\ttotal: 23.3s\tremaining: 25.2s\n",
      "1300:\ttotal: 25.6s\tremaining: 23.6s\n",
      "1400:\ttotal: 27.8s\tremaining: 21.8s\n",
      "1500:\ttotal: 30.1s\tremaining: 20s\n",
      "1600:\ttotal: 32.4s\tremaining: 18.2s\n",
      "1700:\ttotal: 34.8s\tremaining: 16.3s\n",
      "1800:\ttotal: 37.3s\tremaining: 14.5s\n",
      "1900:\ttotal: 39.7s\tremaining: 12.5s\n",
      "2000:\ttotal: 42.3s\tremaining: 10.5s\n",
      "2100:\ttotal: 44.8s\tremaining: 8.51s\n",
      "2200:\ttotal: 47.2s\tremaining: 6.41s\n",
      "2300:\ttotal: 49.5s\tremaining: 4.28s\n",
      "2400:\ttotal: 51.9s\tremaining: 2.14s\n",
      "2499:\ttotal: 54.2s\tremaining: 0us\n",
      "0:\ttotal: 28.4ms\tremaining: 1m 11s\n",
      "100:\ttotal: 2.77s\tremaining: 1m 5s\n",
      "200:\ttotal: 5.35s\tremaining: 1m 1s\n",
      "300:\ttotal: 7.88s\tremaining: 57.6s\n",
      "400:\ttotal: 10.4s\tremaining: 54.6s\n",
      "500:\ttotal: 12.6s\tremaining: 50.1s\n",
      "600:\ttotal: 14.7s\tremaining: 46.4s\n",
      "700:\ttotal: 16.6s\tremaining: 42.6s\n",
      "800:\ttotal: 18.8s\tremaining: 39.8s\n",
      "900:\ttotal: 20.9s\tremaining: 37.1s\n",
      "1000:\ttotal: 23.3s\tremaining: 34.8s\n",
      "1100:\ttotal: 25.3s\tremaining: 32.1s\n",
      "1200:\ttotal: 27.1s\tremaining: 29.3s\n",
      "1300:\ttotal: 28.9s\tremaining: 26.6s\n",
      "1400:\ttotal: 30.7s\tremaining: 24.1s\n",
      "1500:\ttotal: 32.5s\tremaining: 21.7s\n",
      "1600:\ttotal: 34.4s\tremaining: 19.3s\n",
      "1700:\ttotal: 36.2s\tremaining: 17s\n",
      "1800:\ttotal: 38.2s\tremaining: 14.8s\n",
      "1900:\ttotal: 40.2s\tremaining: 12.7s\n",
      "2000:\ttotal: 42.1s\tremaining: 10.5s\n",
      "2100:\ttotal: 43.9s\tremaining: 8.34s\n",
      "2200:\ttotal: 45.7s\tremaining: 6.21s\n",
      "2300:\ttotal: 47.6s\tremaining: 4.12s\n",
      "2400:\ttotal: 49.7s\tremaining: 2.05s\n",
      "2499:\ttotal: 51.4s\tremaining: 0us\n",
      "0:\ttotal: 18.7ms\tremaining: 46.9s\n",
      "100:\ttotal: 1.71s\tremaining: 40.6s\n",
      "200:\ttotal: 3.38s\tremaining: 38.6s\n",
      "300:\ttotal: 5.12s\tremaining: 37.4s\n",
      "400:\ttotal: 6.93s\tremaining: 36.3s\n",
      "500:\ttotal: 8.73s\tremaining: 34.9s\n",
      "600:\ttotal: 10.5s\tremaining: 33.3s\n",
      "700:\ttotal: 12.3s\tremaining: 31.5s\n",
      "800:\ttotal: 14s\tremaining: 29.8s\n",
      "900:\ttotal: 15.7s\tremaining: 27.9s\n",
      "1000:\ttotal: 17.5s\tremaining: 26.2s\n",
      "1100:\ttotal: 19.5s\tremaining: 24.8s\n",
      "1200:\ttotal: 21.7s\tremaining: 23.5s\n",
      "1300:\ttotal: 24s\tremaining: 22.2s\n",
      "1400:\ttotal: 26.2s\tremaining: 20.6s\n",
      "1500:\ttotal: 28s\tremaining: 18.6s\n",
      "1600:\ttotal: 29.9s\tremaining: 16.8s\n",
      "1700:\ttotal: 31.6s\tremaining: 14.8s\n",
      "1800:\ttotal: 33.6s\tremaining: 13s\n",
      "1900:\ttotal: 35.6s\tremaining: 11.2s\n",
      "2000:\ttotal: 37.5s\tremaining: 9.35s\n",
      "2100:\ttotal: 39.5s\tremaining: 7.5s\n",
      "2200:\ttotal: 41.4s\tremaining: 5.63s\n",
      "2300:\ttotal: 43.6s\tremaining: 3.77s\n",
      "2400:\ttotal: 45.9s\tremaining: 1.89s\n",
      "2499:\ttotal: 48.3s\tremaining: 0us\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.9741  \u001b[0m | \u001b[0m 0.1942  \u001b[0m | \u001b[0m 5.728   \u001b[0m | \u001b[0m 0.4024  \u001b[0m |\n",
      "0:\ttotal: 46.4ms\tremaining: 1m 55s\n",
      "100:\ttotal: 3.46s\tremaining: 1m 22s\n",
      "200:\ttotal: 6.68s\tremaining: 1m 16s\n",
      "300:\ttotal: 9.98s\tremaining: 1m 12s\n",
      "400:\ttotal: 13.2s\tremaining: 1m 8s\n",
      "500:\ttotal: 16.5s\tremaining: 1m 5s\n",
      "600:\ttotal: 19.6s\tremaining: 1m 1s\n",
      "700:\ttotal: 22.9s\tremaining: 58.7s\n",
      "800:\ttotal: 25.8s\tremaining: 54.7s\n",
      "900:\ttotal: 28.8s\tremaining: 51.1s\n",
      "1000:\ttotal: 32s\tremaining: 47.9s\n",
      "1100:\ttotal: 35.3s\tremaining: 44.8s\n",
      "1200:\ttotal: 38.4s\tremaining: 41.5s\n",
      "1300:\ttotal: 41.4s\tremaining: 38.2s\n",
      "1400:\ttotal: 44.3s\tremaining: 34.8s\n",
      "1500:\ttotal: 47.3s\tremaining: 31.5s\n",
      "1600:\ttotal: 50.5s\tremaining: 28.3s\n",
      "1700:\ttotal: 53.5s\tremaining: 25.1s\n",
      "1800:\ttotal: 56.5s\tremaining: 21.9s\n",
      "1900:\ttotal: 59.4s\tremaining: 18.7s\n",
      "2000:\ttotal: 1m 2s\tremaining: 15.5s\n",
      "2100:\ttotal: 1m 5s\tremaining: 12.4s\n",
      "2200:\ttotal: 1m 8s\tremaining: 9.27s\n",
      "2300:\ttotal: 1m 11s\tremaining: 6.16s\n",
      "2400:\ttotal: 1m 14s\tremaining: 3.05s\n",
      "2499:\ttotal: 1m 16s\tremaining: 0us\n",
      "0:\ttotal: 36.8ms\tremaining: 1m 31s\n",
      "100:\ttotal: 2.93s\tremaining: 1m 9s\n",
      "200:\ttotal: 5.83s\tremaining: 1m 6s\n",
      "300:\ttotal: 8.72s\tremaining: 1m 3s\n",
      "400:\ttotal: 11.7s\tremaining: 1m 1s\n",
      "500:\ttotal: 14.9s\tremaining: 59.5s\n",
      "600:\ttotal: 17.9s\tremaining: 56.5s\n",
      "700:\ttotal: 20.8s\tremaining: 53.4s\n",
      "800:\ttotal: 23.8s\tremaining: 50.4s\n",
      "900:\ttotal: 26.7s\tremaining: 47.4s\n",
      "1000:\ttotal: 29.6s\tremaining: 44.3s\n",
      "1100:\ttotal: 32.7s\tremaining: 41.6s\n",
      "1200:\ttotal: 35.6s\tremaining: 38.5s\n",
      "1300:\ttotal: 38.5s\tremaining: 35.5s\n",
      "1400:\ttotal: 41.5s\tremaining: 32.6s\n",
      "1500:\ttotal: 44.4s\tremaining: 29.6s\n",
      "1600:\ttotal: 47.7s\tremaining: 26.8s\n",
      "1700:\ttotal: 51.1s\tremaining: 24s\n",
      "1800:\ttotal: 54.3s\tremaining: 21.1s\n",
      "1900:\ttotal: 57.3s\tremaining: 18.1s\n",
      "2000:\ttotal: 1m\tremaining: 15.1s\n",
      "2100:\ttotal: 1m 3s\tremaining: 12.1s\n",
      "2200:\ttotal: 1m 6s\tremaining: 9.06s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300:\ttotal: 1m 9s\tremaining: 6.03s\n",
      "2400:\ttotal: 1m 12s\tremaining: 3s\n",
      "2499:\ttotal: 1m 15s\tremaining: 0us\n",
      "0:\ttotal: 33.7ms\tremaining: 1m 24s\n",
      "100:\ttotal: 3.1s\tremaining: 1m 13s\n",
      "200:\ttotal: 6.16s\tremaining: 1m 10s\n",
      "300:\ttotal: 9.4s\tremaining: 1m 8s\n",
      "400:\ttotal: 12.6s\tremaining: 1m 5s\n",
      "500:\ttotal: 15.7s\tremaining: 1m 2s\n",
      "600:\ttotal: 18.7s\tremaining: 59.2s\n",
      "700:\ttotal: 21.8s\tremaining: 55.9s\n",
      "800:\ttotal: 24.7s\tremaining: 52.4s\n",
      "900:\ttotal: 27.6s\tremaining: 49s\n",
      "1000:\ttotal: 30.5s\tremaining: 45.6s\n",
      "1100:\ttotal: 33.5s\tremaining: 42.6s\n",
      "1200:\ttotal: 36.5s\tremaining: 39.5s\n",
      "1300:\ttotal: 39.4s\tremaining: 36.3s\n",
      "1400:\ttotal: 42.4s\tremaining: 33.3s\n",
      "1500:\ttotal: 45.4s\tremaining: 30.2s\n",
      "1600:\ttotal: 48.4s\tremaining: 27.2s\n",
      "1700:\ttotal: 51.4s\tremaining: 24.1s\n",
      "1800:\ttotal: 54.3s\tremaining: 21.1s\n",
      "1900:\ttotal: 57.6s\tremaining: 18.1s\n",
      "2000:\ttotal: 1m\tremaining: 15.1s\n",
      "2100:\ttotal: 1m 3s\tremaining: 12.1s\n",
      "2200:\ttotal: 1m 6s\tremaining: 9.02s\n",
      "2300:\ttotal: 1m 9s\tremaining: 6s\n",
      "2400:\ttotal: 1m 12s\tremaining: 2.98s\n",
      "2499:\ttotal: 1m 15s\tremaining: 0us\n",
      "0:\ttotal: 32ms\tremaining: 1m 20s\n",
      "100:\ttotal: 2.89s\tremaining: 1m 8s\n",
      "200:\ttotal: 5.84s\tremaining: 1m 6s\n",
      "300:\ttotal: 8.83s\tremaining: 1m 4s\n",
      "400:\ttotal: 11.8s\tremaining: 1m 1s\n",
      "500:\ttotal: 14.7s\tremaining: 58.7s\n",
      "600:\ttotal: 17.6s\tremaining: 55.7s\n",
      "700:\ttotal: 20.6s\tremaining: 53s\n",
      "800:\ttotal: 23.5s\tremaining: 49.9s\n",
      "900:\ttotal: 26.3s\tremaining: 46.8s\n",
      "1000:\ttotal: 29.2s\tremaining: 43.7s\n",
      "1100:\ttotal: 32.2s\tremaining: 41s\n",
      "1200:\ttotal: 35.1s\tremaining: 38s\n",
      "1300:\ttotal: 38s\tremaining: 35s\n",
      "1400:\ttotal: 41.1s\tremaining: 32.2s\n",
      "1500:\ttotal: 44.2s\tremaining: 29.4s\n",
      "1600:\ttotal: 47.2s\tremaining: 26.5s\n",
      "1700:\ttotal: 50.3s\tremaining: 23.6s\n",
      "1800:\ttotal: 53.5s\tremaining: 20.8s\n",
      "1900:\ttotal: 56.8s\tremaining: 17.9s\n",
      "2000:\ttotal: 59.8s\tremaining: 14.9s\n",
      "2100:\ttotal: 1m 2s\tremaining: 11.9s\n",
      "2200:\ttotal: 1m 5s\tremaining: 8.93s\n",
      "2300:\ttotal: 1m 8s\tremaining: 5.94s\n",
      "2400:\ttotal: 1m 11s\tremaining: 2.95s\n",
      "2499:\ttotal: 1m 14s\tremaining: 0us\n",
      "0:\ttotal: 32.2ms\tremaining: 1m 20s\n",
      "100:\ttotal: 3.07s\tremaining: 1m 12s\n",
      "200:\ttotal: 6.33s\tremaining: 1m 12s\n",
      "300:\ttotal: 9.43s\tremaining: 1m 8s\n",
      "400:\ttotal: 12.7s\tremaining: 1m 6s\n",
      "500:\ttotal: 16.1s\tremaining: 1m 4s\n",
      "600:\ttotal: 19.2s\tremaining: 1m\n",
      "700:\ttotal: 22.3s\tremaining: 57.3s\n",
      "800:\ttotal: 25.6s\tremaining: 54.2s\n",
      "900:\ttotal: 28.8s\tremaining: 51.2s\n",
      "1000:\ttotal: 32s\tremaining: 48s\n",
      "1100:\ttotal: 35.4s\tremaining: 45s\n",
      "1200:\ttotal: 38.6s\tremaining: 41.7s\n",
      "1300:\ttotal: 41.6s\tremaining: 38.3s\n",
      "1400:\ttotal: 44.6s\tremaining: 35s\n",
      "1500:\ttotal: 47.7s\tremaining: 31.8s\n",
      "1600:\ttotal: 50.7s\tremaining: 28.5s\n",
      "1700:\ttotal: 53.7s\tremaining: 25.2s\n",
      "1800:\ttotal: 56.7s\tremaining: 22s\n",
      "1900:\ttotal: 59.9s\tremaining: 18.9s\n",
      "2000:\ttotal: 1m 2s\tremaining: 15.7s\n",
      "2100:\ttotal: 1m 6s\tremaining: 12.6s\n",
      "2200:\ttotal: 1m 9s\tremaining: 9.47s\n",
      "2300:\ttotal: 1m 12s\tremaining: 6.31s\n",
      "2400:\ttotal: 1m 16s\tremaining: 3.13s\n",
      "2499:\ttotal: 1m 19s\tremaining: 0us\n",
      "0:\ttotal: 38.8ms\tremaining: 1m 36s\n",
      "100:\ttotal: 3.29s\tremaining: 1m 18s\n",
      "200:\ttotal: 6.4s\tremaining: 1m 13s\n",
      "300:\ttotal: 9.5s\tremaining: 1m 9s\n",
      "400:\ttotal: 12.7s\tremaining: 1m 6s\n",
      "500:\ttotal: 15.8s\tremaining: 1m 3s\n",
      "600:\ttotal: 19s\tremaining: 59.9s\n",
      "700:\ttotal: 22.1s\tremaining: 56.7s\n",
      "800:\ttotal: 25.2s\tremaining: 53.5s\n",
      "900:\ttotal: 28.5s\tremaining: 50.6s\n",
      "1000:\ttotal: 31.8s\tremaining: 47.7s\n",
      "1100:\ttotal: 35s\tremaining: 44.5s\n",
      "1200:\ttotal: 38.1s\tremaining: 41.2s\n",
      "1300:\ttotal: 42s\tremaining: 38.7s\n",
      "1400:\ttotal: 45.5s\tremaining: 35.7s\n",
      "1500:\ttotal: 48.9s\tremaining: 32.6s\n",
      "1600:\ttotal: 52s\tremaining: 29.2s\n",
      "1700:\ttotal: 55.1s\tremaining: 25.9s\n",
      "1800:\ttotal: 58.2s\tremaining: 22.6s\n",
      "1900:\ttotal: 1m 1s\tremaining: 19.3s\n",
      "2000:\ttotal: 1m 4s\tremaining: 16.1s\n",
      "2100:\ttotal: 1m 7s\tremaining: 12.9s\n",
      "2200:\ttotal: 1m 10s\tremaining: 9.63s\n",
      "2300:\ttotal: 1m 14s\tremaining: 6.42s\n",
      "2400:\ttotal: 1m 17s\tremaining: 3.19s\n",
      "2499:\ttotal: 1m 20s\tremaining: 0us\n",
      "0:\ttotal: 32.3ms\tremaining: 1m 20s\n",
      "100:\ttotal: 3.1s\tremaining: 1m 13s\n",
      "200:\ttotal: 6.19s\tremaining: 1m 10s\n",
      "300:\ttotal: 9.26s\tremaining: 1m 7s\n",
      "400:\ttotal: 12.4s\tremaining: 1m 4s\n",
      "500:\ttotal: 15.5s\tremaining: 1m 1s\n",
      "600:\ttotal: 18.6s\tremaining: 58.6s\n",
      "700:\ttotal: 21.6s\tremaining: 55.5s\n",
      "800:\ttotal: 24.7s\tremaining: 52.4s\n",
      "900:\ttotal: 28s\tremaining: 49.7s\n",
      "1000:\ttotal: 31.2s\tremaining: 46.8s\n",
      "1100:\ttotal: 34.5s\tremaining: 43.8s\n",
      "1200:\ttotal: 37.6s\tremaining: 40.7s\n",
      "1300:\ttotal: 40.6s\tremaining: 37.4s\n",
      "1400:\ttotal: 43.6s\tremaining: 34.2s\n",
      "1500:\ttotal: 46.6s\tremaining: 31s\n",
      "1600:\ttotal: 49.6s\tremaining: 27.9s\n",
      "1700:\ttotal: 52.9s\tremaining: 24.8s\n",
      "1800:\ttotal: 56.3s\tremaining: 21.8s\n",
      "1900:\ttotal: 59.4s\tremaining: 18.7s\n",
      "2000:\ttotal: 1m 2s\tremaining: 15.6s\n",
      "2100:\ttotal: 1m 6s\tremaining: 12.5s\n",
      "2200:\ttotal: 1m 10s\tremaining: 9.63s\n",
      "2300:\ttotal: 1m 14s\tremaining: 6.43s\n",
      "2400:\ttotal: 1m 17s\tremaining: 3.2s\n",
      "2499:\ttotal: 1m 21s\tremaining: 0us\n",
      "0:\ttotal: 37.7ms\tremaining: 1m 34s\n",
      "100:\ttotal: 3.36s\tremaining: 1m 19s\n",
      "200:\ttotal: 6.67s\tremaining: 1m 16s\n",
      "300:\ttotal: 9.77s\tremaining: 1m 11s\n",
      "400:\ttotal: 13s\tremaining: 1m 8s\n",
      "500:\ttotal: 16.2s\tremaining: 1m 4s\n",
      "600:\ttotal: 19.4s\tremaining: 1m 1s\n",
      "700:\ttotal: 23.1s\tremaining: 59.4s\n",
      "800:\ttotal: 26.3s\tremaining: 55.8s\n",
      "900:\ttotal: 29.9s\tremaining: 53s\n",
      "1000:\ttotal: 33.3s\tremaining: 49.9s\n",
      "1100:\ttotal: 37.2s\tremaining: 47.3s\n",
      "1200:\ttotal: 40.7s\tremaining: 44s\n",
      "1300:\ttotal: 43.9s\tremaining: 40.5s\n",
      "1400:\ttotal: 47.5s\tremaining: 37.3s\n",
      "1500:\ttotal: 51.2s\tremaining: 34.1s\n",
      "1600:\ttotal: 54.7s\tremaining: 30.7s\n",
      "1700:\ttotal: 58s\tremaining: 27.2s\n",
      "1800:\ttotal: 1m 1s\tremaining: 23.7s\n",
      "1900:\ttotal: 1m 4s\tremaining: 20.3s\n",
      "2000:\ttotal: 1m 7s\tremaining: 16.9s\n",
      "2100:\ttotal: 1m 10s\tremaining: 13.5s\n",
      "2200:\ttotal: 1m 14s\tremaining: 10.1s\n",
      "2300:\ttotal: 1m 17s\tremaining: 6.69s\n",
      "2400:\ttotal: 1m 20s\tremaining: 3.33s\n",
      "2499:\ttotal: 1m 23s\tremaining: 0us\n",
      "0:\ttotal: 40.2ms\tremaining: 1m 40s\n",
      "100:\ttotal: 3.23s\tremaining: 1m 16s\n",
      "200:\ttotal: 6.86s\tremaining: 1m 18s\n",
      "300:\ttotal: 10.1s\tremaining: 1m 13s\n",
      "400:\ttotal: 13.5s\tremaining: 1m 10s\n",
      "500:\ttotal: 17.1s\tremaining: 1m 8s\n",
      "600:\ttotal: 20.8s\tremaining: 1m 5s\n",
      "700:\ttotal: 24.6s\tremaining: 1m 3s\n",
      "800:\ttotal: 28.1s\tremaining: 59.5s\n",
      "900:\ttotal: 31.7s\tremaining: 56.3s\n",
      "1000:\ttotal: 35.6s\tremaining: 53.3s\n",
      "1100:\ttotal: 39.4s\tremaining: 50s\n",
      "1200:\ttotal: 43.7s\tremaining: 47.3s\n",
      "1300:\ttotal: 47.3s\tremaining: 43.6s\n",
      "1400:\ttotal: 50.6s\tremaining: 39.7s\n",
      "1500:\ttotal: 53.9s\tremaining: 35.8s\n",
      "1600:\ttotal: 57.3s\tremaining: 32.2s\n",
      "1700:\ttotal: 1m\tremaining: 28.4s\n",
      "1800:\ttotal: 1m 3s\tremaining: 24.6s\n",
      "1900:\ttotal: 1m 6s\tremaining: 20.9s\n",
      "2000:\ttotal: 1m 9s\tremaining: 17.3s\n",
      "2100:\ttotal: 1m 12s\tremaining: 13.7s\n",
      "2200:\ttotal: 1m 15s\tremaining: 10.2s\n",
      "2300:\ttotal: 1m 18s\tremaining: 6.75s\n",
      "2400:\ttotal: 1m 21s\tremaining: 3.34s\n",
      "2499:\ttotal: 1m 23s\tremaining: 0us\n",
      "0:\ttotal: 60.8ms\tremaining: 2m 32s\n",
      "100:\ttotal: 3s\tremaining: 1m 11s\n",
      "200:\ttotal: 6.01s\tremaining: 1m 8s\n",
      "300:\ttotal: 9.03s\tremaining: 1m 5s\n",
      "400:\ttotal: 12s\tremaining: 1m 3s\n",
      "500:\ttotal: 15s\tremaining: 59.9s\n",
      "600:\ttotal: 18.1s\tremaining: 57.2s\n",
      "700:\ttotal: 21.1s\tremaining: 54.3s\n",
      "800:\ttotal: 24.1s\tremaining: 51.2s\n",
      "900:\ttotal: 27.2s\tremaining: 48.2s\n",
      "1000:\ttotal: 30.2s\tremaining: 45.2s\n",
      "1100:\ttotal: 33.4s\tremaining: 42.4s\n",
      "1200:\ttotal: 36.4s\tremaining: 39.3s\n",
      "1300:\ttotal: 39.3s\tremaining: 36.2s\n",
      "1400:\ttotal: 42.2s\tremaining: 33.1s\n",
      "1500:\ttotal: 45.2s\tremaining: 30.1s\n",
      "1600:\ttotal: 48.1s\tremaining: 27s\n",
      "1700:\ttotal: 51s\tremaining: 23.9s\n",
      "1800:\ttotal: 53.8s\tremaining: 20.9s\n",
      "1900:\ttotal: 56.6s\tremaining: 17.8s\n",
      "2000:\ttotal: 59.6s\tremaining: 14.8s\n",
      "2100:\ttotal: 1m 2s\tremaining: 11.9s\n",
      "2200:\ttotal: 1m 5s\tremaining: 8.9s\n",
      "2300:\ttotal: 1m 8s\tremaining: 5.92s\n",
      "2400:\ttotal: 1m 11s\tremaining: 2.95s\n",
      "2499:\ttotal: 1m 14s\tremaining: 0us\n",
      "0:\ttotal: 58.7ms\tremaining: 2m 26s\n",
      "100:\ttotal: 3.26s\tremaining: 1m 17s\n",
      "200:\ttotal: 6.35s\tremaining: 1m 12s\n",
      "300:\ttotal: 9.38s\tremaining: 1m 8s\n",
      "400:\ttotal: 12.4s\tremaining: 1m 5s\n",
      "500:\ttotal: 15.4s\tremaining: 1m 1s\n",
      "600:\ttotal: 18.6s\tremaining: 58.8s\n",
      "700:\ttotal: 21.6s\tremaining: 55.4s\n",
      "800:\ttotal: 24.5s\tremaining: 51.9s\n",
      "900:\ttotal: 27.4s\tremaining: 48.5s\n",
      "1000:\ttotal: 30.4s\tremaining: 45.5s\n",
      "1100:\ttotal: 33.6s\tremaining: 42.7s\n",
      "1200:\ttotal: 36.6s\tremaining: 39.6s\n",
      "1300:\ttotal: 39.6s\tremaining: 36.5s\n",
      "1400:\ttotal: 42.5s\tremaining: 33.4s\n",
      "1500:\ttotal: 45.5s\tremaining: 30.3s\n",
      "1600:\ttotal: 48.4s\tremaining: 27.2s\n",
      "1700:\ttotal: 51.3s\tremaining: 24.1s\n",
      "1800:\ttotal: 54.3s\tremaining: 21.1s\n",
      "1900:\ttotal: 57.4s\tremaining: 18.1s\n",
      "2000:\ttotal: 1m\tremaining: 15.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100:\ttotal: 1m 3s\tremaining: 12.1s\n",
      "2200:\ttotal: 1m 6s\tremaining: 9.07s\n",
      "2300:\ttotal: 1m 9s\tremaining: 6.04s\n",
      "2400:\ttotal: 1m 12s\tremaining: 3.01s\n",
      "2499:\ttotal: 1m 15s\tremaining: 0us\n",
      "0:\ttotal: 35.7ms\tremaining: 1m 29s\n",
      "100:\ttotal: 3.03s\tremaining: 1m 11s\n",
      "200:\ttotal: 6.03s\tremaining: 1m 8s\n",
      "300:\ttotal: 9.01s\tremaining: 1m 5s\n",
      "400:\ttotal: 11.9s\tremaining: 1m 2s\n",
      "500:\ttotal: 14.9s\tremaining: 59.5s\n",
      "600:\ttotal: 17.8s\tremaining: 56.3s\n",
      "700:\ttotal: 20.9s\tremaining: 53.5s\n",
      "800:\ttotal: 23.9s\tremaining: 50.7s\n",
      "900:\ttotal: 27s\tremaining: 47.9s\n",
      "1000:\ttotal: 30s\tremaining: 44.9s\n",
      "1100:\ttotal: 33.2s\tremaining: 42.2s\n",
      "1200:\ttotal: 36.2s\tremaining: 39.1s\n",
      "1300:\ttotal: 39.3s\tremaining: 36.2s\n",
      "1400:\ttotal: 42.4s\tremaining: 33.2s\n",
      "1500:\ttotal: 45.4s\tremaining: 30.2s\n",
      "1600:\ttotal: 48.6s\tremaining: 27.3s\n",
      "1700:\ttotal: 51.7s\tremaining: 24.3s\n",
      "1800:\ttotal: 54.7s\tremaining: 21.2s\n",
      "1900:\ttotal: 57.7s\tremaining: 18.2s\n",
      "2000:\ttotal: 1m 1s\tremaining: 15.2s\n",
      "2100:\ttotal: 1m 4s\tremaining: 12.2s\n",
      "2200:\ttotal: 1m 7s\tremaining: 9.14s\n",
      "2300:\ttotal: 1m 10s\tremaining: 6.08s\n",
      "2400:\ttotal: 1m 13s\tremaining: 3.03s\n",
      "2499:\ttotal: 1m 16s\tremaining: 0us\n",
      "0:\ttotal: 71.8ms\tremaining: 2m 59s\n",
      "100:\ttotal: 3s\tremaining: 1m 11s\n",
      "200:\ttotal: 5.95s\tremaining: 1m 8s\n",
      "300:\ttotal: 8.94s\tremaining: 1m 5s\n",
      "400:\ttotal: 12s\tremaining: 1m 2s\n",
      "500:\ttotal: 15s\tremaining: 59.9s\n",
      "600:\ttotal: 18s\tremaining: 56.8s\n",
      "700:\ttotal: 21s\tremaining: 54s\n",
      "800:\ttotal: 24s\tremaining: 50.9s\n",
      "900:\ttotal: 27s\tremaining: 47.8s\n",
      "1000:\ttotal: 30s\tremaining: 45s\n",
      "1100:\ttotal: 33.3s\tremaining: 42.3s\n",
      "1200:\ttotal: 36.3s\tremaining: 39.3s\n",
      "1300:\ttotal: 39.4s\tremaining: 36.3s\n",
      "1400:\ttotal: 42.5s\tremaining: 33.3s\n",
      "1500:\ttotal: 45.6s\tremaining: 30.4s\n",
      "1600:\ttotal: 48.7s\tremaining: 27.4s\n",
      "1700:\ttotal: 51.9s\tremaining: 24.4s\n",
      "1800:\ttotal: 55s\tremaining: 21.3s\n",
      "1900:\ttotal: 58.1s\tremaining: 18.3s\n",
      "2000:\ttotal: 1m 1s\tremaining: 15.3s\n",
      "2100:\ttotal: 1m 4s\tremaining: 12.2s\n",
      "2200:\ttotal: 1m 7s\tremaining: 9.14s\n",
      "2300:\ttotal: 1m 10s\tremaining: 6.08s\n",
      "2400:\ttotal: 1m 13s\tremaining: 3.02s\n",
      "2499:\ttotal: 1m 16s\tremaining: 0us\n",
      "0:\ttotal: 32ms\tremaining: 1m 20s\n",
      "100:\ttotal: 2.94s\tremaining: 1m 9s\n",
      "200:\ttotal: 5.83s\tremaining: 1m 6s\n",
      "300:\ttotal: 8.71s\tremaining: 1m 3s\n",
      "400:\ttotal: 11.6s\tremaining: 1m\n",
      "500:\ttotal: 14.6s\tremaining: 58.2s\n",
      "600:\ttotal: 17.6s\tremaining: 55.6s\n",
      "700:\ttotal: 20.6s\tremaining: 53s\n",
      "800:\ttotal: 23.7s\tremaining: 50.3s\n",
      "900:\ttotal: 27s\tremaining: 47.9s\n",
      "1000:\ttotal: 30.1s\tremaining: 45.1s\n",
      "1100:\ttotal: 33.3s\tremaining: 42.3s\n",
      "1200:\ttotal: 36.3s\tremaining: 39.2s\n",
      "1300:\ttotal: 39.2s\tremaining: 36.1s\n",
      "1400:\ttotal: 42.1s\tremaining: 33s\n",
      "1500:\ttotal: 45s\tremaining: 30s\n",
      "1600:\ttotal: 48s\tremaining: 26.9s\n",
      "1700:\ttotal: 51s\tremaining: 24s\n",
      "1800:\ttotal: 54s\tremaining: 21s\n",
      "1900:\ttotal: 57s\tremaining: 18s\n",
      "2000:\ttotal: 1m\tremaining: 15s\n",
      "2100:\ttotal: 1m 3s\tremaining: 12s\n",
      "2200:\ttotal: 1m 6s\tremaining: 8.97s\n",
      "2300:\ttotal: 1m 9s\tremaining: 5.97s\n",
      "2400:\ttotal: 1m 11s\tremaining: 2.97s\n",
      "2499:\ttotal: 1m 15s\tremaining: 0us\n",
      "0:\ttotal: 36ms\tremaining: 1m 29s\n",
      "100:\ttotal: 3.16s\tremaining: 1m 15s\n",
      "200:\ttotal: 6.07s\tremaining: 1m 9s\n",
      "300:\ttotal: 8.96s\tremaining: 1m 5s\n",
      "400:\ttotal: 11.9s\tremaining: 1m 2s\n",
      "500:\ttotal: 14.8s\tremaining: 59.2s\n",
      "600:\ttotal: 17.9s\tremaining: 56.4s\n",
      "700:\ttotal: 20.9s\tremaining: 53.6s\n",
      "800:\ttotal: 23.9s\tremaining: 50.7s\n",
      "900:\ttotal: 27s\tremaining: 47.9s\n",
      "1000:\ttotal: 30.1s\tremaining: 45.1s\n",
      "1100:\ttotal: 33.4s\tremaining: 42.4s\n",
      "1200:\ttotal: 36.4s\tremaining: 39.4s\n",
      "1300:\ttotal: 39.4s\tremaining: 36.3s\n",
      "1400:\ttotal: 42.4s\tremaining: 33.3s\n",
      "1500:\ttotal: 45.4s\tremaining: 30.2s\n",
      "1600:\ttotal: 48.4s\tremaining: 27.2s\n",
      "1700:\ttotal: 51.4s\tremaining: 24.1s\n",
      "1800:\ttotal: 54.3s\tremaining: 21.1s\n",
      "1900:\ttotal: 57.3s\tremaining: 18s\n",
      "2000:\ttotal: 1m\tremaining: 15.1s\n",
      "2100:\ttotal: 1m 3s\tremaining: 12.1s\n",
      "2200:\ttotal: 1m 6s\tremaining: 9.03s\n",
      "2300:\ttotal: 1m 9s\tremaining: 6.03s\n",
      "2400:\ttotal: 1m 12s\tremaining: 3.01s\n",
      "2499:\ttotal: 1m 15s\tremaining: 0us\n",
      "0:\ttotal: 37.1ms\tremaining: 1m 32s\n",
      "100:\ttotal: 3.03s\tremaining: 1m 11s\n",
      "200:\ttotal: 6.25s\tremaining: 1m 11s\n",
      "300:\ttotal: 9.46s\tremaining: 1m 9s\n",
      "400:\ttotal: 12.7s\tremaining: 1m 6s\n",
      "500:\ttotal: 15.7s\tremaining: 1m 2s\n",
      "600:\ttotal: 18.6s\tremaining: 58.9s\n",
      "700:\ttotal: 21.6s\tremaining: 55.5s\n",
      "800:\ttotal: 24.7s\tremaining: 52.4s\n",
      "900:\ttotal: 27.8s\tremaining: 49.3s\n",
      "1000:\ttotal: 30.9s\tremaining: 46.2s\n",
      "1100:\ttotal: 34.2s\tremaining: 43.4s\n",
      "1200:\ttotal: 37.3s\tremaining: 40.3s\n",
      "1300:\ttotal: 40.5s\tremaining: 37.3s\n",
      "1400:\ttotal: 43.7s\tremaining: 34.2s\n",
      "1500:\ttotal: 46.6s\tremaining: 31s\n",
      "1600:\ttotal: 49.6s\tremaining: 27.9s\n",
      "1700:\ttotal: 52.6s\tremaining: 24.7s\n",
      "1800:\ttotal: 55.5s\tremaining: 21.6s\n",
      "1900:\ttotal: 58.5s\tremaining: 18.4s\n",
      "2000:\ttotal: 1m 1s\tremaining: 15.3s\n",
      "2100:\ttotal: 1m 4s\tremaining: 12.2s\n",
      "2200:\ttotal: 1m 7s\tremaining: 9.17s\n",
      "2300:\ttotal: 1m 10s\tremaining: 6.1s\n",
      "2400:\ttotal: 1m 13s\tremaining: 3.04s\n",
      "2499:\ttotal: 1m 16s\tremaining: 0us\n",
      "0:\ttotal: 55.8ms\tremaining: 2m 19s\n",
      "100:\ttotal: 3.1s\tremaining: 1m 13s\n",
      "200:\ttotal: 6.31s\tremaining: 1m 12s\n",
      "300:\ttotal: 9.35s\tremaining: 1m 8s\n",
      "400:\ttotal: 12.3s\tremaining: 1m 4s\n",
      "500:\ttotal: 15.3s\tremaining: 1m 1s\n",
      "600:\ttotal: 18.4s\tremaining: 58.3s\n",
      "700:\ttotal: 21.5s\tremaining: 55.3s\n",
      "800:\ttotal: 24.7s\tremaining: 52.3s\n",
      "900:\ttotal: 27.8s\tremaining: 49.4s\n",
      "1000:\ttotal: 30.8s\tremaining: 46.2s\n",
      "1100:\ttotal: 34s\tremaining: 43.2s\n",
      "1200:\ttotal: 37.3s\tremaining: 40.3s\n",
      "1300:\ttotal: 40.3s\tremaining: 37.2s\n",
      "1400:\ttotal: 43.3s\tremaining: 34s\n",
      "1500:\ttotal: 46.3s\tremaining: 30.8s\n",
      "1600:\ttotal: 49.2s\tremaining: 27.6s\n",
      "1700:\ttotal: 52.2s\tremaining: 24.5s\n",
      "1800:\ttotal: 55.1s\tremaining: 21.4s\n",
      "1900:\ttotal: 58s\tremaining: 18.3s\n",
      "2000:\ttotal: 1m\tremaining: 15.2s\n",
      "2100:\ttotal: 1m 3s\tremaining: 12.1s\n",
      "2200:\ttotal: 1m 6s\tremaining: 9.08s\n",
      "2300:\ttotal: 1m 9s\tremaining: 6.04s\n",
      "2400:\ttotal: 1m 12s\tremaining: 3s\n",
      "2499:\ttotal: 1m 15s\tremaining: 0us\n",
      "0:\ttotal: 37.7ms\tremaining: 1m 34s\n",
      "100:\ttotal: 3.06s\tremaining: 1m 12s\n",
      "200:\ttotal: 6.08s\tremaining: 1m 9s\n",
      "300:\ttotal: 9.12s\tremaining: 1m 6s\n",
      "400:\ttotal: 12.3s\tremaining: 1m 4s\n",
      "500:\ttotal: 15.3s\tremaining: 1m 1s\n",
      "600:\ttotal: 18.4s\tremaining: 58.1s\n",
      "700:\ttotal: 21.5s\tremaining: 55.1s\n",
      "800:\ttotal: 24.5s\tremaining: 51.9s\n",
      "900:\ttotal: 27.5s\tremaining: 48.8s\n",
      "1000:\ttotal: 30.5s\tremaining: 45.6s\n",
      "1100:\ttotal: 33.6s\tremaining: 42.7s\n",
      "1200:\ttotal: 36.5s\tremaining: 39.5s\n",
      "1300:\ttotal: 39.5s\tremaining: 36.4s\n",
      "1400:\ttotal: 42.5s\tremaining: 33.3s\n",
      "1500:\ttotal: 45.5s\tremaining: 30.3s\n",
      "1600:\ttotal: 48.5s\tremaining: 27.2s\n",
      "1700:\ttotal: 51.5s\tremaining: 24.2s\n",
      "1800:\ttotal: 54.6s\tremaining: 21.2s\n",
      "1900:\ttotal: 57.8s\tremaining: 18.2s\n",
      "2000:\ttotal: 1m\tremaining: 15.2s\n",
      "2100:\ttotal: 1m 3s\tremaining: 12.1s\n",
      "2200:\ttotal: 1m 6s\tremaining: 9.1s\n",
      "2300:\ttotal: 1m 10s\tremaining: 6.06s\n",
      "2400:\ttotal: 1m 13s\tremaining: 3.01s\n",
      "2499:\ttotal: 1m 15s\tremaining: 0us\n",
      "0:\ttotal: 58.5ms\tremaining: 2m 26s\n",
      "100:\ttotal: 3.12s\tremaining: 1m 14s\n",
      "200:\ttotal: 6.19s\tremaining: 1m 10s\n",
      "300:\ttotal: 9.19s\tremaining: 1m 7s\n",
      "400:\ttotal: 12.3s\tremaining: 1m 4s\n",
      "500:\ttotal: 15.3s\tremaining: 1m 1s\n",
      "600:\ttotal: 18.3s\tremaining: 58s\n",
      "700:\ttotal: 21.4s\tremaining: 54.9s\n",
      "800:\ttotal: 24.3s\tremaining: 51.6s\n",
      "900:\ttotal: 27.3s\tremaining: 48.5s\n",
      "1000:\ttotal: 30.3s\tremaining: 45.4s\n",
      "1100:\ttotal: 33.5s\tremaining: 42.5s\n",
      "1200:\ttotal: 36.4s\tremaining: 39.4s\n",
      "1300:\ttotal: 39.4s\tremaining: 36.3s\n",
      "1400:\ttotal: 42.4s\tremaining: 33.3s\n",
      "1500:\ttotal: 45.4s\tremaining: 30.2s\n",
      "1600:\ttotal: 48.4s\tremaining: 27.2s\n",
      "1700:\ttotal: 51.3s\tremaining: 24.1s\n",
      "1800:\ttotal: 54.3s\tremaining: 21.1s\n",
      "1900:\ttotal: 57.3s\tremaining: 18s\n",
      "2000:\ttotal: 1m\tremaining: 15s\n",
      "2100:\ttotal: 1m 3s\tremaining: 12s\n",
      "2200:\ttotal: 1m 6s\tremaining: 8.98s\n",
      "2300:\ttotal: 1m 9s\tremaining: 5.98s\n",
      "2400:\ttotal: 1m 12s\tremaining: 2.98s\n",
      "2499:\ttotal: 1m 15s\tremaining: 0us\n",
      "0:\ttotal: 31.8ms\tremaining: 1m 19s\n",
      "100:\ttotal: 3.14s\tremaining: 1m 14s\n",
      "200:\ttotal: 6.28s\tremaining: 1m 11s\n",
      "300:\ttotal: 9.33s\tremaining: 1m 8s\n",
      "400:\ttotal: 12.4s\tremaining: 1m 4s\n",
      "500:\ttotal: 15.4s\tremaining: 1m 1s\n",
      "600:\ttotal: 18.3s\tremaining: 57.9s\n",
      "700:\ttotal: 21.3s\tremaining: 54.7s\n",
      "800:\ttotal: 24.3s\tremaining: 51.4s\n",
      "900:\ttotal: 27.2s\tremaining: 48.3s\n",
      "1000:\ttotal: 30.3s\tremaining: 45.4s\n",
      "1100:\ttotal: 33.5s\tremaining: 42.6s\n",
      "1200:\ttotal: 36.6s\tremaining: 39.6s\n",
      "1300:\ttotal: 39.7s\tremaining: 36.6s\n",
      "1400:\ttotal: 42.6s\tremaining: 33.4s\n",
      "1500:\ttotal: 45.6s\tremaining: 30.4s\n",
      "1600:\ttotal: 48.8s\tremaining: 27.4s\n",
      "1700:\ttotal: 51.8s\tremaining: 24.3s\n",
      "1800:\ttotal: 54.9s\tremaining: 21.3s\n",
      "1900:\ttotal: 57.8s\tremaining: 18.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000:\ttotal: 1m\tremaining: 15.2s\n",
      "2100:\ttotal: 1m 3s\tremaining: 12.1s\n",
      "2200:\ttotal: 1m 6s\tremaining: 9.07s\n",
      "2300:\ttotal: 1m 9s\tremaining: 6.03s\n",
      "2400:\ttotal: 1m 12s\tremaining: 3s\n",
      "2499:\ttotal: 1m 15s\tremaining: 0us\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9724  \u001b[0m | \u001b[0m 0.5429  \u001b[0m | \u001b[0m 6.096   \u001b[0m | \u001b[0m 0.6877  \u001b[0m |\n",
      "0:\ttotal: 161ms\tremaining: 6m 42s\n",
      "100:\ttotal: 10.5s\tremaining: 4m 8s\n",
      "200:\ttotal: 21.2s\tremaining: 4m 2s\n",
      "300:\ttotal: 31.9s\tremaining: 3m 53s\n",
      "400:\ttotal: 42.4s\tremaining: 3m 41s\n",
      "500:\ttotal: 53s\tremaining: 3m 31s\n",
      "600:\ttotal: 1m 3s\tremaining: 3m 20s\n",
      "700:\ttotal: 1m 14s\tremaining: 3m 10s\n",
      "800:\ttotal: 1m 25s\tremaining: 3m\n",
      "900:\ttotal: 1m 35s\tremaining: 2m 50s\n",
      "1000:\ttotal: 1m 46s\tremaining: 2m 39s\n",
      "1100:\ttotal: 1m 56s\tremaining: 2m 28s\n",
      "1200:\ttotal: 2m 7s\tremaining: 2m 17s\n",
      "1300:\ttotal: 2m 18s\tremaining: 2m 7s\n",
      "1400:\ttotal: 2m 28s\tremaining: 1m 56s\n",
      "1500:\ttotal: 2m 39s\tremaining: 1m 45s\n",
      "1600:\ttotal: 2m 49s\tremaining: 1m 35s\n",
      "1700:\ttotal: 3m\tremaining: 1m 24s\n",
      "1800:\ttotal: 3m 10s\tremaining: 1m 13s\n",
      "1900:\ttotal: 3m 21s\tremaining: 1m 3s\n",
      "2000:\ttotal: 3m 31s\tremaining: 52.8s\n",
      "2100:\ttotal: 3m 42s\tremaining: 42.2s\n",
      "2200:\ttotal: 3m 52s\tremaining: 31.6s\n",
      "2300:\ttotal: 4m 2s\tremaining: 21s\n",
      "2400:\ttotal: 4m 13s\tremaining: 10.4s\n",
      "2499:\ttotal: 4m 23s\tremaining: 0us\n",
      "0:\ttotal: 117ms\tremaining: 4m 53s\n",
      "100:\ttotal: 10.9s\tremaining: 4m 17s\n",
      "200:\ttotal: 21.6s\tremaining: 4m 6s\n",
      "300:\ttotal: 33s\tremaining: 4m 1s\n",
      "400:\ttotal: 43.8s\tremaining: 3m 49s\n",
      "500:\ttotal: 54.6s\tremaining: 3m 38s\n",
      "600:\ttotal: 1m 5s\tremaining: 3m 25s\n",
      "700:\ttotal: 1m 15s\tremaining: 3m 13s\n",
      "800:\ttotal: 1m 25s\tremaining: 3m 2s\n",
      "900:\ttotal: 1m 36s\tremaining: 2m 51s\n",
      "1000:\ttotal: 1m 47s\tremaining: 2m 40s\n",
      "1100:\ttotal: 1m 57s\tremaining: 2m 29s\n",
      "1200:\ttotal: 2m 8s\tremaining: 2m 18s\n",
      "1300:\ttotal: 2m 18s\tremaining: 2m 7s\n",
      "1400:\ttotal: 2m 28s\tremaining: 1m 56s\n",
      "1500:\ttotal: 2m 39s\tremaining: 1m 45s\n",
      "1600:\ttotal: 2m 49s\tremaining: 1m 35s\n",
      "1700:\ttotal: 3m\tremaining: 1m 24s\n",
      "1800:\ttotal: 3m 11s\tremaining: 1m 14s\n",
      "1900:\ttotal: 3m 22s\tremaining: 1m 3s\n",
      "2000:\ttotal: 3m 32s\tremaining: 52.9s\n",
      "2100:\ttotal: 3m 42s\tremaining: 42.2s\n",
      "2200:\ttotal: 3m 52s\tremaining: 31.6s\n",
      "2300:\ttotal: 4m 2s\tremaining: 21s\n",
      "2400:\ttotal: 4m 13s\tremaining: 10.4s\n",
      "2499:\ttotal: 4m 23s\tremaining: 0us\n",
      "0:\ttotal: 115ms\tremaining: 4m 46s\n",
      "100:\ttotal: 10.7s\tremaining: 4m 13s\n",
      "200:\ttotal: 20.9s\tremaining: 3m 59s\n",
      "300:\ttotal: 31.1s\tremaining: 3m 47s\n",
      "400:\ttotal: 41.8s\tremaining: 3m 38s\n",
      "500:\ttotal: 52.5s\tremaining: 3m 29s\n",
      "600:\ttotal: 1m 3s\tremaining: 3m 20s\n",
      "700:\ttotal: 1m 13s\tremaining: 3m 9s\n",
      "800:\ttotal: 1m 24s\tremaining: 2m 58s\n",
      "900:\ttotal: 1m 34s\tremaining: 2m 47s\n",
      "1000:\ttotal: 1m 44s\tremaining: 2m 36s\n",
      "1100:\ttotal: 1m 54s\tremaining: 2m 25s\n",
      "1200:\ttotal: 2m 5s\tremaining: 2m 15s\n",
      "1300:\ttotal: 2m 15s\tremaining: 2m 5s\n",
      "1400:\ttotal: 2m 26s\tremaining: 1m 55s\n",
      "1500:\ttotal: 2m 37s\tremaining: 1m 44s\n",
      "1600:\ttotal: 2m 48s\tremaining: 1m 34s\n",
      "1700:\ttotal: 2m 59s\tremaining: 1m 24s\n",
      "1800:\ttotal: 3m 9s\tremaining: 1m 13s\n",
      "1900:\ttotal: 3m 20s\tremaining: 1m 3s\n",
      "2000:\ttotal: 3m 31s\tremaining: 52.6s\n",
      "2100:\ttotal: 3m 41s\tremaining: 42.1s\n",
      "2200:\ttotal: 3m 52s\tremaining: 31.5s\n",
      "2300:\ttotal: 4m 2s\tremaining: 21s\n",
      "2400:\ttotal: 4m 13s\tremaining: 10.5s\n",
      "2499:\ttotal: 4m 24s\tremaining: 0us\n",
      "0:\ttotal: 115ms\tremaining: 4m 46s\n",
      "100:\ttotal: 10.6s\tremaining: 4m 12s\n",
      "200:\ttotal: 21.5s\tremaining: 4m 5s\n",
      "300:\ttotal: 31.6s\tremaining: 3m 50s\n",
      "400:\ttotal: 42.3s\tremaining: 3m 41s\n",
      "500:\ttotal: 53s\tremaining: 3m 31s\n",
      "600:\ttotal: 1m 3s\tremaining: 3m 20s\n",
      "700:\ttotal: 1m 14s\tremaining: 3m 10s\n",
      "800:\ttotal: 1m 24s\tremaining: 2m 59s\n",
      "900:\ttotal: 1m 35s\tremaining: 2m 49s\n",
      "1000:\ttotal: 1m 46s\tremaining: 2m 38s\n",
      "1100:\ttotal: 1m 56s\tremaining: 2m 28s\n",
      "1200:\ttotal: 2m 7s\tremaining: 2m 17s\n",
      "1300:\ttotal: 2m 18s\tremaining: 2m 7s\n",
      "1400:\ttotal: 2m 29s\tremaining: 1m 56s\n",
      "1500:\ttotal: 2m 39s\tremaining: 1m 46s\n",
      "1600:\ttotal: 2m 50s\tremaining: 1m 35s\n",
      "1700:\ttotal: 3m\tremaining: 1m 24s\n",
      "1800:\ttotal: 3m 11s\tremaining: 1m 14s\n",
      "1900:\ttotal: 3m 21s\tremaining: 1m 3s\n",
      "2000:\ttotal: 3m 32s\tremaining: 52.9s\n",
      "2100:\ttotal: 3m 42s\tremaining: 42.3s\n",
      "2200:\ttotal: 3m 53s\tremaining: 31.7s\n",
      "2300:\ttotal: 4m 3s\tremaining: 21.1s\n",
      "2400:\ttotal: 4m 14s\tremaining: 10.5s\n",
      "2499:\ttotal: 4m 24s\tremaining: 0us\n",
      "0:\ttotal: 162ms\tremaining: 6m 43s\n",
      "100:\ttotal: 10.6s\tremaining: 4m 11s\n",
      "200:\ttotal: 21.1s\tremaining: 4m 1s\n",
      "300:\ttotal: 31.7s\tremaining: 3m 51s\n",
      "400:\ttotal: 42.4s\tremaining: 3m 41s\n",
      "500:\ttotal: 53s\tremaining: 3m 31s\n",
      "600:\ttotal: 1m 3s\tremaining: 3m 20s\n",
      "700:\ttotal: 1m 13s\tremaining: 3m 9s\n",
      "800:\ttotal: 1m 24s\tremaining: 2m 58s\n",
      "900:\ttotal: 1m 34s\tremaining: 2m 48s\n",
      "1000:\ttotal: 1m 45s\tremaining: 2m 38s\n",
      "1100:\ttotal: 1m 56s\tremaining: 2m 28s\n",
      "1200:\ttotal: 2m 7s\tremaining: 2m 17s\n",
      "1300:\ttotal: 2m 17s\tremaining: 2m 6s\n",
      "1400:\ttotal: 2m 28s\tremaining: 1m 56s\n",
      "1500:\ttotal: 2m 39s\tremaining: 1m 46s\n",
      "1600:\ttotal: 2m 50s\tremaining: 1m 35s\n",
      "1700:\ttotal: 3m 1s\tremaining: 1m 25s\n",
      "1800:\ttotal: 3m 11s\tremaining: 1m 14s\n",
      "1900:\ttotal: 3m 22s\tremaining: 1m 3s\n",
      "2000:\ttotal: 3m 32s\tremaining: 53s\n",
      "2100:\ttotal: 3m 42s\tremaining: 42.3s\n",
      "2200:\ttotal: 3m 54s\tremaining: 31.8s\n",
      "2300:\ttotal: 4m 4s\tremaining: 21.2s\n",
      "2400:\ttotal: 4m 15s\tremaining: 10.5s\n",
      "2499:\ttotal: 4m 25s\tremaining: 0us\n",
      "0:\ttotal: 124ms\tremaining: 5m 10s\n",
      "100:\ttotal: 10.7s\tremaining: 4m 13s\n",
      "200:\ttotal: 21.3s\tremaining: 4m 3s\n",
      "300:\ttotal: 31.8s\tremaining: 3m 52s\n",
      "400:\ttotal: 42.6s\tremaining: 3m 43s\n",
      "500:\ttotal: 53.1s\tremaining: 3m 31s\n",
      "600:\ttotal: 1m 3s\tremaining: 3m 22s\n",
      "700:\ttotal: 1m 14s\tremaining: 3m 12s\n",
      "800:\ttotal: 1m 25s\tremaining: 3m 1s\n",
      "900:\ttotal: 1m 36s\tremaining: 2m 50s\n",
      "1000:\ttotal: 1m 46s\tremaining: 2m 40s\n",
      "1100:\ttotal: 1m 57s\tremaining: 2m 29s\n",
      "1200:\ttotal: 2m 7s\tremaining: 2m 18s\n",
      "1300:\ttotal: 2m 18s\tremaining: 2m 7s\n",
      "1400:\ttotal: 2m 29s\tremaining: 1m 57s\n",
      "1500:\ttotal: 2m 39s\tremaining: 1m 46s\n",
      "1600:\ttotal: 2m 50s\tremaining: 1m 35s\n",
      "1700:\ttotal: 3m\tremaining: 1m 24s\n",
      "1800:\ttotal: 3m 11s\tremaining: 1m 14s\n",
      "1900:\ttotal: 3m 21s\tremaining: 1m 3s\n",
      "2000:\ttotal: 3m 32s\tremaining: 53s\n",
      "2100:\ttotal: 3m 43s\tremaining: 42.4s\n",
      "2200:\ttotal: 3m 53s\tremaining: 31.8s\n",
      "2300:\ttotal: 4m 4s\tremaining: 21.1s\n",
      "2400:\ttotal: 4m 14s\tremaining: 10.5s\n",
      "2499:\ttotal: 4m 24s\tremaining: 0us\n",
      "0:\ttotal: 138ms\tremaining: 5m 44s\n",
      "100:\ttotal: 10.9s\tremaining: 4m 18s\n",
      "200:\ttotal: 21.4s\tremaining: 4m 5s\n",
      "300:\ttotal: 31.8s\tremaining: 3m 52s\n",
      "400:\ttotal: 42.3s\tremaining: 3m 41s\n",
      "500:\ttotal: 52.8s\tremaining: 3m 30s\n",
      "600:\ttotal: 1m 3s\tremaining: 3m 21s\n",
      "700:\ttotal: 1m 14s\tremaining: 3m 10s\n",
      "800:\ttotal: 1m 24s\tremaining: 2m 59s\n",
      "900:\ttotal: 1m 35s\tremaining: 2m 48s\n",
      "1000:\ttotal: 1m 45s\tremaining: 2m 38s\n",
      "1100:\ttotal: 1m 55s\tremaining: 2m 27s\n",
      "1200:\ttotal: 2m 6s\tremaining: 2m 16s\n",
      "1300:\ttotal: 2m 17s\tremaining: 2m 6s\n",
      "1400:\ttotal: 2m 27s\tremaining: 1m 55s\n",
      "1500:\ttotal: 2m 38s\tremaining: 1m 45s\n",
      "1600:\ttotal: 2m 48s\tremaining: 1m 34s\n",
      "1700:\ttotal: 2m 59s\tremaining: 1m 24s\n",
      "1800:\ttotal: 3m 10s\tremaining: 1m 13s\n",
      "1900:\ttotal: 3m 20s\tremaining: 1m 3s\n",
      "2000:\ttotal: 3m 31s\tremaining: 52.7s\n",
      "2100:\ttotal: 3m 41s\tremaining: 42.2s\n",
      "2200:\ttotal: 3m 52s\tremaining: 31.5s\n",
      "2300:\ttotal: 4m 2s\tremaining: 21s\n",
      "2400:\ttotal: 4m 12s\tremaining: 10.4s\n",
      "2499:\ttotal: 4m 23s\tremaining: 0us\n",
      "0:\ttotal: 150ms\tremaining: 6m 14s\n",
      "100:\ttotal: 10.4s\tremaining: 4m 7s\n",
      "200:\ttotal: 20.9s\tremaining: 3m 59s\n",
      "300:\ttotal: 31.8s\tremaining: 3m 52s\n",
      "400:\ttotal: 43.2s\tremaining: 3m 46s\n",
      "500:\ttotal: 54s\tremaining: 3m 35s\n",
      "600:\ttotal: 1m 4s\tremaining: 3m 24s\n",
      "700:\ttotal: 1m 14s\tremaining: 3m 12s\n",
      "800:\ttotal: 1m 24s\tremaining: 3m\n",
      "900:\ttotal: 1m 35s\tremaining: 2m 49s\n",
      "1000:\ttotal: 1m 46s\tremaining: 2m 38s\n",
      "1100:\ttotal: 1m 56s\tremaining: 2m 28s\n",
      "1200:\ttotal: 2m 7s\tremaining: 2m 17s\n",
      "1300:\ttotal: 2m 17s\tremaining: 2m 6s\n",
      "1400:\ttotal: 2m 28s\tremaining: 1m 56s\n",
      "1500:\ttotal: 2m 40s\tremaining: 1m 46s\n",
      "1600:\ttotal: 2m 50s\tremaining: 1m 35s\n",
      "1700:\ttotal: 3m\tremaining: 1m 24s\n",
      "1800:\ttotal: 3m 11s\tremaining: 1m 14s\n",
      "1900:\ttotal: 3m 22s\tremaining: 1m 3s\n",
      "2000:\ttotal: 3m 32s\tremaining: 53.1s\n",
      "2100:\ttotal: 3m 43s\tremaining: 42.4s\n",
      "2200:\ttotal: 3m 53s\tremaining: 31.7s\n",
      "2300:\ttotal: 4m 3s\tremaining: 21.1s\n",
      "2400:\ttotal: 4m 14s\tremaining: 10.5s\n",
      "2499:\ttotal: 4m 24s\tremaining: 0us\n",
      "0:\ttotal: 124ms\tremaining: 5m 9s\n",
      "100:\ttotal: 10.9s\tremaining: 4m 18s\n",
      "200:\ttotal: 21.1s\tremaining: 4m\n",
      "300:\ttotal: 31.7s\tremaining: 3m 51s\n",
      "400:\ttotal: 42.5s\tremaining: 3m 42s\n",
      "500:\ttotal: 55s\tremaining: 3m 39s\n",
      "600:\ttotal: 1m 6s\tremaining: 3m 29s\n",
      "700:\ttotal: 1m 17s\tremaining: 3m 18s\n",
      "800:\ttotal: 1m 28s\tremaining: 3m 7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900:\ttotal: 1m 39s\tremaining: 2m 56s\n",
      "1000:\ttotal: 1m 49s\tremaining: 2m 44s\n",
      "1100:\ttotal: 2m\tremaining: 2m 32s\n",
      "1200:\ttotal: 2m 12s\tremaining: 2m 23s\n",
      "1300:\ttotal: 2m 23s\tremaining: 2m 12s\n",
      "1400:\ttotal: 2m 34s\tremaining: 2m 1s\n",
      "1500:\ttotal: 2m 45s\tremaining: 1m 49s\n",
      "1600:\ttotal: 2m 55s\tremaining: 1m 38s\n",
      "1700:\ttotal: 3m 6s\tremaining: 1m 27s\n",
      "1800:\ttotal: 3m 17s\tremaining: 1m 16s\n",
      "1900:\ttotal: 3m 27s\tremaining: 1m 5s\n",
      "2000:\ttotal: 3m 38s\tremaining: 54.4s\n",
      "2100:\ttotal: 3m 49s\tremaining: 43.6s\n",
      "2200:\ttotal: 4m 1s\tremaining: 32.8s\n",
      "2300:\ttotal: 4m 13s\tremaining: 21.9s\n",
      "2400:\ttotal: 4m 24s\tremaining: 10.9s\n",
      "2499:\ttotal: 4m 34s\tremaining: 0us\n",
      "0:\ttotal: 146ms\tremaining: 6m 3s\n",
      "100:\ttotal: 10.7s\tremaining: 4m 13s\n",
      "200:\ttotal: 21.7s\tremaining: 4m 8s\n",
      "300:\ttotal: 32.5s\tremaining: 3m 57s\n",
      "400:\ttotal: 43.1s\tremaining: 3m 45s\n",
      "500:\ttotal: 53.8s\tremaining: 3m 34s\n",
      "600:\ttotal: 1m 4s\tremaining: 3m 24s\n",
      "700:\ttotal: 1m 15s\tremaining: 3m 13s\n",
      "800:\ttotal: 1m 26s\tremaining: 3m 3s\n",
      "900:\ttotal: 1m 38s\tremaining: 2m 54s\n",
      "1000:\ttotal: 1m 50s\tremaining: 2m 45s\n",
      "1100:\ttotal: 2m 1s\tremaining: 2m 34s\n",
      "1200:\ttotal: 2m 12s\tremaining: 2m 23s\n",
      "1300:\ttotal: 2m 22s\tremaining: 2m 11s\n",
      "1400:\ttotal: 2m 33s\tremaining: 2m\n",
      "1500:\ttotal: 2m 44s\tremaining: 1m 49s\n",
      "1600:\ttotal: 2m 55s\tremaining: 1m 38s\n",
      "1700:\ttotal: 3m 6s\tremaining: 1m 27s\n",
      "1800:\ttotal: 3m 17s\tremaining: 1m 16s\n",
      "1900:\ttotal: 3m 28s\tremaining: 1m 5s\n",
      "2000:\ttotal: 3m 38s\tremaining: 54.6s\n",
      "2100:\ttotal: 3m 49s\tremaining: 43.6s\n",
      "2200:\ttotal: 4m\tremaining: 32.6s\n",
      "2300:\ttotal: 4m 10s\tremaining: 21.7s\n",
      "2400:\ttotal: 4m 21s\tremaining: 10.8s\n",
      "2499:\ttotal: 4m 32s\tremaining: 0us\n",
      "0:\ttotal: 150ms\tremaining: 6m 14s\n",
      "100:\ttotal: 10.9s\tremaining: 4m 18s\n",
      "200:\ttotal: 22.4s\tremaining: 4m 16s\n",
      "300:\ttotal: 33.4s\tremaining: 4m 4s\n",
      "400:\ttotal: 44.2s\tremaining: 3m 51s\n",
      "500:\ttotal: 55.2s\tremaining: 3m 40s\n",
      "600:\ttotal: 1m 7s\tremaining: 3m 33s\n",
      "700:\ttotal: 1m 19s\tremaining: 3m 23s\n",
      "800:\ttotal: 1m 29s\tremaining: 3m 10s\n",
      "900:\ttotal: 1m 42s\tremaining: 3m 1s\n",
      "1000:\ttotal: 1m 55s\tremaining: 2m 53s\n",
      "1100:\ttotal: 2m 6s\tremaining: 2m 41s\n",
      "1200:\ttotal: 2m 17s\tremaining: 2m 28s\n",
      "1300:\ttotal: 2m 27s\tremaining: 2m 15s\n",
      "1400:\ttotal: 2m 37s\tremaining: 2m 3s\n",
      "1500:\ttotal: 2m 48s\tremaining: 1m 51s\n",
      "1600:\ttotal: 2m 59s\tremaining: 1m 40s\n",
      "1700:\ttotal: 3m 10s\tremaining: 1m 29s\n",
      "1800:\ttotal: 3m 21s\tremaining: 1m 18s\n",
      "1900:\ttotal: 3m 32s\tremaining: 1m 7s\n",
      "2000:\ttotal: 3m 43s\tremaining: 55.7s\n",
      "2100:\ttotal: 3m 55s\tremaining: 44.6s\n",
      "2200:\ttotal: 4m 6s\tremaining: 33.5s\n",
      "2300:\ttotal: 4m 17s\tremaining: 22.2s\n",
      "2400:\ttotal: 4m 28s\tremaining: 11.1s\n",
      "2499:\ttotal: 4m 38s\tremaining: 0us\n",
      "0:\ttotal: 173ms\tremaining: 7m 12s\n",
      "100:\ttotal: 10.7s\tremaining: 4m 14s\n",
      "200:\ttotal: 21.6s\tremaining: 4m 7s\n",
      "300:\ttotal: 31.9s\tremaining: 3m 52s\n",
      "400:\ttotal: 41.9s\tremaining: 3m 39s\n",
      "500:\ttotal: 53s\tremaining: 3m 31s\n",
      "600:\ttotal: 1m 4s\tremaining: 3m 22s\n",
      "700:\ttotal: 1m 15s\tremaining: 3m 13s\n",
      "800:\ttotal: 1m 27s\tremaining: 3m 4s\n",
      "900:\ttotal: 1m 38s\tremaining: 2m 55s\n",
      "1000:\ttotal: 1m 49s\tremaining: 2m 44s\n",
      "1100:\ttotal: 2m\tremaining: 2m 33s\n",
      "1200:\ttotal: 2m 12s\tremaining: 2m 22s\n",
      "1300:\ttotal: 2m 23s\tremaining: 2m 12s\n",
      "1400:\ttotal: 2m 34s\tremaining: 2m 1s\n",
      "1500:\ttotal: 2m 45s\tremaining: 1m 50s\n",
      "1600:\ttotal: 2m 57s\tremaining: 1m 39s\n",
      "1700:\ttotal: 3m 8s\tremaining: 1m 28s\n",
      "1800:\ttotal: 3m 19s\tremaining: 1m 17s\n",
      "1900:\ttotal: 3m 30s\tremaining: 1m 6s\n",
      "2000:\ttotal: 3m 42s\tremaining: 55.5s\n",
      "2100:\ttotal: 3m 54s\tremaining: 44.5s\n",
      "2200:\ttotal: 4m 5s\tremaining: 33.4s\n",
      "2300:\ttotal: 4m 18s\tremaining: 22.3s\n",
      "2400:\ttotal: 4m 30s\tremaining: 11.2s\n",
      "2499:\ttotal: 4m 42s\tremaining: 0us\n",
      "0:\ttotal: 128ms\tremaining: 5m 20s\n",
      "100:\ttotal: 11.8s\tremaining: 4m 40s\n",
      "200:\ttotal: 25s\tremaining: 4m 45s\n",
      "300:\ttotal: 36.5s\tremaining: 4m 27s\n",
      "400:\ttotal: 47.9s\tremaining: 4m 10s\n",
      "500:\ttotal: 59.2s\tremaining: 3m 56s\n",
      "600:\ttotal: 1m 10s\tremaining: 3m 41s\n",
      "700:\ttotal: 1m 22s\tremaining: 3m 31s\n",
      "800:\ttotal: 1m 35s\tremaining: 3m 22s\n",
      "900:\ttotal: 1m 48s\tremaining: 3m 11s\n",
      "1000:\ttotal: 2m\tremaining: 2m 59s\n",
      "1100:\ttotal: 2m 12s\tremaining: 2m 48s\n",
      "1200:\ttotal: 2m 23s\tremaining: 2m 35s\n",
      "1300:\ttotal: 2m 34s\tremaining: 2m 22s\n",
      "1400:\ttotal: 2m 45s\tremaining: 2m 10s\n",
      "1500:\ttotal: 2m 56s\tremaining: 1m 57s\n",
      "1600:\ttotal: 3m 7s\tremaining: 1m 45s\n",
      "1700:\ttotal: 3m 20s\tremaining: 1m 33s\n",
      "1800:\ttotal: 3m 33s\tremaining: 1m 22s\n",
      "1900:\ttotal: 3m 45s\tremaining: 1m 10s\n",
      "2000:\ttotal: 3m 57s\tremaining: 59.1s\n",
      "2100:\ttotal: 4m 8s\tremaining: 47.3s\n",
      "2200:\ttotal: 4m 20s\tremaining: 35.4s\n",
      "2300:\ttotal: 4m 32s\tremaining: 23.6s\n",
      "2400:\ttotal: 4m 44s\tremaining: 11.7s\n",
      "2499:\ttotal: 4m 55s\tremaining: 0us\n",
      "0:\ttotal: 137ms\tremaining: 5m 43s\n",
      "100:\ttotal: 11.2s\tremaining: 4m 25s\n",
      "200:\ttotal: 22.3s\tremaining: 4m 15s\n",
      "300:\ttotal: 34.6s\tremaining: 4m 12s\n",
      "400:\ttotal: 48.1s\tremaining: 4m 11s\n",
      "500:\ttotal: 1m\tremaining: 3m 59s\n",
      "600:\ttotal: 1m 12s\tremaining: 3m 47s\n",
      "700:\ttotal: 1m 24s\tremaining: 3m 37s\n",
      "800:\ttotal: 1m 37s\tremaining: 3m 26s\n",
      "900:\ttotal: 1m 48s\tremaining: 3m 12s\n",
      "1000:\ttotal: 1m 59s\tremaining: 2m 59s\n",
      "1100:\ttotal: 2m 12s\tremaining: 2m 47s\n",
      "1200:\ttotal: 2m 23s\tremaining: 2m 35s\n",
      "1300:\ttotal: 2m 35s\tremaining: 2m 23s\n",
      "1400:\ttotal: 2m 46s\tremaining: 2m 10s\n",
      "1500:\ttotal: 2m 58s\tremaining: 1m 58s\n",
      "1600:\ttotal: 3m 10s\tremaining: 1m 46s\n",
      "1700:\ttotal: 3m 21s\tremaining: 1m 34s\n",
      "1800:\ttotal: 3m 34s\tremaining: 1m 23s\n",
      "1900:\ttotal: 3m 46s\tremaining: 1m 11s\n",
      "2000:\ttotal: 3m 57s\tremaining: 59.3s\n",
      "2100:\ttotal: 4m 10s\tremaining: 47.5s\n",
      "2200:\ttotal: 4m 23s\tremaining: 35.8s\n",
      "2300:\ttotal: 4m 35s\tremaining: 23.9s\n",
      "2400:\ttotal: 4m 47s\tremaining: 11.8s\n",
      "2499:\ttotal: 4m 58s\tremaining: 0us\n",
      "0:\ttotal: 125ms\tremaining: 5m 12s\n",
      "100:\ttotal: 11.3s\tremaining: 4m 28s\n",
      "200:\ttotal: 23s\tremaining: 4m 23s\n",
      "300:\ttotal: 34.4s\tremaining: 4m 11s\n",
      "400:\ttotal: 46s\tremaining: 4m\n",
      "500:\ttotal: 58.1s\tremaining: 3m 51s\n",
      "600:\ttotal: 1m 9s\tremaining: 3m 40s\n",
      "700:\ttotal: 1m 20s\tremaining: 3m 27s\n",
      "800:\ttotal: 1m 32s\tremaining: 3m 16s\n",
      "900:\ttotal: 1m 44s\tremaining: 3m 5s\n",
      "1000:\ttotal: 1m 56s\tremaining: 2m 54s\n",
      "1100:\ttotal: 2m 7s\tremaining: 2m 42s\n",
      "1200:\ttotal: 2m 19s\tremaining: 2m 30s\n",
      "1300:\ttotal: 2m 30s\tremaining: 2m 19s\n",
      "1400:\ttotal: 2m 42s\tremaining: 2m 7s\n",
      "1500:\ttotal: 2m 53s\tremaining: 1m 55s\n",
      "1600:\ttotal: 3m 4s\tremaining: 1m 43s\n",
      "1700:\ttotal: 3m 15s\tremaining: 1m 31s\n",
      "1800:\ttotal: 3m 27s\tremaining: 1m 20s\n",
      "1900:\ttotal: 3m 38s\tremaining: 1m 8s\n",
      "2000:\ttotal: 3m 49s\tremaining: 57.3s\n",
      "2100:\ttotal: 4m 1s\tremaining: 45.9s\n",
      "2200:\ttotal: 4m 13s\tremaining: 34.4s\n",
      "2300:\ttotal: 4m 25s\tremaining: 22.9s\n",
      "2400:\ttotal: 4m 36s\tremaining: 11.4s\n",
      "2499:\ttotal: 4m 48s\tremaining: 0us\n",
      "0:\ttotal: 126ms\tremaining: 5m 14s\n",
      "100:\ttotal: 11.4s\tremaining: 4m 30s\n",
      "200:\ttotal: 23s\tremaining: 4m 23s\n",
      "300:\ttotal: 35.5s\tremaining: 4m 19s\n",
      "400:\ttotal: 48.1s\tremaining: 4m 12s\n",
      "500:\ttotal: 1m\tremaining: 3m 59s\n",
      "600:\ttotal: 1m 12s\tremaining: 3m 47s\n",
      "700:\ttotal: 1m 23s\tremaining: 3m 35s\n",
      "800:\ttotal: 1m 36s\tremaining: 3m 24s\n",
      "900:\ttotal: 1m 50s\tremaining: 3m 16s\n",
      "1000:\ttotal: 2m 3s\tremaining: 3m 4s\n",
      "1100:\ttotal: 2m 15s\tremaining: 2m 52s\n",
      "1200:\ttotal: 2m 28s\tremaining: 2m 40s\n",
      "1300:\ttotal: 2m 40s\tremaining: 2m 28s\n",
      "1400:\ttotal: 2m 53s\tremaining: 2m 16s\n",
      "1500:\ttotal: 3m 5s\tremaining: 2m 3s\n",
      "1600:\ttotal: 3m 17s\tremaining: 1m 50s\n",
      "1700:\ttotal: 3m 29s\tremaining: 1m 38s\n",
      "1800:\ttotal: 3m 41s\tremaining: 1m 25s\n",
      "1900:\ttotal: 3m 52s\tremaining: 1m 13s\n",
      "2000:\ttotal: 4m 4s\tremaining: 1m\n",
      "2100:\ttotal: 4m 15s\tremaining: 48.6s\n",
      "2200:\ttotal: 4m 27s\tremaining: 36.3s\n",
      "2300:\ttotal: 4m 38s\tremaining: 24.1s\n",
      "2400:\ttotal: 4m 50s\tremaining: 12s\n",
      "2499:\ttotal: 5m 1s\tremaining: 0us\n",
      "0:\ttotal: 127ms\tremaining: 5m 16s\n",
      "100:\ttotal: 12.2s\tremaining: 4m 49s\n",
      "200:\ttotal: 23.8s\tremaining: 4m 31s\n",
      "300:\ttotal: 37.7s\tremaining: 4m 35s\n",
      "400:\ttotal: 50s\tremaining: 4m 21s\n",
      "500:\ttotal: 1m 2s\tremaining: 4m 7s\n",
      "600:\ttotal: 1m 14s\tremaining: 3m 53s\n",
      "700:\ttotal: 1m 27s\tremaining: 3m 45s\n",
      "800:\ttotal: 1m 41s\tremaining: 3m 35s\n",
      "900:\ttotal: 1m 55s\tremaining: 3m 24s\n",
      "1000:\ttotal: 2m 7s\tremaining: 3m 10s\n",
      "1100:\ttotal: 2m 18s\tremaining: 2m 56s\n",
      "1200:\ttotal: 2m 31s\tremaining: 2m 44s\n",
      "1300:\ttotal: 2m 44s\tremaining: 2m 31s\n",
      "1400:\ttotal: 2m 57s\tremaining: 2m 19s\n",
      "1500:\ttotal: 3m 10s\tremaining: 2m 6s\n",
      "1600:\ttotal: 3m 23s\tremaining: 1m 54s\n",
      "1700:\ttotal: 3m 36s\tremaining: 1m 41s\n",
      "1800:\ttotal: 3m 50s\tremaining: 1m 29s\n",
      "1900:\ttotal: 4m 2s\tremaining: 1m 16s\n",
      "2000:\ttotal: 4m 13s\tremaining: 1m 3s\n",
      "2100:\ttotal: 4m 25s\tremaining: 50.5s\n",
      "2200:\ttotal: 4m 38s\tremaining: 37.9s\n",
      "2300:\ttotal: 4m 51s\tremaining: 25.2s\n",
      "2400:\ttotal: 5m 4s\tremaining: 12.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499:\ttotal: 5m 16s\tremaining: 0us\n",
      "0:\ttotal: 143ms\tremaining: 5m 56s\n",
      "100:\ttotal: 12.4s\tremaining: 4m 55s\n",
      "200:\ttotal: 24.5s\tremaining: 4m 39s\n",
      "300:\ttotal: 36.2s\tremaining: 4m 24s\n",
      "400:\ttotal: 48.4s\tremaining: 4m 13s\n",
      "500:\ttotal: 1m\tremaining: 4m 1s\n",
      "600:\ttotal: 1m 12s\tremaining: 3m 48s\n",
      "700:\ttotal: 1m 23s\tremaining: 3m 35s\n",
      "800:\ttotal: 1m 34s\tremaining: 3m 21s\n",
      "900:\ttotal: 1m 46s\tremaining: 3m 8s\n",
      "1000:\ttotal: 1m 58s\tremaining: 2m 56s\n",
      "1100:\ttotal: 2m 9s\tremaining: 2m 44s\n",
      "1200:\ttotal: 2m 21s\tremaining: 2m 33s\n",
      "1300:\ttotal: 2m 32s\tremaining: 2m 20s\n",
      "1400:\ttotal: 2m 43s\tremaining: 2m 8s\n",
      "1500:\ttotal: 2m 55s\tremaining: 1m 56s\n",
      "1600:\ttotal: 3m 7s\tremaining: 1m 45s\n",
      "1700:\ttotal: 3m 18s\tremaining: 1m 33s\n",
      "1800:\ttotal: 3m 29s\tremaining: 1m 21s\n",
      "1900:\ttotal: 3m 40s\tremaining: 1m 9s\n",
      "2000:\ttotal: 3m 51s\tremaining: 57.7s\n",
      "2100:\ttotal: 4m 2s\tremaining: 46s\n",
      "2200:\ttotal: 4m 12s\tremaining: 34.4s\n",
      "2300:\ttotal: 4m 23s\tremaining: 22.8s\n",
      "2400:\ttotal: 4m 34s\tremaining: 11.3s\n",
      "2499:\ttotal: 4m 45s\tremaining: 0us\n",
      "0:\ttotal: 112ms\tremaining: 4m 40s\n",
      "100:\ttotal: 11.3s\tremaining: 4m 27s\n",
      "200:\ttotal: 22.7s\tremaining: 4m 19s\n",
      "300:\ttotal: 34.4s\tremaining: 4m 11s\n",
      "400:\ttotal: 46.1s\tremaining: 4m 1s\n",
      "500:\ttotal: 57.3s\tremaining: 3m 48s\n",
      "600:\ttotal: 1m 8s\tremaining: 3m 36s\n",
      "700:\ttotal: 1m 19s\tremaining: 3m 25s\n",
      "800:\ttotal: 1m 31s\tremaining: 3m 13s\n",
      "900:\ttotal: 1m 42s\tremaining: 3m 1s\n",
      "1000:\ttotal: 1m 53s\tremaining: 2m 49s\n",
      "1100:\ttotal: 2m 4s\tremaining: 2m 37s\n",
      "1200:\ttotal: 2m 15s\tremaining: 2m 26s\n",
      "1300:\ttotal: 2m 26s\tremaining: 2m 14s\n",
      "1400:\ttotal: 2m 36s\tremaining: 2m 3s\n",
      "1500:\ttotal: 2m 47s\tremaining: 1m 51s\n",
      "1600:\ttotal: 2m 57s\tremaining: 1m 39s\n",
      "1700:\ttotal: 3m 7s\tremaining: 1m 28s\n",
      "1800:\ttotal: 3m 17s\tremaining: 1m 16s\n",
      "1900:\ttotal: 3m 28s\tremaining: 1m 5s\n",
      "2000:\ttotal: 3m 40s\tremaining: 55.1s\n",
      "2100:\ttotal: 3m 52s\tremaining: 44.1s\n",
      "2200:\ttotal: 4m 3s\tremaining: 33.1s\n",
      "2300:\ttotal: 4m 14s\tremaining: 22s\n",
      "2400:\ttotal: 4m 26s\tremaining: 11s\n",
      "2499:\ttotal: 4m 37s\tremaining: 0us\n",
      "0:\ttotal: 122ms\tremaining: 5m 3s\n",
      "100:\ttotal: 11.7s\tremaining: 4m 37s\n",
      "200:\ttotal: 23.1s\tremaining: 4m 24s\n",
      "300:\ttotal: 34.3s\tremaining: 4m 10s\n",
      "400:\ttotal: 45.5s\tremaining: 3m 58s\n",
      "500:\ttotal: 56.7s\tremaining: 3m 46s\n",
      "600:\ttotal: 1m 8s\tremaining: 3m 35s\n",
      "700:\ttotal: 1m 19s\tremaining: 3m 23s\n",
      "800:\ttotal: 1m 30s\tremaining: 3m 11s\n",
      "900:\ttotal: 1m 41s\tremaining: 2m 59s\n",
      "1000:\ttotal: 1m 52s\tremaining: 2m 48s\n",
      "1100:\ttotal: 2m 3s\tremaining: 2m 37s\n",
      "1200:\ttotal: 2m 15s\tremaining: 2m 26s\n",
      "1300:\ttotal: 2m 26s\tremaining: 2m 15s\n",
      "1400:\ttotal: 2m 38s\tremaining: 2m 4s\n",
      "1500:\ttotal: 2m 50s\tremaining: 1m 53s\n",
      "1600:\ttotal: 3m 2s\tremaining: 1m 42s\n",
      "1700:\ttotal: 3m 14s\tremaining: 1m 31s\n",
      "1800:\ttotal: 3m 26s\tremaining: 1m 20s\n",
      "1900:\ttotal: 3m 38s\tremaining: 1m 8s\n",
      "2000:\ttotal: 3m 49s\tremaining: 57.3s\n",
      "2100:\ttotal: 4m\tremaining: 45.8s\n",
      "2200:\ttotal: 4m 11s\tremaining: 34.2s\n",
      "2300:\ttotal: 4m 22s\tremaining: 22.7s\n",
      "2400:\ttotal: 4m 33s\tremaining: 11.3s\n",
      "2499:\ttotal: 4m 44s\tremaining: 0us\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9695  \u001b[0m | \u001b[0m 0.2122  \u001b[0m | \u001b[0m 8.391   \u001b[0m | \u001b[0m 0.03709 \u001b[0m |\n",
      "0:\ttotal: 82.4ms\tremaining: 3m 25s\n",
      "100:\ttotal: 5.6s\tremaining: 2m 13s\n",
      "200:\ttotal: 11.1s\tremaining: 2m 7s\n",
      "300:\ttotal: 17.1s\tremaining: 2m 4s\n",
      "400:\ttotal: 22.6s\tremaining: 1m 58s\n",
      "500:\ttotal: 28.2s\tremaining: 1m 52s\n",
      "600:\ttotal: 33.6s\tremaining: 1m 46s\n",
      "700:\ttotal: 39s\tremaining: 1m 40s\n",
      "800:\ttotal: 44.3s\tremaining: 1m 33s\n",
      "900:\ttotal: 49.7s\tremaining: 1m 28s\n",
      "1000:\ttotal: 55.2s\tremaining: 1m 22s\n",
      "1100:\ttotal: 1m\tremaining: 1m 17s\n",
      "1200:\ttotal: 1m 6s\tremaining: 1m 12s\n",
      "1300:\ttotal: 1m 12s\tremaining: 1m 6s\n",
      "1400:\ttotal: 1m 18s\tremaining: 1m 1s\n",
      "1500:\ttotal: 1m 24s\tremaining: 56s\n",
      "1600:\ttotal: 1m 30s\tremaining: 50.6s\n",
      "1700:\ttotal: 1m 35s\tremaining: 45s\n",
      "1800:\ttotal: 1m 41s\tremaining: 39.4s\n",
      "1900:\ttotal: 1m 46s\tremaining: 33.7s\n",
      "2000:\ttotal: 1m 52s\tremaining: 28s\n",
      "2100:\ttotal: 1m 57s\tremaining: 22.3s\n",
      "2200:\ttotal: 2m 3s\tremaining: 16.7s\n",
      "2300:\ttotal: 2m 8s\tremaining: 11.1s\n",
      "2400:\ttotal: 2m 14s\tremaining: 5.55s\n",
      "2499:\ttotal: 2m 20s\tremaining: 0us\n",
      "0:\ttotal: 110ms\tremaining: 4m 35s\n",
      "100:\ttotal: 5.69s\tremaining: 2m 15s\n",
      "200:\ttotal: 11.3s\tremaining: 2m 9s\n",
      "300:\ttotal: 17s\tremaining: 2m 4s\n",
      "400:\ttotal: 22.5s\tremaining: 1m 57s\n",
      "500:\ttotal: 28s\tremaining: 1m 51s\n",
      "600:\ttotal: 33.4s\tremaining: 1m 45s\n",
      "700:\ttotal: 38.9s\tremaining: 1m 39s\n",
      "800:\ttotal: 45.1s\tremaining: 1m 35s\n",
      "900:\ttotal: 50.9s\tremaining: 1m 30s\n",
      "1000:\ttotal: 56.8s\tremaining: 1m 24s\n",
      "1100:\ttotal: 1m 2s\tremaining: 1m 19s\n",
      "1200:\ttotal: 1m 8s\tremaining: 1m 14s\n",
      "1300:\ttotal: 1m 14s\tremaining: 1m 8s\n",
      "1400:\ttotal: 1m 19s\tremaining: 1m 2s\n",
      "1500:\ttotal: 1m 25s\tremaining: 56.9s\n",
      "1600:\ttotal: 1m 31s\tremaining: 51.2s\n",
      "1700:\ttotal: 1m 36s\tremaining: 45.4s\n",
      "1800:\ttotal: 1m 42s\tremaining: 39.7s\n",
      "1900:\ttotal: 1m 48s\tremaining: 34.1s\n",
      "2000:\ttotal: 1m 54s\tremaining: 28.6s\n",
      "2100:\ttotal: 2m\tremaining: 22.8s\n",
      "2200:\ttotal: 2m 5s\tremaining: 17.1s\n",
      "2300:\ttotal: 2m 11s\tremaining: 11.4s\n",
      "2400:\ttotal: 2m 17s\tremaining: 5.67s\n",
      "2499:\ttotal: 2m 22s\tremaining: 0us\n",
      "0:\ttotal: 72.7ms\tremaining: 3m 1s\n",
      "100:\ttotal: 5.72s\tremaining: 2m 15s\n",
      "200:\ttotal: 11.3s\tremaining: 2m 9s\n",
      "300:\ttotal: 16.9s\tremaining: 2m 3s\n",
      "400:\ttotal: 22.7s\tremaining: 1m 58s\n",
      "500:\ttotal: 28.3s\tremaining: 1m 52s\n",
      "600:\ttotal: 34.1s\tremaining: 1m 47s\n",
      "700:\ttotal: 40s\tremaining: 1m 42s\n",
      "800:\ttotal: 46.3s\tremaining: 1m 38s\n",
      "900:\ttotal: 52.2s\tremaining: 1m 32s\n",
      "1000:\ttotal: 58.3s\tremaining: 1m 27s\n",
      "1100:\ttotal: 1m 3s\tremaining: 1m 21s\n",
      "1200:\ttotal: 1m 9s\tremaining: 1m 15s\n",
      "1300:\ttotal: 1m 15s\tremaining: 1m 9s\n",
      "1400:\ttotal: 1m 22s\tremaining: 1m 4s\n",
      "1500:\ttotal: 1m 29s\tremaining: 59.4s\n",
      "1600:\ttotal: 1m 35s\tremaining: 53.9s\n",
      "1700:\ttotal: 1m 42s\tremaining: 48.1s\n",
      "1800:\ttotal: 1m 49s\tremaining: 42.5s\n",
      "1900:\ttotal: 1m 55s\tremaining: 36.5s\n",
      "2000:\ttotal: 2m 2s\tremaining: 30.4s\n",
      "2100:\ttotal: 2m 7s\tremaining: 24.2s\n",
      "2200:\ttotal: 2m 12s\tremaining: 18s\n",
      "2300:\ttotal: 2m 18s\tremaining: 11.9s\n",
      "2400:\ttotal: 2m 24s\tremaining: 5.95s\n",
      "2499:\ttotal: 2m 32s\tremaining: 0us\n",
      "0:\ttotal: 88.3ms\tremaining: 3m 40s\n",
      "100:\ttotal: 8.36s\tremaining: 3m 18s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0.47218873504718734, 7.4416986192919286, 0.01)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-7d46391b1c97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer.maximize(\n\u001b[0;32m      2\u001b[0m     \u001b[0minit_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-90-146f2c84a981>\u001b[0m in \u001b[0;36mmodelfit\u001b[1;34m(learning_rate, depth, bagging_temperature)\u001b[0m\n\u001b[0;32m      7\u001b[0m                              \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                              \u001b[0mbagging_temperature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbagging_temperature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                              early_stopping_rounds = 500),X_train,pd.DataFrame(y_train),scoring='roc_auc',cv=20).mean()\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcat1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    443\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    446\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 252\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;31m# For callabe scoring, the return type is only know after calling. If the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   4539\u001b[0m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0;32m   4540\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4541\u001b[1;33m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[0;32m   4542\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   1921\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1922\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m                 \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"init_model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1924\u001b[0m             )\n\u001b[0;32m   1925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AZhongnan University\\python\\Ana\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1366\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1367\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer.maximize(\n",
    "    init_points = 5,\n",
    "    n_iter = 25,\n",
    ")\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 81.8ms\tremaining: 3m 24s\n",
      "100:\ttotal: 2.2s\tremaining: 52.4s\n",
      "200:\ttotal: 4.59s\tremaining: 52.5s\n",
      "300:\ttotal: 6.92s\tremaining: 50.6s\n",
      "400:\ttotal: 9.23s\tremaining: 48.3s\n",
      "500:\ttotal: 11.4s\tremaining: 45.6s\n",
      "600:\ttotal: 13.6s\tremaining: 43s\n",
      "700:\ttotal: 17.5s\tremaining: 44.9s\n",
      "800:\ttotal: 22.2s\tremaining: 47.2s\n",
      "900:\ttotal: 26.1s\tremaining: 46.3s\n",
      "1000:\ttotal: 29.9s\tremaining: 44.8s\n",
      "1100:\ttotal: 33.7s\tremaining: 42.9s\n",
      "1200:\ttotal: 37.6s\tremaining: 40.6s\n",
      "1300:\ttotal: 41.4s\tremaining: 38.2s\n",
      "1400:\ttotal: 45.3s\tremaining: 35.5s\n",
      "1500:\ttotal: 49.4s\tremaining: 32.8s\n",
      "1600:\ttotal: 53.5s\tremaining: 30s\n",
      "1700:\ttotal: 57.6s\tremaining: 27.1s\n",
      "1800:\ttotal: 1m 1s\tremaining: 24s\n",
      "1900:\ttotal: 1m 5s\tremaining: 20.8s\n",
      "2000:\ttotal: 1m 10s\tremaining: 17.5s\n",
      "2100:\ttotal: 1m 14s\tremaining: 14.2s\n",
      "2200:\ttotal: 1m 18s\tremaining: 10.7s\n",
      "2300:\ttotal: 1m 23s\tremaining: 7.18s\n",
      "2400:\ttotal: 1m 27s\tremaining: 3.6s\n",
      "2499:\ttotal: 1m 31s\tremaining: 0us\n",
      "the catboost model auc : 0.875\n"
     ]
    }
   ],
   "source": [
    "#categorical_features_indices = np.where(X_train.dtypes != np.float)[0]\n",
    "#|  1        |  0.9806   |  0.4224   |  7.602    |  0.01011  |\n",
    "#|  2        |  0.9787   |  0.309    |  4.734    |  0.1013   |\n",
    "cat1 = CatBoostClassifier(loss_function=\"Logloss\",eval_metric=\"AUC\",\n",
    "                          iterations=2500,learning_rate=0.01,depth=7,verbose=100,bagging_temperature = 0.4,\n",
    "                          early_stopping_rounds=500)\n",
    "cat1.fit(X_train,pd.DataFrame(y_train))\n",
    "\n",
    "y_test_pre = cat1.predict(X_test)\n",
    "y_test_true = np.array(y_test)\n",
    "print (\"the catboost model auc : %.4g\" % metrics.roc_auc_score(y_test_true,y_test_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       136\n",
      "         1.0       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.99       140\n",
      "   macro avg       1.00      0.88      0.93       140\n",
      "weighted avg       0.99      0.99      0.99       140\n",
      "\n",
      "auc值为: 0.875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'CatBoostClassifier ROC Curve')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#具体的模型得分报告\n",
    "print(classification_report(y_test_true,y_test_pre))\n",
    "print(\"auc值为:\",roc_auc_score(y_test_true,y_test_pre))\n",
    "\n",
    "#ROC曲线绘制\n",
    "fpr1,tpr1,threshold1 = roc_curve(y_test_true,y_test_pre)\n",
    "plt.plot(fpr1, tpr1, color='r') \n",
    "plt.plot([0, 1], [0, 1], color='blue',linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('CatBoostClassifier ROC Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOPERATE_EXP         9.940680\n",
      "CASH_C_EQUIV         3.565959\n",
      "N_CE_END_BAL         3.259419\n",
      "GOING_CONCERN_NI     2.315758\n",
      "C_INF_FR_INVEST_A    2.025923\n",
      "                       ...   \n",
      "C_PAID_G_S           0.335896\n",
      "C_PAID_FOR_TAXES     0.332616\n",
      "INVENTORIES          0.315658\n",
      "T_CL                 0.235686\n",
      "ADMIN_EXP            0.203284\n",
      "Length: 104, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#特征重要性排名\n",
    "cat_predictors = [i  for i in ramdonForest_end_Data.drop(columns = 'FLAG').columns]\n",
    "cat_feat_imp = pd.Series(cat1.feature_importances_,cat_predictors).sort_values(ascending=False)\n",
    "cat_feat_imp[0:20].plot(kind = 'bar',title='Feature Importance')\n",
    "plt.ylabel('Feature Importance Score')\n",
    "plt.show()\n",
    "print(cat_feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOPERATE_EXP           9.940680\n",
      "CASH_C_EQUIV           3.565959\n",
      "N_CE_END_BAL           3.259419\n",
      "GOING_CONCERN_NI       2.315758\n",
      "C_INF_FR_INVEST_A      2.025923\n",
      "PREPAYMENT             1.845933\n",
      "OTH_PAYABLE            1.698766\n",
      "N_CF_FR_FINAN_A        1.680021\n",
      "ST_BORR                1.598634\n",
      "C_OUTF_FR_INVEST_A     1.562119\n",
      "N_INCOME               1.534726\n",
      "C_FR_OTH_OPERATE_A     1.389514\n",
      "NOPERATE_INCOME        1.341951\n",
      "CAPITAL_RESER          1.277323\n",
      "AR                     1.263323\n",
      "NI_NI                  1.217588\n",
      "N_CE_BEG_BAL           1.195639\n",
      "OR_TC                  1.191520\n",
      "IN_TC                  1.174806\n",
      "C_PAID_FOR_OTH_OP_A    1.150919\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(cat_feat_imp[0:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
